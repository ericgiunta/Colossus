[{"path":"/articles/Alt_Run_Opt.html","id":"general-options","dir":"Articles","previous_headings":"","what":"General Options","title":"Alternative Regression Options","text":"Cox proportional hazards Poisson model regressions additional functions can account specific situations. general situations follows: following sections review math behind basic functions option changes .","code":""},{"path":[]},{"path":"/articles/Alt_Run_Opt.html","id":"cox-proportional-hazards","dir":"Articles","previous_headings":"Stratification","what":"Cox Proportional Hazards","title":"Alternative Regression Options","text":"Cox Proportional Hazards, Log-Likelihood calculated taking ratio hazard ratio event sum hazard ratios every row risk. defines risk group every event time intervals containing event time. Intervals assumed open left closed right, events assumed take place right endpoint. gives following common equation Log-Likelihood: Ll=∏(ri∑j:tj∈Rirj)δi \\begin{aligned}     Ll = \\prod_{}^{n} \\left( \\frac{r_{}}{\\sum_{j: t_j \\R_i} r_j} \\right)^{\\delta_i} \\end{aligned} r denotes hazard ratios, denominator sum hazard ratios intervals containing event time, term raised power 1 interval event 0 otherwise. Different tie methods modify denominator based order events assumed, general form still stands. goal compare event interval intervals within similar time span. Stratification adds condition: user stratifies covariate “F” risk group split subgroups value “F”. goal becomes compare event intervals intervals similar strata time. done remove influence stratification variables calculations. code, done adding additional parameter stratification column using different response term model. Multiple strata columns can provided including vector columns.","code":"Strat_Col <- \"s0\" e <- CoxRun(Cox_Strata(time1, time2, event, s0) ~ loglinear(dose), df,   a_n = a_n, control = control ) Strat_Cols <- c(\"s0\", \"s1\", \"s2\") e <- CoxRun(Cox_Strata(time1, time2, event, c(s0, s1, s2)) ~ loglinear(dose), df,   a_n = a_n, control = control )"},{"path":"/articles/Alt_Run_Opt.html","id":"poisson-regression","dir":"Articles","previous_headings":"Stratification","what":"Poisson Regression","title":"Alternative Regression Options","text":"Poisson model regression risk groups account , theory . remove influence stratification covariate new term added account effects. Colossus, Log-Linear term. following may model used without stratification: R=∑(xi⋅βi) \\begin{aligned}     R = \\sum_i (x_i \\cdot \\beta_i) \\end{aligned} stratified model may look like : R=(∑(xi⋅βi))×(exp(∑strata(xstrata⋅βstrata))) \\begin{aligned}     R = (\\sum_i (x_i \\cdot \\beta_i)) \\times (\\exp{(\\sum_{strata} (x_{strata} \\cdot \\beta_{strata}))}) \\end{aligned} results associated non-stratified parameters returned default. strata effect calculated taking ratio events strata sum person-years multiplied risk strata. derivatives written, substituting strata effect. βstrata=(∑ieventi)/(∑iPi⋅Ri) \\begin{aligned}     \\beta_{strata} = (\\sum_i {event}_i) / (\\sum_i P_i \\cdot R_i) \\end{aligned} code, done adding list stratification columns using different response term model. Colossus combines list stratification columns single interaction, matter user provides list combines .","code":"Strat_Col <- c(\"e\") e <- PoisRun(Poisson_Strata(pyr, event, e) ~ loglinear(dose), df,   a_n = a_n, control = control )"},{"path":"/articles/Alt_Run_Opt.html","id":"non-derivative-calculation","dir":"Articles","previous_headings":"","what":"Non-Derivative Calculation","title":"Alternative Regression Options","text":"Colossus uses Newton’s method perform regression, can become computationally intensive model becomes complicated. , Colossus contains functions calculate scores parameter set skip derivative calculations. results used perform bisection method regression plot dependence score parameter values. ability left user’s convenience. code similar previous examples:","code":"e <- CoxRun(Cox(time1, time2, event) ~ loglinear(dose), df,   a_n = a_n, control = control, single = TRUE )"},{"path":[]},{"path":"/articles/Alt_Run_Opt.html","id":"fine-gray","dir":"Articles","previous_headings":"Competing Risks","what":"Fine-Gray","title":"Alternative Regression Options","text":"Cox PH assumption every individual recorded event naturally censored. Censoring assumed statistically independent regard event studied. assumptions commonly violated competing event occurring. sensitivity analysis, two extremes generally tested. Either every person competing event treated event interest instead, assumed never experience event interest. However, methods find realistic alternative. Colossus applies Fine-Gray model competing risks, instead weights contribution competing event intervals future intervals probability censored. previously established, risk groups formed measure probability individual survived time experienced event interest, given experience event time: λ(t)=limΔt→0(P(t≤T≤t+Δt) (k=1),T≥t)Δt \\begin{aligned}     \\lambda(t) = \\lim_{\\Delta t \\0} \\frac{(P(t \\leq T \\leq t + \\Delta t)\\text{ }(k=1), T \\geq t)}{\\Delta t} \\end{aligned} competing risks model adjusts probability individual survived time experienced event interest, given experience event time survived previous time experienced different event: λ(t)=limΔt→0(P(t≤T≤t+Δt) (k=1),(T≥t) ((T<t) (k≠1)))Δt \\begin{aligned}     \\lambda(t) = \\lim_{\\Delta t \\0} \\frac{(P(t \\leq T \\leq t + \\Delta t)\\text{ }(k=1), (T \\geq t)\\text{ }((T < t)\\text{ }(k \\neq 1)))}{\\Delta t} \\end{aligned} means risk groups contain intervals actually risk intervals competing events treated risk. assume time-dependent covariates used, remains weigh contribution competing events. general, weighting column provided regression, values can solved survival curve using “finegray” function survival library. code, call similar standard function. process finding weighting included . example, assume event column, lung, contain 0 events, 1 primary event, 2 competing event.","code":"pdata <- finegray(Surv(time2, event) ~ ., data = df)  e <- CoxRun(FineGray(fgstart, fgstop, fgstatus, fgwt) ~ loglinear(dose), pdata,   a_n = a_n, control = control )"},{"path":"/articles/Alt_Run_Opt.html","id":"poisson-joint-analysis","dir":"Articles","previous_headings":"Competing Risks","what":"Poisson Joint Analysis","title":"Alternative Regression Options","text":"dataset multiple outcomes, often two ways Poisson models fit. Either multiple independent models fit events combined one model fit several events. methods limit models completely independent identical. true model may combination shared terms terms specific event, modeled methods. fit type model joint analysis method (Cologne, 2019) available Colossus. Suppose one table person-years, covariate, counts two events. Assume fitting event rate (λ\\lambda) event (y,zy,z) reason believe background rate (β\\beta) event. λy()=β*exp(μy*)λz()=β*exp(μz*) \\begin{aligned}     \\lambda_y() = \\beta*\\exp{(\\mu_y*)}\\\\     \\lambda_z() = \\beta*\\exp{(\\mu_z*)} \\end{aligned} one solve equations separately table split two tables, one event column. premise joint analysis write model can applied every event, including factor covariate select event solved . split tables can recombined multiple events can solved allowing shared event-specific parameters. λ(,αy,αz)=β*exp(μy*(*αy)+μz*(*αz)) \\begin{aligned}     \\lambda(,\\alpha_y,\\alpha_z) = \\beta*\\exp{(\\mu_y*(*\\alpha_y) + \\mu_z*(*\\alpha_z))} \\end{aligned} Colossus includes several functions apply method, function produces input joint analysis regression function also runs regression. general converts table lists formula input regression. Colossus generally accepts formula describe elements model. joint analysis, Colossus instead expects list formula. formula expect cover model elements specific event, potentially model shared elements. Colossus expects name shared model “shared”. left hand side shared model used. function returns list containing combined table model object. results used input available regression functions. Colossus also includes wrapper function directly call Poisson model regression function.","code":"a <- c(0, 0, 0, 1, 1, 1) b <- c(1, 1, 1, 2, 2, 2) c <- c(0, 1, 2, 2, 1, 0) d <- c(1, 1, 0, 0, 1, 1) e <- c(0, 1, 1, 1, 0, 0) df <- data.table(\"t0\" = a, \"t1\" = b, \"e0\" = c, \"e1\" = d, \"fac\" = e) time1 <- \"t0\" time2 <- \"t1\" df$pyr <- df$t1 - df$t0 pyr <- \"pyr\" events <- c(\"e0\", \"e1\") model_1 <- Pois(pyr, e0) ~ loglin(fac, 0) model_2 <- Pois(pyr, e1) ~ loglin(fac, 0) model_s <- Pois(pyr) ~ plinear(t0, 0) formula_list <- list(model_1, model_2, \"shared\" = model_s) get_form_joint(formula_list, df, nthreads = 1) #> $model #> $person_year #> [1] \"pyr\" #>  #> $event #> [1] \"events\" #>  #> $strata #> [1] \"NONE\" #>  #> $null #> [1] FALSE #>  #> $term_n #> [1] 0 0 0 #>  #> $tform #> [1] \"plin\"   \"loglin\" \"loglin\" #>  #> $names #> [1] \"t0\"     \"fac_e0\" \"fac_e1\" #>  #> $a_n #> [1] 0 0 0 #>  #> $keep_constant #> [1] 0 0 0 #>  #> $modelform #> [1] \"ME\" #>  #> $gmix_term #> [1] 1 #>  #> $gmix_theta #> [1] 0 #>  #> $expres_calls #> list() #>  #> attr(,\"class\") #> [1] \"poismodel\" #>  #> $data #>        t0    t1 events    e0    e1   fac   pyr fac_e0 fac_e1 #>     <num> <num>  <num> <num> <num> <num> <num>  <num>  <num> #>  1:     0     1      0     1     0     0     1      0      0 #>  2:     0     1      1     1     0     1     1      1      0 #>  3:     0     1      2     1     0     1     1      1      0 #>  4:     1     2      2     1     0     1     1      1      0 #>  5:     1     2      1     1     0     0     1      0      0 #>  6:     1     2      0     1     0     0     1      0      0 #>  7:     0     1      1     0     1     0     1      0      0 #>  8:     0     1      1     0     1     1     1      0      1 #>  9:     0     1      0     0     1     1     1      0      1 #> 10:     1     2      0     0     1     1     1      0      1 #> 11:     1     2      1     0     1     0     1      0      0 #> 12:     1     2      1     0     1     0     1      0      0 control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiter\" = 10, \"halfmax\" = 5, \"epsilon\" = 1e-6,   \"deriv_epsilon\" = 1e-6, \"verbose\" = 2 ) e <- PoisRunJoint(formula_list, df, control = control) print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:        t0    plin           -0.184          0.385          0.631 #> 2:    fac_e0  loglin            0.574          0.468          0.219 #> 3:    fac_e1  loglin           -1.035          1.009          0.305 #>  #> Poisson Model Used #> -2*Log-Likelihood: 20.891,  Deviation: 6.436,  AIC: 12.436,  BIC: 28.346 #> Iterations run: 10 #> maximum step size: 4.775e-06, maximum first derivative: 1.595e-06 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.017 seconds #> |-------------------------------------------------------------------|"},{"path":"/articles/Control_Options.html","id":"general-use","dir":"Articles","previous_headings":"","what":"General Use","title":"List of Control Options","text":"several control lists used Colossus user can use customize regression, functions defined assign default values missing list items. following sections go control list, used, every item assigned means.","code":""},{"path":"/articles/Control_Options.html","id":"standard-control-list","dir":"Articles","previous_headings":"General Use","what":"Standard Control List","title":"List of Control Options","text":"“control” variable used every regression function. list focuses options control convergence criteria standard Cox proportional hazards options. can input control argument, given named arguments function, combination two.","code":""},{"path":"/articles/Control_Options.html","id":"other-control-lists","dir":"Articles","previous_headings":"General Use","what":"Other Control Lists","title":"List of Control Options","text":"following options can used cox plotting function select difference types plots: following options can used poisson residual function select difference types residuals: likelihood boundary calculated, several additional control options used:","code":""},{"path":"/articles/Dose_Formula_Inputs.html","id":"dose-response-formula","dir":"Articles","previous_headings":"","what":"Dose Response Formula","title":"Dose Response Formula Terms","text":"Colossus features term composed sum multiple linear non-linear elements can used define many dose-response curves used radiation epidemiology. terms referred dose-response terms, nothing prohibiting used non-dose covariates. following formulae available, reproduced starting description vignette. SNL=∑(αi×exp(xi⋅βi))+∑(βi⋅(xi)2)+∑iFLT+∑iFSTP+∑iFLQ+∑iFLEXPFLT={αi⋅(x−βi)(x>βi)0elseFSTP={αi(x>βi)0elseFLQ={βi⋅x(x>αi)λi⋅x2+νielseFLEXP={βi⋅x(x>αi)λi−exp(νi+μ⋅x)elseTj=SLL,j×SL,j×SPL,j×SNL,j \\begin{aligned}     S_{NL}=\\sum_i (\\alpha_i \\times \\exp(x_i \\cdot \\beta_i)) + \\sum_i (\\beta_i \\cdot (x_i)^2) + \\sum_i F_{LT} + \\sum_i F_{STP} + \\sum_i F_{LQ} + \\sum_i F_{LEXP}\\\\     F_{LT} = \\begin{cases} \\alpha_i \\cdot (x-\\beta_i) & (x>\\beta_i) \\\\ 0 &\\text{else} \\end{cases}\\\\     F_{STP} = \\begin{cases} \\alpha_i & (x>\\beta_i) \\\\ 0 &\\text{else} \\end{cases}\\\\     F_{LQ} = \\begin{cases} \\beta_i \\cdot x & (x>\\alpha_i) \\\\ \\lambda_i \\cdot x^2 + \\nu_i &\\text{else} \\end{cases}\\\\     F_{LEXP} = \\begin{cases} \\beta_i \\cdot x & (x>\\alpha_i) \\\\ \\lambda_i - \\exp{(\\nu_i + \\mu \\cdot x)} &\\text{else} \\end{cases}\\\\     T_j=S_{LL,j} \\times S_{L,j} \\times S_{PL,j} \\times S_{NL,j} \\end{aligned} every subterm type, 1 3 parameters fully define curve. Linear-Quadratic Linear-Exponential curves continuously differentiable, 2-3 parameters can set. λLQ=βLQ/(2αLQ)νLQ=(βLQ*αLQ)/2νLEXP=ln(βLEXP)−ln(μLEXP)+μLEXP*αLEXPλLEXP=βLEXP*αLEXP+exp(νLEXP−μLEXP*αLEXP) \\begin{aligned}     \\lambda_{LQ} = \\beta_{LQ}/(2\\alpha_{LQ})\\\\     \\nu_{LQ} = (\\beta_{LQ}*\\alpha_{LQ})/2\\\\     \\nu_{LEXP} = \\ln(\\beta_{LEXP})-\\ln(\\mu_{LEXP})+\\mu_{LEXP}*\\alpha_{LEXP}\\\\     \\lambda_{LEXP} = \\beta_{LEXP}*\\alpha_{LEXP}+exp(\\nu_{LEXP}-\\mu_{LEXP}*\\alpha_{LEXP}) \\end{aligned}","code":""},{"path":"/articles/Dose_Formula_Inputs.html","id":"using-the-different-subterms","dir":"Articles","previous_headings":"","what":"Using The Different subterms","title":"Dose Response Formula Terms","text":"subterms used like subterm model, except multiple parameters defined. following table lists model subterms used: applied model used regression, parameter listed result table. following table covers subterm type listed special parameter: linear-exponential linear-quadratic curves must either completely fixed completely free. contrast, exponential, linear threshold, step-function curves can partially fixed. exponential term can provided covariate exponent assume magnitude 1. linear threshold step functions can provided fixed threshold covariate, can used define linear--threshold model combination linear step functions known thresholds.","code":""},{"path":"/articles/Equation_Expression.html","id":"equation-expression","dir":"Articles","previous_headings":"","what":"Equation Expression","title":"Unified Equation Representation","text":"Generally, survival model defined using Surv object, initialized interval event columns, list columns. Colossus can handle much complicated models, definition complicated. Instead Surv object, model specified ‘cox’, ‘poisson’, ‘finegray’, also including strata option. right side equation listed similarly. Columns added subterm types (loglinear, linear, plinear, etc.). subterm list columns term number. Finally, method combine terms added separate item (multiplicative, additive, etc.). Surv(interval, event) ∼name + ... + factor(name)’Survival(interval, event) ∼ subterm(name, factor(name), term_number) + ... + term_model()’ \\begin{aligned}     \\text{Surv(interval, event) } \\sim \\text{name + ... + factor(name)} \\\\     \\text{'Survival(interval, event) } \\sim \\text{ subterm(name, factor(name), term_number) + ... + term_model()'} \\end{aligned} Based number entries, format time interval assumed. Cox models use entry time, exit time, event status. can either named ‘start’, ‘tend’, ‘event’ included order. none named, left truncated interval assumed. stratified cox model includes named entry ‘strata’ right-entry assumed stratification column. Fine-Gray model adds weighting column standard Cox interval representation, assumed entry named ‘weight’ right-entry. total, assumed order : entry time, exit time, event status, strata column, weighting column. ’Cox(tstart, tend, event) ∼ ...’’Cox_Strata(tstart, tend, event, strata) ∼ ...’’FineGray(tstart, tend, event, weight) ∼ ...’’FineGray_Strata(tstart, tend, event, strata, weight) ∼ ...’ \\begin{aligned}     \\text{'Cox(tstart, tend, event) } \\sim \\text{ ...'} \\\\     \\text{'Cox_Strata(tstart, tend, event, strata) } \\sim \\text{ ...'} \\\\     \\text{'FineGray(tstart, tend, event, weight) } \\sim \\text{ ...'} \\\\     \\text{'FineGray_Strata(tstart, tend, event, strata, weight) } \\sim \\text{ ...'} \\end{aligned} Poisson models use measure duration (named ‘pyr’), number events (named ‘event’), strata columns. assumed order ‘pyr’, ‘event’, strata columns listed sequentially. duration event columns can named, naming strata columns currently supported. ’Pois(pyr, event) ∼ ...’’Pois_Strata(pyr, event, strata_0) ∼ ...’’Pois_Strata(pyr, event, strata_0, strata_1, ...) ∼ ...’ \\begin{aligned}     \\text{'Pois(pyr, event) } \\sim \\text{ ...'} \\\\     \\text{'Pois_Strata(pyr, event, strata_0) } \\sim \\text{ ...'} \\\\     \\text{'Pois_Strata(pyr, event, strata_0, strata_1, ...) } \\sim \\text{ ...'} \\end{aligned} right hand side adds elements subterms. subterm included columns, optionally term number. Subterms assumed term 0 term number provided, model assumed multiplicative excess. factor option automatically removes first level reference. Note unused levels can listed first use levels. following expressions equivalent. following tables cover subterms term models currently implemented. Every option listed multiple equivalent aliases refer subterm model formula.","code":"term_n <- c(0, 0, 1) tform <- c(\"loglin\", \"loglin\", \"lin\") names <- c(\"dose0\", \"dose1\", \"dose2\") modelform <- \"M\" tstart <- \"t0\" tend <- \"t1\" event <- \"lung\"  Model_Eq <- Cox(t0, t1, lung) ~ loglinear(dose0, dose1, 0) +   linear(dose2, 1) + ME() Model_Eq <- Cox(t0, t1, lung) ~ loglinear(dose0, dose1) +   linear(dose2, 1)  df <- data.table(   \"dose0\" = 1:4, \"dose1\" = 2:5, \"dose2\" = 3:6,   \"t0\" = c(0, 0, 1, 0), \"t1\" = 5:8, \"lung\" = c(1, 0, 0, 1) ) res <- get_form(Model_Eq, df, nthreads = 1) formula <- res$model new_data <- res$data"},{"path":"/articles/Excess_and_Predicted_Cases.html","id":"general-theory","dir":"Articles","previous_headings":"","what":"General Theory","title":"Excess and Predicted Cases","text":"field radiation epidemiology, common question “many additional cancer cases occurred due radiation exposures?”. often generalized question many cases background cases many cases excess cases. calculated splitting poisson model background term excess terms. Colossus, background term assumed first term, every term assumed causing excess cases. Colossus function, EventAssignment, calculates number background/excess cases average predicted counts true counts. Let us assume following model event rate: R(β,x,α,D)=exp(β⋅x)*(1+α⋅D) \\begin{aligned}     R(\\beta,x, \\alpha, D)=\\exp(\\beta \\cdot x)*(1 + \\alpha \\cdot D) \\end{aligned} total rate (RR) composed background rate (RBKR_{BK}) excess rate (REXR_{EX}). cases row total (cc) background/excess count (cBK,cEXc_{BK}, c_{EX}). Additionally, every row measure person-time (tt). Colossus also computes predicted number total, background, excess cases (P,PBK.PEXP, P_{BK}. P_{EX}). every model assume average number background cases background rate multiplied time, remaining cases excess, true number background/excess cases proportional predicted cases. R=exp(β⋅x)*(1+α⋅D)RBK=exp(β⋅x)P=PBK+PEXP=R*tPBK=RBK*tPEX=P−PBKc=cBK+cEXcBK=c*PBKPcEX=c*PEXP \\begin{aligned}     R = \\exp(\\beta \\cdot x)*(1 + \\alpha \\cdot D)\\\\     R_{BK} = \\exp(\\beta \\cdot x)\\\\     P = P_{BK} + P_{EX}\\\\     P = R * t\\\\     P_{BK} = R_{BK} * t\\\\     P_{EX} = P - P_{BK}\\\\     c = c_{BK} + c_{EX}\\\\     c_{BK} = c * \\frac{P_{BK}}{P}\\\\     c_{EX} = c * \\frac{P_{EX}}{P} \\end{aligned} Colossus returns two matrices, one true cases one predicted cases. matrix three columns events assigned background, excess, total. provides information relative amount background excess cases, well differences expected true number cases. EventAssignment can also used calculate number cases confidence interval model parameter. excess background cases evaluated midpoint, well risk model optimized model parameter held constant boundary values. produces three lists matrices, lower limit, midpoint, upper limit. point standard matrices observed predicted events produced. method can also applied results likelihood-based boundary regression evaluate distribution cases likelihood-based confidence interval.","code":"a_n <- c(0.1, 0.1) model <- Pois(pyr, event) ~ loglinear(x, 0) + plinear(D, 1) + Multiplicative() poisres <- PoisRun(model, df, a_n = a_n) e <- EventAssignment(poisres, df)  e0 <- e$predict e1 <- e$caused  BK <- e0[, 1] EX <- e0[, 2] Total <- e0[, 3] e <- EventAssignment(poisres, df, check_num = 2, z = 1.96)  e_lower <- e$lower_limit$caused e_mid <- e$midpoint$caused e_high <- e$upper_limit$caused  EX_low <- e_lower[, 2] EX_mid <- e_mid[, 2] EX_high <- e_high[, 2]  p_bound <- LikelihoodBound(poisres, df, para_number = 2, alpha = 0.05) e <- EventAssignment(p_bound, df)"},{"path":"/articles/Grad_Hess.html","id":"optimization-theory","dir":"Articles","previous_headings":"","what":"Optimization Theory","title":"Gradient and Hessian Approaches","text":"Colossus offers three levels score calculation, calculating score, calculating score first derivative, calculating score first second derivatives. second third options correspond Gradient Descent Newton-Raphson optimization approaches. goal vignette discuss methods different, circumstances might appropriate. cases, algorithm designed iteratively change parameter estimates approach set parameter values optimize score. major difference much information calculated used. Newton-Raphson algorithm calculates second derivative matrix, inverts , solves linear system equations set first derivative vector zero. method establishes magnitude direction every step. every step several time-intensive calculations, new parameter estimates informed. algorithm, Colossus uses learning rate (η\\eta) maximum allowable parameter change (βmax\\beta_{max}). Colossus uses half-steps slowly reduce allowable step size solution approaches optimum. Δβ×∂2LL∂β2≈−∂LL∂βΔβ=−η∂LL∂βt×(∂2LL∂βt2)−1βt+1=βt+sign(Δβ)*min([|Δβ|,βmax]) \\begin{aligned}     \\Delta \\beta \\times \\frac{\\partial^2 LL}{\\partial \\beta^2} \\approx - \\frac{\\partial LL}{\\partial \\beta} \\\\     \\Delta \\beta = - \\eta \\frac{\\partial LL}{\\partial \\beta_{t}} \\times \\left ( \\frac{\\partial^2 LL}{\\partial \\beta_{t}^2} \\right)^{-1} \\\\     \\beta_{t+1} = \\beta_{t} + sign(\\Delta \\beta)*min \\left( \\left[ \\left|\\Delta \\beta \\right|, \\beta_{max} \\right] \\right) \\end{aligned} alternative Gradient descent approach. algorithm, first derivatives calculated used determine vector highest change score. establishes direction change parameters, multiplied learning rate (η\\eta). Similar Newton-Raphson algorithm, magnitude limited maximum allowable parameter change (βmax\\beta_{max}). Gradient algorithm avoids time-intensive second-derivative calculations takes less informed steps. iteration runs faster, iterations may required. Δβ=η*∂LL∂ββt+1=βt+sign(Δβ)*min([|Δβ|,βmax]) \\begin{aligned}    \\Delta \\beta = \\eta * \\frac{\\partial LL}{\\partial \\beta}\\\\    \\beta_{t+1} = \\beta_{t} + sign(\\Delta \\beta)*min \\left( \\left[ \\left|\\Delta \\beta \\right|, \\beta_{max} \\right] \\right) \\end{aligned} standard half-step framework likely sufficient Gradient descent algorithm. , several different optimization options added: momentum, adadelta, adam. use previous information gradient inform step size future steps. first method, momentum, applies weighted sum (γ\\gamma) current previous step. done speed steps moving toward optimum position correct algorithm oversteps. can avoid issue oscillation around optimum value. Δβt=γ*Δβt−1+η*∂LL∂ββt+1=βt+sign(Δβt)*min([|Δβt|,βmax]) \\begin{aligned}    \\Delta \\beta_{t} = \\gamma * \\Delta \\beta_{t-1} + \\eta * \\frac{\\partial LL}{\\partial \\beta}\\\\    \\beta_{t+1} = \\beta_{t} + sign(\\Delta \\beta_{t})*min \\left( \\left[ \\left|\\Delta \\beta_{t} \\right|, \\beta_{max} \\right] \\right) \\end{aligned} next method, adadelta method, applies parameter-specific learning rate tracking root mean square (RMS) gradient parameter updates within window. Instead tracking true window iteration, old estimate RMS decayed weight (γ\\gamma) added new estimate. ratio RMS parameter update RMS gradient used normalize results back correct units. small offset (ϵ\\epsilon) used avoid case division zero. gt=(∂LL∂β)tE[g2]t=γ*E[g2]t−1+(1−γ)*gt2E[Δβ2]t−1=γ*E[Δβ2]t−2+(1−γ)*Δβt−12RMS[g]t=E[g2]t+ϵRMS[Δβ]t−1=E[Δβ2]t−1+ϵΔβt=RMS[Δβ]t−1RMS[g]t*gtβt+1=βt+sign(Δβt)*min([|Δβt|,βmax]) \\begin{aligned}     g_t = \\left (\\frac{\\partial LL}{\\partial \\beta} \\right)_{t} \\\\     E[g^2]_{t} = \\gamma * E[g^2]_{t-1} + (1-\\gamma) * g^2_{t} \\\\     E[\\Delta \\beta^2]_{t-1} = \\gamma * E[\\Delta \\beta^2]_{t-2} + (1-\\gamma) * \\Delta \\beta^2_{t-1} \\\\     RMS[g]_t = \\sqrt{E[g^2]_{t} + \\epsilon} \\\\     RMS[\\Delta \\beta]_{t-1} = \\sqrt{E[\\Delta \\beta^2]_{t-1} + \\epsilon} \\\\    \\Delta \\beta_{t} = \\frac{RMS[\\Delta \\beta]_{t-1}}{RMS[g]_t} * g_t\\\\    \\beta_{t+1} = \\beta_{t} + sign(\\Delta \\beta_{t})*min \\left( \\left[ \\left|\\Delta \\beta_{t} \\right|, \\beta_{max} \\right] \\right) \\end{aligned} final method, adam, combines theory behind momentum adadelta methods. adam method tracks estimate first moment vector (mm) second moment vector (vv), weighted decay parameters (β1,β2\\beta_1, \\beta_2). bias corrected correct bias early iterations (m̂,v̂\\hat{m}, \\hat{v}). learning rate (η\\eta) second moment vector provide decaying learning rate adadelta, first moment vector provides effect similar momentum. Combined, generally able stabilize gradient descent algorithms without incurring significant computational cost. gt=(∂LL∂β)tm0,v0=0,0mt=β1*mt−1+(1−β1)*gtvt=β2*vt−1+(1−β2)*gt2m̂t=mt/(1−β1t)v̂t=vt/(1−β2t)Δβt=ηv̂t+ϵ*m̂tβt+1=βt+sign(Δβt)*min([|Δβt|,βmax]) \\begin{aligned}     g_t = \\left (\\frac{\\partial LL}{\\partial \\beta} \\right)_{t} \\\\     m_0, v_0 = 0, 0 \\\\     m_t = \\beta_1 * m_{t-1} + (1-\\beta_1) * g_t \\\\     v_t = \\beta_2 * v_{t-1} + (1-\\beta_2) * g^2_t \\\\     \\hat{m}_t = m_t / (1-\\beta_1^t) \\\\     \\hat{v}_t = v_t / (1-\\beta_2^t) \\\\    \\Delta \\beta_{t} = \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} * \\hat{m}_t \\\\    \\beta_{t+1} = \\beta_{t} + sign(\\Delta \\beta_{t})*min \\left( \\left[ \\left|\\Delta \\beta_{t} \\right|, \\beta_{max} \\right] \\right) \\end{aligned}","code":""},{"path":"/articles/Grad_Hess.html","id":"use-in-practice","dir":"Articles","previous_headings":"","what":"Use in Practice","title":"Gradient and Hessian Approaches","text":"first thing acknowledge gradient descent method may require hyperparameter tuning standard Newton-Raphson method. general, may necessary run analysis multiple times different learning rates, decay terms, offsets. following test example shows basic usage simple model. Every gradient descent algorithm available tested starting point. cases, algorithm approaches solution different rates. case, local extrema, standard approach fine. show fundamental differences methods. effect momentum apparent compared standard option, estimates oscillate quickly. differences adadelta adam also visible, adam method converged quicker. results necessarily use optimized hyperparameters, meant prove method best.","code":"fname <- \"tests/testthat/ll_comp_0.csv\" colTypes <- c(\"double\", \"double\", \"double\", \"integer\", \"integer\") df <- fread(fname, nThread = 1, data.table = TRUE, header = TRUE, colClasses = colTypes, verbose = 2, fill = TRUE) set.seed(3742) df$rand <- floor(runif(nrow(df), min = 0, max = 5))  a_n <- c(-0.1, -0.1) keep_constant <- c(0, 0)  # Code not run due to duration for (method in c(\"momentum\", \"adadelta\", \"adam\", \"gradient\")) {   gradient_control <- list(\"epsilon_decay\" = 1e-4)   gradient_control[[method]] <- TRUE   a_n <- c(-0.1, -0.1)   control <- list(     \"ncores\" = 1, \"lr\" = 0.2, \"maxiters\" = c(1, 20),     \"halfmax\" = 2, \"epsilon\" = 1e-6,     \"deriv_epsilon\" = 1e-6, \"verbose\" = 4   )   e <- CoxRun(Cox(t0, t1, lung) ~ loglinear(dose, rand, 0) + m(), df,     a_n = a_n, keep_constant = keep_constant,     control = control, gradient_control = gradient_control   )   print(e) } x <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22) y <- c(-0.1, 0.9, 0.446528, 0.839821, 0.493552, 0.799313, 0.528609, 0.768118, 0.555872, 0.743827, 0.577191, 0.724839, 0.593904, 0.70996, 0.607026, 0.698284, 0.617337, 0.689114, 0.625445, 0.681907, 0.631822, 0.67624, 0.67624, -0.1, 0.9, 0.446528, 0.431696, 0.834161, 0.857333, 0.501858, 0.477865, 0.793264, 0.814217, 0.531039, 0.511871, 0.770217, 0.78877, 0.55277, 0.530413, 0.745479, 0.771659, 0.578773, 0.54938, 0.72037, 0.750178, 0.750178, -0.1, -0.0683777, -0.0236573, 0.0204036, 0.0631351, 0.104199, 0.143407, 0.180661, 0.215914, 0.249159, 0.280419, 0.309735, 0.337162, 0.362769, 0.386631, 0.408828, 0.429444, 0.448562, 0.466269, 0.482647, 0.497779, 0.511745, 0.511745, -0.1, 0.0999967, 0.299992, 0.49416, 0.672686, 0.818272, 0.912721, 0.951325, 0.943139, 0.900966, 0.836339, 0.759197, 0.678706, 0.6037, 0.542181, 0.50002, 0.479848, 0.481022, 0.500511, 0.53392, 0.576232, 0.622276, 0.622276) c <- c(\"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\")  df <- data.table(\"x\" = x, \"y\" = y, \"method\" = c)  g <- ggplot2::ggplot(df, ggplot2::aes(x = .data$x, y = .data$y, group = .data$method, color = .data$method)) +   ggplot2::geom_line(\"linewidth\" = 1.2) +   ggplot2::labs(x = \"Iteration\", y = \"First Parameter Value\") +   ggplot2::ggtitle(\"First Parameter Value Convergence\") g x <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22) y <- c(-0.1, 0.382267, 0.481728, 0.371577, 0.474396, 0.383262, 0.464408, 0.392812, 0.456452, 0.40023, 0.45019, 0.406007, 0.445259, 0.41052, 0.441374, 0.414052, 0.438314, 0.416821, 0.435902, 0.418993, 0.434002, 0.420699, 0.420699, -0.1, 0.382267, 0.481728, 0.461092, 0.353981, 0.381487, 0.499642, 0.486223, 0.365388, 0.35904, 0.467404, 0.490215, 0.404434, 0.37681, 0.439266, 0.459563, 0.412495, 0.405195, 0.44752, 0.445014, 0.399118, 0.404763, 0.404763, -0.1, -0.0683799, -0.0236649, 0.0193058, 0.0594837, 0.0964731, 0.130195, 0.160739, 0.188284, 0.213051, 0.235278, 0.255201, 0.273049, 0.289032, 0.303346, 0.316169, 0.327659, 0.337961, 0.347201, 0.355493, 0.36294, 0.36963, 0.36963, -0.1, 0.0999917, 0.299977, 0.469249, 0.559129, 0.571139, 0.537754, 0.485171, 0.434002, 0.399975, 0.38974, 0.400107, 0.422011, 0.444253, 0.456706, 0.453734, 0.435816, 0.40853, 0.380544, 0.36118, 0.357234, 0.370462, 0.370462) c <- c(\"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\")  df <- data.table(\"x\" = x, \"y\" = y, \"method\" = c)  g <- ggplot2::ggplot(df, ggplot2::aes(x = .data$x, y = .data$y, group = .data$method, color = .data$method)) +   ggplot2::geom_line(\"linewidth\" = 1.2) +   ggplot2::labs(x = \"Iteration\", y = \"Second Parameter Value\") +   ggplot2::ggtitle(\"Second Parameter Value Convergence\") g x <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22) y <- c(239.962, 234.592, 234.454, 234.362, 234.282, 234.226, 234.178, 234.144, 234.116, 234.094, 234.076, 234.062, 234.052, 234.044, 234.038, 234.032, 234.028, 234.026, 234.022, 234.02, 234.02, 234.018, 234.018, 239.962, 234.592, 234.454, 234.494, 234.362, 234.416, 234.284, 234.344, 234.226, 234.292, 234.174, 234.244, 234.142, 234.204, 234.112, 234.17, 234.092, 234.144, 234.072, 234.122, 234.06, 234.102, 234.102, 239.962, 239.438, 238.74, 238.104, 237.536, 237.036, 236.598, 236.22, 235.89, 235.608, 235.364, 235.156, 234.978, 234.826, 234.696, 234.586, 234.492, 234.414, 234.348, 234.292, 234.244, 234.206, 234.206, 239.962, 237.064, 235.166, 234.276, 234.118, 234.34, 234.642, 234.804, 234.766, 234.58, 234.334, 234.122, 234.018, 234.042, 234.142, 234.246, 234.298, 234.286, 234.23, 234.158, 234.09, 234.04, 234.04) c <- c(\"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"momentum\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adadelta\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\")  df <- data.table(\"x\" = x, \"y\" = y, \"method\" = c)  g <- ggplot2::ggplot(df, ggplot2::aes(x = .data$x, y = .data$y, group = .data$method, color = .data$method)) +   ggplot2::geom_line(\"linewidth\" = 1.2) +   ggplot2::labs(x = \"Iteration\", y = \"Log-Likelihood Value\") +   ggplot2::ggtitle(\"Log-Likelihood Convergence\") g"},{"path":"/articles/Grad_Hess.html","id":"hyper-parameter-tuning-examples","dir":"Articles","previous_headings":"Use in Practice","what":"Hyper-parameter Tuning Examples","title":"Gradient and Hessian Approaches","text":"First, brief comparison learning rates standard gradient descent method. analysis, gradient scale (-2,2) learning rate scale ~ 1/10 appropriate. gradient much larger learning rate need correspondingly decreased. learning rate high, estimate unstable oscillate. learning rate low estimate converge reasonable amount time.  Next, momentum decay. momentum decay term helpful particularly standard method overshoots solution. example, standard method learning rate 0.1 issue overshooting solution, momentum method tested learning rate 0.2 induce oscillation. learning rate 0.0, standard gradient descent increase momentum effect see faster convergence.  Finally, epsilon offset used adadelta method. example, offset low change parameter value per iteration near zero, increased algorithm converges faster estimate oscillates.","code":"x <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22) y <- c(-0.1, -0.0758866, -0.0524678, -0.0297801, -0.00784991, 0.0133049, 0.0336744, 0.053255, 0.0720488, 0.0900628, 0.107308, 0.123797, 0.139549, 0.154581, 0.168914, 0.18257, 0.195571, 0.207941, 0.219702, 0.230879, 0.241495, 0.251573, 0.251573, -0.1, 0.141134, 0.305602, 0.376672, 0.406159, 0.418355, 0.423402, 0.425492, 0.426358, 0.426717, 0.426865, 0.426927, 0.426952, 0.426963, 0.426967, 0.426969, 0.42697, 0.42697, 0.42697, 0.42697, -0.1, 0.382267, 0.481728, 0.371577, 0.474396, 0.383262, 0.464408, 0.392812, 0.456452, 0.40023, 0.45019, 0.406007, 0.445259, 0.41052, 0.441374, 0.414052, 0.438314, 0.416821, 0.435902, 0.418993, 0.434002, 0.420699, 0.420699, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, -0.1, 0.9, 0.9) c <- c(\"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.01\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.1\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\")  df <- data.table(\"x\" = x, \"y\" = y, \"LearningRate\" = c)  g <- ggplot2::ggplot(df, ggplot2::aes(x = .data$x, y = .data$y, group = .data$LearningRate, color = .data$LearningRate)) +   ggplot2::geom_line(\"linewidth\" = 1.2) +   ggplot2::labs(x = \"Iteration\", y = \"Second Parameter\") +   ggplot2::ggtitle(\"Second Parameter Convergence\") g x <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22) y <- c(-0.1, 0.382267, 0.481728, 0.371577, 0.474396, 0.383262, 0.464408, 0.392812, 0.456452, 0.40023, 0.45019, 0.406007, 0.445259, 0.41052, 0.441374, 0.414052, 0.438314, 0.416821, 0.435902, 0.418993, 0.434002, 0.420699, 0.420699, -0.1, 0.382267, 0.481728, 0.391469, 0.435244, 0.429155, 0.424804, 0.427892, 0.426568, 0.427082, 0.427015, 0.426915, 0.426992, 0.426967, 0.42697, 0.426971, 0.42697, 0.426971, 0.42697, 0.42697, 0.426971, 0.426971, -0.1, 0.382267, 0.481728, 0.421307, 0.389624, 0.442182, 0.445048, 0.414796, 0.420771, 0.433596, 0.427802, 0.424361, 0.427741, 0.42752, 0.426131, 0.427168, 0.427483, 0.426655, 0.426746, 0.427195, 0.427034, 0.426856, 0.426856) c <- c(\"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.0\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.2\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\", \"0.5\")  df <- data.table(\"x\" = x, \"y\" = y, \"MomentumDecay\" = c)  g <- ggplot2::ggplot(df, ggplot2::aes(x = .data$x, y = .data$y, group = .data$MomentumDecay, color = .data$MomentumDecay)) +   ggplot2::geom_line(\"linewidth\" = 1.2) +   ggplot2::labs(x = \"Iteration\", y = \"Second Parameter\") +   ggplot2::ggtitle(\"Second Parameter Convergence\") g x <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22) y <- c(-0.1, -0.0998946, -0.0997455, -0.0995686, -0.0993678, -0.0991457, -0.0989042, -0.0986448, -0.0983686, -0.0980766, -0.0977695, -0.0974482, -0.0971132, -0.096765, -0.0964041, -0.0960311, -0.0956462, -0.0952498, -0.0948422, -0.0944238, -0.0939948, -0.0935554, -0.0935554, -0.1, -0.0894592, -0.0745523, -0.0569106, -0.0369613, -0.0149815, 0.00881833, 0.0342662, 0.0612136, 0.0895258, 0.119075, 0.149732, 0.181361, 0.213808, 0.246885, 0.280336, 0.313768, 0.346445, 0.376444, 0.393247, 0.380437, 0.397974, 0.397974, -0.1, -0.0666699, -0.0195369, 0.0357806, 0.0976085, 0.164622, 0.235362, 0.307561, 0.375392, 0.39949, 0.393904, 0.42769, 0.416127, 0.448594, 0.412644, 0.445826, 0.410436, 0.445034, 0.409797, 0.444717, 0.409586, 0.444599, 0.444599, -0.1, 0.00530869, 0.154075, 0.317511, 0.438734, 0.311745, 0.479287, 0.359676, 0.509816, 0.380595, 0.519051, 0.390015, 0.516403, 0.39013, 0.51552, 0.389794, 0.484692, 0.374198, 0.483729, 0.372471, 0.483021, 0.372011, 0.372011) c <- c(\"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-8\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-4\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-3\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\", \"1e-2\")  df <- data.table(\"x\" = x, \"y\" = y, \"Epsilon\" = c)  g <- ggplot2::ggplot(df, ggplot2::aes(x = .data$x, y = .data$y, group = .data$Epsilon, color = .data$Epsilon)) +   ggplot2::geom_line(\"linewidth\" = 1.2) +   ggplot2::labs(x = \"Iteration\", y = \"Second Parameter\") +   ggplot2::ggtitle(\"Second Parameter Convergence\") g"},{"path":"/articles/Logistic.html","id":"logistic-modeling-for-binomial-odds-and-binary-data","dir":"Articles","previous_headings":"","what":"Logistic Modeling for Binomial Odds and Binary Data","title":"Logistic Regression","text":"One alternative regression method Colossus predicting probability event independent trials logistic regression. theory presented following section.","code":""},{"path":"/articles/Logistic.html","id":"general-theory","dir":"Articles","previous_headings":"Logistic Modeling for Binomial Odds and Binary Data","what":"General Theory","title":"Logistic Regression","text":"start describing structure data. logistic regression models Colossus assume data can represented terms trials, events, risk factors. Similar Poisson model using person-years number events row, logistic model requires measure number independent trials events group. special case analysis row represents one trial, either 0 1 events observed. likelihood (LL) logistic model function trials (NiN_i), events (yiy_i), probability success (pip_i) row, ii. Colossus, log-likelihood (LlLl) optimized. L=∏[piyi×(1−pi)Ni−yi]Ll=∑[yiln(pi)+(Ni−yi)ln(1−pi)] \\begin{aligned}     L = \\prod_i \\left [ p_i^{y_i} \\times (1-p_i)^{N_i - y_i} \\right ] \\\\     Ll = \\sum_i \\left [ y_i \\ln(p_i) + (N_i - y_i) \\ln(1-p_i) \\right ] \\\\ \\end{aligned} Similar survival models Colossus, model written function various risk factors (f(β→,x→)f(\\vec{\\beta}, \\vec{x})). function related probability linking function. Three options currently available: odds, identity, complementary log linking, based options present 32-bit Epicure. podds=f(β→,x→)1+f(β→,x→)pid=f(β→,x→)pcomp=e−f(β→,x→) \\begin{aligned}     p_{odds} = \\frac{f(\\vec{\\beta}, \\vec{x})}{1+f(\\vec{\\beta}, \\vec{x})} \\\\     p_{id} = f(\\vec{\\beta}, \\vec{x}) \\\\     p_{comp} = e^{-f(\\vec{\\beta}, \\vec{x})} \\end{aligned} Similar regression models Colossus, first derivative vector second derivative matrix calculated optimize model parameters. ∂Ll∂μ=∑[yi∂pi/∂μpi−(Ni−yi)∂pi/∂μ1−pi]∂2Ll∂μ∂ν=∑[yi(∂2pi/∂μ∂νpi−∂pi/∂μpi∂pi/∂νpi)−(Ni−yi)(∂2pi/∂μ∂ν1−pi+∂pi/∂μ1−pi∂pi/∂ν1−pi)] \\begin{aligned}     \\frac{\\partial Ll}{\\partial \\mu} = \\sum_i \\left [ y_i \\frac{\\partial p_i/\\partial \\mu}{p_i} - (N_i - y_i) \\frac{\\partial p_i/\\partial \\mu}{1-p_i} \\right ] \\\\     \\frac{\\partial^2 Ll}{\\partial \\mu \\partial \\nu} = \\sum_i \\left [ y_i \\left (\\frac{\\partial^2 p_i/\\partial \\mu \\partial \\nu}{p_i} - \\frac{\\partial p_i/\\partial \\mu}{p_i} \\frac{\\partial p_i/\\partial \\nu}{p_i} \\right ) - (N_i - y_i) \\left ( \\frac{\\partial^2 p_i/\\partial \\mu \\partial \\nu}{1-p_i} + \\frac{\\partial p_i/\\partial \\mu}{1-p_i} \\frac{\\partial p_i/\\partial \\nu}{1-p_i} \\right ) \\right ] \\\\ \\end{aligned}","code":""},{"path":"/articles/Logistic.html","id":"examples-of-use","dir":"Articles","previous_headings":"Logistic Modeling for Binomial Odds and Binary Data","what":"Examples of Use","title":"Logistic Regression","text":"use logistic model Colossus closely follows regression options. start loading preparing data. example, using Veterans’ Administration Lung Cancer study data survival package. Every row 1 trial binary event status column. , model uses trial column, event column, “risk” equation converted probability. case, number trials 1, column can omitted, illustrate, artificially create trial column named “trial”. start testing effects cell type. default, Colossus always remove first level factored column. can force Colossus include every level defining lowest level unused value, -1 case. gives final model removed baseline added intercept column (CONST). case, p-values null hypothesis cell type effect. removed baseline added intercept, p-values null hypothesis cell type effect baseline. analysis, using default odds ratio. linking function can changed using “link” option. following examples show impact using linking function. Note probability must 0-1, starting values set ensure initial probability estimates valid. using categorical risk factors, every model converges score event probabilities; however, standard error p-values affected. using continuous variables, linking functions give way define complicated risk models.","code":"# veteran %>% setDT() df <- copy(veteran) # Make the same adjustments as Epicure example 6.5 karno <- df$karno karno[93] <- 20 df$karno <- karno df$trt <- df$trt - 1 df$trt <- as.integer(df$trt == 0) cell_lvl <- c(\"large\", \"squamous\", \"smallcell\", \"adeno\") df$cell <- as.integer(factor(df$celltype, level = cell_lvl)) - 1 df$karno50 <- df$karno - 50  df$trial <- 1 df$cell <- factor(df$cell, levels = c(-1, 0, 1, 2, 3))  model <- Logit(trial, status) ~ loglinear(cell) model <- Logit(status) ~ loglinear(cell)  control <- list(verbose = 0, ncores = 1) e <- LogisticRun(model, df, control = control) print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:    cell_0  loglin             3.26          1.019       1.39e-03 #> 2:    cell_1  loglin             2.05          0.531       1.16e-04 #> 3:    cell_2  loglin             2.71          0.596       5.58e-06 #> 4:    cell_3  loglin             3.26          1.019       1.39e-03 #>  #> Logisitic Model Used #> -2*Log-Likelihood: 64.429,  Deviation: 64.429,  AIC: 72.429,  BIC: 84.109 #> Iterations run: 11 #> maximum step size: 1.075e-04, maximum first derivative: 3.454e-05 #> Analysis converged #> Run finished in 0.026 seconds #> |-------------------------------------------------------------------| a_n <- c(0.1, 0.1, 0.1, 0.1) e <- LogisticRun(model, df, control = control, a_n = a_n, link = \"odds\") print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:    cell_0  loglin             3.26          1.019       1.39e-03 #> 2:    cell_1  loglin             2.05          0.531       1.16e-04 #> 3:    cell_2  loglin             2.71          0.596       5.58e-06 #> 4:    cell_3  loglin             3.26          1.019       1.39e-03 #>  #> Logisitic Model Used #> -2*Log-Likelihood: 64.429,  Deviation: 64.429,  AIC: 72.429,  BIC: 84.109 #> Iterations run: 11 #> maximum step size: 9.569e-05, maximum first derivative: 3.072e-05 #> Analysis converged #> Run finished in 0.027 seconds #> |-------------------------------------------------------------------|  a_n <- c(-1, -1, -1, -1) e <- LogisticRun(model, df, control = control, a_n = a_n, link = \"ident\") print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:    cell_0  loglin          -0.0377         0.0377         0.3173 #> 2:    cell_1  loglin          -0.1214         0.0607         0.0456 #> 3:    cell_2  loglin          -0.0645         0.0373         0.0833 #> 4:    cell_3  loglin          -0.0377         0.0377         0.3173 #>  #> Logisitic Model Used #> -2*Log-Likelihood: 64.429,  Deviation: 64.429,  AIC: 72.429,  BIC: 84.109 #> Iterations run: 9 #> maximum step size: 3.037e-05, maximum first derivative: 7.168e-03 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.016 seconds #> |-------------------------------------------------------------------|  a_n <- c(0.1, 0.1, 0.1, 0.1) e <- LogisticRun(model, df, control = control, a_n = a_n, link = \"loglink\") print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:    cell_0  loglin            -3.28          1.000       1.05e-03 #> 2:    cell_1  loglin            -2.11          0.500       2.49e-05 #> 3:    cell_2  loglin            -2.74          0.577       2.08e-06 #> 4:    cell_3  loglin            -3.28          1.000       1.05e-03 #>  #> Logisitic Model Used #> -2*Log-Likelihood: 64.429,  Deviation: 64.429,  AIC: 72.429,  BIC: 84.109 #> Iterations run: 12 #> maximum step size: 1.263e-04, maximum first derivative: 4.514e-05 #> Analysis converged #> Run finished in 0.015 seconds #> |-------------------------------------------------------------------|"},{"path":"/articles/Matched_Case_Control.html","id":"matched-case-control-modeling","dir":"Articles","previous_headings":"","what":"Matched Case-Control Modeling","title":"Matched Case-Control Logistic Regression","text":"One alternative regression method Colossus matched case-control logistic regression. theory presented following section.","code":""},{"path":[]},{"path":"/articles/Matched_Case_Control.html","id":"conditional-logistic-regression","dir":"Articles","previous_headings":"Matched Case-Control Modeling > General Theory","what":"Conditional Logistic Regression","title":"Matched Case-Control Logistic Regression","text":"Suppose matched case-control data divide data matched set. set mm cases nn records. denote relative risk individual ii set rir_i. can calculate probability case exposures conditional exposures set taking ratio product relative risks cases sum product relative risks every way selecting mm individuals nn risk. ∏imri∑c∈R(∏j=1mrcj)L=∑=1mlog(ri)−log(∑c∈R(∏j=1mrcj)) \\begin{aligned}     \\frac{\\prod_{}^{m} r_i}{\\sum_{c \\R} \\left ( \\prod_{j=1}^{m} r_{c_j} \\right )} \\\\     L = \\sum_{=1}^{m} log(r_i) - log \\left ( \\sum_{c \\R} \\left ( \\prod_{j=1}^{m} r_{c_j} \\right ) \\right ) \\end{aligned} Using methods presented Gail et al. (1981) can calculate combination n!/m!(n−m)!n!/m!(n-m)! ways select mm items manageable recursive formula B(m,n)B(m,n). B(m,n)=∑c∈R(∏j=1mrcj)B(m,n)=B(m,n−1)+rnB(m−1,n−1)B(m,n)={∑jnrjm=10m>n \\begin{aligned}     B(m, n) = \\sum_{c \\R} \\left ( \\prod_{j=1}^{m} r_{c_j} \\right ) \\\\     B(m,n) = B(m, n-1) + r_n B(m-1, n-1) \\\\     B(m,n) = \\begin{cases}      \\sum_{j}^{n} r_j & m = 1 \\\\      0                & m > n     \\end{cases} \\end{aligned} can directly solve first second derivatives recursive formula. ∂ri∂βμ=:riμ∂B(m,n)∂βμ=Bμ(m,n)=∑c∈R[(∑j=1mrcjμrcj)∏j=1mrcj]Bμ(m,n)=Bμ(m,n−1)+rnBμ(m−1,n−1)+rnμB(m−1,n−1)Bμ(m,n)={∑jnrjμm=10m>n \\begin{aligned}     \\frac{\\partial r_i}{\\partial \\beta_\\mu} =: r_{}^{\\mu} \\\\     \\frac{\\partial B(m,n)}{\\partial \\beta_\\mu} = B^{\\mu}(m, n) = \\sum_{c \\R} \\left [ \\left ( \\sum_{j=1}^{m} \\frac{r_{c_j}^{\\mu}}{r_{c_j}} \\right ) \\prod_{j=1}^{m} r_{c_j} \\right ] \\\\     B^{\\mu}(m,n) = B^{\\mu}(m, n-1) + r_n B^{\\mu}(m-1, n-1) + r_n^{\\mu} B(m-1, n-1) \\\\     B^{\\mu}(m,n) = \\begin{cases}      \\sum_{j}^{n} r_j^{\\mu} & m = 1 \\\\      0                & m > n     \\end{cases} \\end{aligned} ∂2ri∂βμ∂βν=:riμ,ν∂2B(m,n)∂βμ∂βν=Bμ,ν(m,n)=∑c∈R[(∑j=1mrcjμ,νrcj+(∑j=1mrcjμrcj)(∑j=1mrcjνrcj)−∑j=1mrcjμrcjrcjνrcj)∏j=1mrcj]Bμ,ν(m,n)=Bμ,ν(m,n−1)+rnμ,νB(m−1,n−1)+rnνBμ(m−1,n−1)+rnμBν(m−1,n−1)+rnBμ,ν(m−1,n−1)Bμ,ν(m,n)={∑jnrjμ,νm=10m>n \\begin{aligned}     \\frac{\\partial^2 r_i}{\\partial \\beta_\\mu \\partial \\beta_\\nu} =: r_{}^{\\mu,\\nu} \\\\     \\frac{\\partial^2 B(m,n)}{\\partial \\beta_\\mu \\partial \\beta_\\nu} = B^{\\mu,\\nu}(m, n) = \\sum_{c \\R} \\left [ \\left ( \\sum_{j=1}^{m} \\frac{r_{c_j}^{\\mu,\\nu}}{r_{c_j}} +      \\left ( \\sum_{j=1}^{m} \\frac{r_{c_j}^{\\mu}}{r_{c_j}} \\right ) \\left ( \\sum_{j=1}^{m} \\frac{r_{c_j}^{\\nu}}{r_{c_j}} \\right ) - \\sum_{j=1}^{m} \\frac{r_{c_j}^{\\mu}}{r_{c_j}} \\frac{r_{c_j}^{\\nu}}{r_{c_j}} \\right ) \\prod_{j=1}^{m} r_{c_j} \\right ] \\\\     B^{\\mu,\\nu}(m,n) = B^{\\mu,\\nu}(m, n-1) + r_n^{\\mu,\\nu} B(m-1, n-1) + r_n^{\\nu} B^{\\mu}(m-1, n-1) + r_n^{\\mu} B^{\\nu}(m-1, n-1) + r_n B^{\\mu,\\nu}(m-1, n-1) \\\\     B^{\\mu,\\nu}(m,n) = \\begin{cases}      \\sum_{j}^{n} r_j^{\\mu,\\nu} & m = 1 \\\\      0                & m > n     \\end{cases} \\end{aligned} Finally, expressions B(m,n)B(m,n) can substituted equations contribution Log-Likelihood derivatives matched set. model optimized via methods regression models. Lset=∑=1mlog(ri)−log(B(m,n))Lsetμ=∑=1mriμri−Bμ(m,n)B(m,n)Lsetμ,ν=∑=1m(riμ,νri−riμririnuri)−(Bμ,ν(m,n)B(m,n)−Bμ(m,n)B(m,n)Bν(m,n)B(m,n)) \\begin{aligned}     L_{set} = \\sum_{=1}^{m} log(r_i) - log \\left ( B(m,n) \\right ) \\\\     L^{\\mu}_{set} = \\sum_{=1}^{m} \\frac{r_i^{\\mu}}{r_i} - \\frac{B^{\\mu}(m,n)}{B(m,n)} \\\\     L^{\\mu, \\nu}_{set} = \\sum_{=1}^{m} \\left ( \\frac{r_i^{\\mu,\\nu}}{r_i} - \\frac{r_i^{\\mu}}{r_i}\\frac{r_i^{nu}}{r_i} \\right ) - \\left ( \\frac{B^{\\mu,\\nu}(m,n)}{B(m,n)} - \\frac{B^{\\mu}(m,n)}{B(m,n)}\\frac{B^{\\nu}(m,n)}{B(m,n)}  \\right ) \\end{aligned}","code":""},{"path":"/articles/Matched_Case_Control.html","id":"unconditional-logistic-regression","dir":"Articles","previous_headings":"Matched Case-Control Modeling > General Theory","what":"Unconditional Logistic Regression","title":"Matched Case-Control Logistic Regression","text":"important note recursive formula calculation can quickly become time-consuming, particularly large number cases. make matched case-control method generally applicable, likelihood function can changed logistic regression model matched sets large number cases. general, matched case-control regression function adds item model control list, “cond_thres”, set threshold switch logistic regression model. logistic loglikelihood defined treating matched case-control data single trial data. likelihood function event status (θi\\theta_i) odds ratio (OiO_i). odds ratio row calculated product odds ratio matched set (OsO_s) relative risk row (rir_i). Behind scenes, Colossus optimizes model parameters (β→\\vec{\\beta}) relative risk well logistic model matched set odds ratios (Os=eαsO_s=e^{\\alpha_s}). Li=yiln(Osri)−ln(1+Osri)∂Li∂βj=yirijri−Osrij1+Osri∂Li∂αs=(yi−1)+11+Osri∂2Li∂βj∂βk=yi(rij,kri−rijririkri)−Os(rij,k1+Osri−Osrij1+Osririk1+Osri)∂2Li∂βj∂αs=−Osrij1+Osri∂2Li∂αs2=−Osri1+Osri \\begin{aligned}     L_i = y_i ln(O_s r_i) - ln(1+ O_s r_i) \\\\     \\frac{\\partial L_i}{\\partial \\beta_j} = y_i \\frac{r^j_i}{r_i} - O_s \\frac{r^j_i}{1 + O_s r_i}\\\\     \\frac{\\partial L_i}{\\partial \\alpha_s} = (y_i - 1) + \\frac{1}{1 + O_s r_i} \\\\     \\frac{\\partial^2 L_i}{\\partial \\beta_j \\partial \\beta_k} = y_i \\left ( \\frac{r^{j,k}_i}{r_i} - \\frac{r^j_i}{r_i} \\frac{r^k_i}{r_i} \\right ) - O_s \\left ( \\frac{r^{j,k}_i}{1 + O_s r_i} - O_s \\frac{r^j_i}{1 + O_s r_i} \\frac{r^k_i}{1 + O_s r_i} \\right ) \\\\     \\frac{\\partial^2 L_i}{\\partial \\beta_j \\partial \\alpha_s} = \\frac{-O_s r^j_i}{1 + O_s r_i} \\\\     \\frac{\\partial^2 L_i}{\\partial \\alpha_s^2} = \\frac{-O_s r_i}{1 + O_s r_i} \\end{aligned}","code":""},{"path":"/articles/Matched_Case_Control.html","id":"examples-of-use","dir":"Articles","previous_headings":"Matched Case-Control Modeling","what":"Examples of Use","title":"Matched Case-Control Logistic Regression","text":"following provides basic example use matched case-control regression function. data used lung cancer study, included R survival library. Slight adjustments made make data line data included 32-bit Epicure, comparison. short, want model effects treatment Karnofsky performance score sets matched cancer cell type. following examples, using matching strata changing conditional threshold. first case, every matched set uses recursive formula. second case, one set uses simplified formula. Finally third case, every set uses simplified formula. cases, regression returns typical output can summarized similarly regression function outputs.","code":"# data(cancer, package = \"survival\") veteran %>% setDT() df <- copy(veteran) # Make the same adjustments as Epicure example 6.5 karno <- df$karno karno[93] <- 20 df$karno <- karno df$trt <- df$trt - 1 df$trt <- as.integer(df$trt == 0) cell_lvl <- c(\"large\", \"squamous\", \"smallcell\", \"adeno\") df$cell <- as.integer(factor(df$celltype, level = cell_lvl)) - 1  df$karno50 <- df$karno - 50 model <- CaseControl_Strata(status, cell) ~ loglinear(karno50, trt)   control <- list(verbose = 2, maxiters = c(25, 25), ncores = 1) e0 <- CaseControlRun(model, df, control = control, conditional_threshold = 100) e1 <- CaseControlRun(model, df, control = control, conditional_threshold = 40) e2 <- CaseControlRun(model, df, control = control, conditional_threshold = 0)   print(e0) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:   karno50  loglin             0.01          0.017          0.556 #> 2:       trt  loglin             0.01          0.700          0.989 #>  #> Matched Case-Control Model Used #> Model stratified by 'cell' #> Deviance: 57.029 #> 0 out of 4 matched sets used Unconditional Likelihood #> Iterations run: 3 #> maximum step size: 6.104e-05, maximum first derivative: 1.465e+02 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.027 seconds #> |-------------------------------------------------------------------| print(e1) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:   karno50  loglin             0.01         0.0171          0.558 #> 2:       trt  loglin             0.01         0.5726          0.986 #>  #> Matched Case-Control Model Used #> Model stratified by 'cell' #> Deviance: 59.956 #> 1 out of 4 matched sets used Unconditional Likelihood #> Iterations run: 3 #> maximum step size: 6.104e-05, maximum first derivative: 1.463e+02 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.013 seconds #> |-------------------------------------------------------------------| print(e2) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:   karno50  loglin             0.01         0.0172          0.561 #> 2:       trt  loglin             0.01         0.5164          0.985 #>  #> Matched Case-Control Model Used #> Model stratified by 'cell' #> Deviance: 67.073 #> 4 out of 4 matched sets used Unconditional Likelihood #> Iterations run: 3 #> maximum step size: 6.104e-05, maximum first derivative: 1.498e+02 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.013 seconds #> |-------------------------------------------------------------------|"},{"path":"/articles/Multi_Realization.html","id":"available-methods","dir":"Articles","previous_headings":"","what":"Available Methods","title":"Multiple Realization Methods","text":"many instances user may want use data known distribution, cases may sufficient use single realization. Colossus provides two ways use multiple realizations. first runs multiple regressions row, different realization. second optimizes average Log-Likelihood realizations. methods designed assist circumstances combinations shared unshared errors present, two-dimensional Monte Carlo method used generate realizations least one covariate column. Note method apply uncertainties event/cases interval/duration columns.","code":""},{"path":"/articles/Multi_Realization.html","id":"specifics-of-use","dir":"Articles","previous_headings":"Available Methods","what":"Specifics of Use","title":"Multiple Realization Methods","text":"Let us suppose interested performing regression three covariates: age bin, amount exposure radioisotope interval, average sleep interval. Age bin known, exposure known distribution shared among individuals, sleep randomly distributed independent interval. λ(,r,s)=exp(βa×+βa×r+βa×s) \\begin{aligned}     \\lambda(, r, s) = \\exp{(\\beta_a \\times + \\beta_a \\times r + \\beta_a \\times s)} \\end{aligned} Colossus requires two items apply multiple realizations, list columns replace, matrix columns realization. Suppose user generates 5 realizations. two distributed columns five realizations. Similar regression options, Colossus always expects column names listed model table. first method designed perform Frequentist Model Averaging method. runs regression returns matrices final parameter estimates, standard deviations, log-likelihoods/AIC regression. results can used create likelihood-weighted parameter distributions, account uncertainty final parameter estimates. Note strict requirement realization columns realizations distributed column. user use method compare models formula different covariates. difficulty Colossus refresh parameter estimates realization regressions, user may need keep mind feasible parameter space. individual realizations optimized initial parameter estimate infeasible, parameter estimates associated negative term reduced magnitude. cases, enough find nearby feasible space start . second method designed perform Monte Carlo Maximum Likelihood method. returns standard regression output, using average log-likelihood. , requirement realization columns distribution. code also used determine set model parameters optimize average risk series similar models.","code":"model <- Cox(t0, t1, event) ~ loglinear(a, r0, s0)  a_n <- c(0.1, 0.1, 0.1) dose_index <- c(\"r0\", \"s0\") # The two columns in the model to replace are the radiation/sleeping covariates dose_realizations <- matrix(   c(\"r0\", \"r1\", \"r2\", \"r3\", \"r4\", \"s0\", \"s1\", \"s2\", \"s3\", \"s4\"),   nrow = 2 ) # columns to be used for realizations 0-4, rows for each column being replaced e_fma <- CoxRunMulti(model, df,   a_n = a_n,   realization_columns = realization_columns,   realization_index = realization_index,   fma = TRUE ) e_mcml <- CoxRunMulti(model, df,   a_n = a_n,   realization_columns = realization_columns,   realization_index = realization_index,   mcml = TRUE )"},{"path":"/articles/Plotting_And_Analysis.html","id":"example-setup","dir":"Articles","previous_headings":"","what":"Example Setup","title":"Functions for Plotting and Analysis","text":"use analysis lung dataset survival package visualize different plotting methods available Colossus.","code":"data(cancer, package = \"survival\") cancer %>% setDT() df <- copy(cancer)  df$UserID <- seq_len(nrow(df))  df$status <- df$status - 1 df$sex <- df$sex - 1  control <- list(ncore = 1) a_n <- c(0.01701289, -0.51256478) coxres <- CoxRun(Cox(time, status) ~ loglinear(age, sex, 0),   df,   control = control, a_n = a_n )"},{"path":"/articles/Plotting_And_Analysis.html","id":"survival-function-approximation","dir":"Articles","previous_headings":"","what":"Survival Function Approximation","title":"Functions for Plotting and Analysis","text":"fitting Cox proportional hazards model, one may interested baseline survival rate . One method weighting number events event time total risk. absence excess risk, hazard point time equal event rate hazard ratio every row equal one, assumption holds case negligible excess risk. λ(t)=d[t]n[t]=d[t]∑=1n(1)=d[t]∑=1n(ri) \\begin{aligned}     \\lambda(t) = \\frac{d[t]}{n[t]} = \\frac{d[t]}{\\sum_{=1}^n(1)} = \\frac{d[t]}{\\sum_{=1}^n(r_i)} \\end{aligned} Suppose every row risk time twice likely experience event baseline. expect twice many events baseline. logic applies case every row risk half likely. generalizes average risk. Colossus allows instantaneous hazard approximated stratified non-stratified models. λ(t)=d[t]∑=1n(ri)=d[t]∑=1n(2)=d[t]/2n[t]λ(t)=d[t]∑=1n(ri)=d[t]∑=1n(0.5)=d[t]*2n[t] \\begin{aligned}      \\lambda(t) = \\frac{d[t]}{\\sum_{=1}^n(r_i)} = \\frac{d[t]}{\\sum_{=1}^n(2)} = \\frac{d[t]/2}{n[t]}\\\\      \\lambda(t) = \\frac{d[t]}{\\sum_{=1}^n(r_i)} = \\frac{d[t]}{\\sum_{=1}^n(0.5)} = \\frac{d[t]*2}{n[t]} \\end{aligned} instantaneous hazard approximated, cumulative hazard can approximated. surviving fraction approximately equal exponential negative cumulative hazard event time. Λ(t)=∫0t(λ(x)dx)S(t)=exp(−Λ(t)) \\begin{aligned}     \\Lambda(t) = \\int_0^t (\\lambda(x) dx)\\\\     S(t) = \\exp{(-\\Lambda(t))} \\end{aligned}","code":"plot_options <- list(   \"type\" = c(\"surv\", paste(tempfile(), \"run\", sep = \"\")), \"studyid\" = \"UserID\",   \"verbose\" = 2, \"surv_curv\" = T, \"martingale\" = F, \"strat_haz\" = F, \"km\" = F )  e <- plot(coxres, df, plot_options)  norm_surv <- e[[\"standard\"]]  g <- ggplot2::ggplot(norm_surv, ggplot2::aes(x = .data$t, y = .data$h)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::labs(x = \"age\", y = \"Instantaneous Hazard\") g g <- ggplot2::ggplot(norm_surv, ggplot2::aes(x = .data$t, y = .data$ch)) +   ggplot2::geom_line(color = \"black\", alpha = 1) +   ggplot2::labs(x = \"age\", y = \"Cumulative Hazard\") g g <- ggplot2::ggplot(norm_surv, ggplot2::aes(x = .data$t, y = .data$surv)) +   ggplot2::geom_line(color = \"black\", alpha = 1) +   ggplot2::labs(x = \"age\", y = \"Surviving Fraction\") g plot_options <- list(   \"type\" = c(\"surv\", paste(tempfile(), \"run\", sep = \"\")), \"studyid\" = \"UserID\",   \"verbose\" = 2, \"surv_curv\" = F, \"martingale\" = F, \"strat_haz\" = F, \"km\" = T )  e <- plot(coxres, df, plot_options)  km <- e[[\"kaplin-meier\"]] g <- ggplot2::ggplot(km, ggplot2::aes(x = .data$t_t, y = .data$n_t)) +   ggplot2::geom_line(color = \"black\", alpha = 1) +   ggplot2::labs(x = \"age\", y = \"KM Survival\") g"},{"path":"/articles/Plotting_And_Analysis.html","id":"cox-proportional-hazards-model-assumptions","dir":"Articles","previous_headings":"","what":"Cox Proportional Hazards model assumptions","title":"Functions for Plotting and Analysis","text":"Cox proportional hazards model definition assumes proportional hazards independent time. violated, results regression may misleading. two checks Colossus provides can used test assumption, Schoenfeld residuals Martingale residuals. cases, premise hazard ratio independent time, residuals also independent time.","code":""},{"path":"/articles/Plotting_And_Analysis.html","id":"schoenfeld-residuals","dir":"Articles","previous_headings":"Cox Proportional Hazards model assumptions","what":"Schoenfeld Residuals","title":"Functions for Plotting and Analysis","text":"Schoenfeld residuals compare average covariate value rows events risk-weighted average covariate rows risk. Consistently high low residuals may due hazard much higher lower model predicts. residuals also correlated event time, hazard ratio may dependent event time. also option scale residuals standard deviation. s(t,x)=∑∈eventsxid[t]−∑inxi*ri∑inri \\begin{aligned}     s(t,x) = \\frac{\\sum_{\\events} x_i}{d[t]} - \\frac{\\sum_i^n x_i*r_i}{\\sum_i^n r_i} \\end{aligned}","code":"plot_options <- list(   \"type\" = c(\"schoenfeld\", paste(tempfile(), \"run\", sep = \"\")),   \"studyid\" = \"UserID\", \"verbose\" = 2 )  res_all <- plot(coxres, df, plot_options)  res_age <- res_all[[\"age\"]]  g <- ggplot2::ggplot(res_age, ggplot2::aes(x = .data$time, y = .data$y)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::labs(     x = paste(\"Survival Time\", sep = \"\"),     y = paste(\"Schoenfeld Residual (age)\", sep = \" \")   ) g g <- ggplot2::ggplot(res_age, ggplot2::aes(x = .data$time, y = .data$y_scale)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::labs(     x = paste(\"Survival Time\", sep = \"\"),     y = paste(\"Schoenfeld Residual Scaled (age)\", sep = \" \")   ) g res_sex <- res_all[[\"sex\"]]  g <- ggplot2::ggplot(res_sex, ggplot2::aes(x = .data$time, y = .data$y)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::labs(     x = paste(\"Survival Time\", sep = \"\"),     y = paste(\"Schoenfeld Residual (sex)\", sep = \" \")   ) g g <- ggplot2::ggplot(res_sex, ggplot2::aes(x = .data$time, y = .data$y_scale)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::labs(     x = paste(\"Survival Time\", sep = \"\"),     y = paste(\"Schoenfeld Residual Scaled (sex)\", sep = \" \")   ) g"},{"path":"/articles/Plotting_And_Analysis.html","id":"martingale-residuals","dir":"Articles","previous_headings":"Cox Proportional Hazards model assumptions","what":"Martingale Residuals","title":"Functions for Plotting and Analysis","text":"Martingale residuals compare event status cumulative hazard subject. residual bound open interval (−∞,1)(-\\infty, 1). Negative residuals correspond subjects survive despite high cumulative hazard residuals near unity correspond subjects experienced event despite low cumulative hazard. distribution residuals event time can indicate model -predicting -predicting dependent time. mj=δj−∫t0t1λ(t)*rjdt \\begin{aligned}     m_j = \\delta_j - \\int_{t_0}^{t_1} \\lambda(t) * r_j dt \\end{aligned}","code":"plot_options <- list(   \"type\" = c(\"surv\", paste(tempfile(), \"run\", sep = \"\")),   \"studyid\" = \"UserID\", \"verbose\" = 2, \"surv_curv\" = F,   \"martingale\" = T, \"strat_haz\" = F, \"km\" = F, \"cov_cols\" = c(\"age\", \"sex\") ) res_all <- plot(coxres, df, plot_options)  res_age <- res_all[[\"age\"]]  g <- ggplot2::ggplot() +   ggplot2::geom_point(     data = res_age,     ggplot2::aes(x = .data$cov_max, y = .data$res_sum, group = .data$event, color = .data$event)   ) g <- g + ggplot2::labs(x = \"Max Age\", y = \"Martingale Residuals\") g res_sex <- res_all[[\"sex\"]] g <- ggplot2::ggplot() +   ggplot2::geom_point(     data = res_sex,     ggplot2::aes(x = .data$cov_max, y = .data$res_sum, group = .data$event, color = .data$event)   ) g <- g + ggplot2::labs(x = \"Sex\", y = \"Martingale Residuals\") g res_surv <- res_all[[\"survival_time\"]] g <- ggplot2::ggplot() +   ggplot2::geom_point(     data = res_surv,     ggplot2::aes(x = .data$time_max, y = .data$res_sum, group = .data$event, color = .data$event)   ) g <- g + ggplot2::labs(x = \"Survival Time\", y = \"Martingale Residuals\") g"},{"path":"/articles/Plotting_And_Analysis.html","id":"general-evaluation-of-risk","dir":"Articles","previous_headings":"","what":"General Evaluation of Risk","title":"Functions for Plotting and Analysis","text":"Colossus also offers scripts plot relative risk parameter value parameter model, assuming every parameter constant.","code":"plot_options <- list(   \"type\" = c(\"risk\", paste(tempfile(), \"run\", sep = \"\")), \"studyid\" = \"UserID\",   \"verbose\" = 2 ) res_all <- plot(coxres, df, plot_options)  res_age <- res_all[[\"age\"]]  g <- ggplot2::ggplot(res_age, ggplot2::aes(x = .data$x, y = .data$y)) +   ggplot2::geom_line(color = \"black\") +   ggplot2::labs(x = \"Age\", y = \"Relative Risk\") g res_sex <- res_all[[\"sex\"]] g <- ggplot2::ggplot(res_sex, ggplot2::aes(x = .data$x, y = .data$y)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::labs(x = \"Sex\", y = \"Relative Risk\") g"},{"path":"/articles/SMR_Analysis.html","id":"external-rate-comparisons","dir":"Articles","previous_headings":"","what":"External Rate Comparisons","title":"SMR Analysis","text":"times, important determine event rate cohort statistically different event rate reference population. traditionally done calculating Standardized Mortality Ratio (SMR). analysis assumes researcher table event rates different combinations ages categories reference population, applied collected data estimate number events collected data subject background event rate reference population. goal generally determine observed events statistically different expected number events, investigate much effect different covariates .","code":""},{"path":"/articles/SMR_Analysis.html","id":"smr-calculation","dir":"Articles","previous_headings":"External Rate Comparisons","what":"SMR Calculation","title":"SMR Analysis","text":"One method approximate fit model SMR. simplest model estimate true rate (λi\\lambda_i) multiple expected rate (λi*\\lambda^{*}_{}). provides SMR full cohort, assuming one estimated rate every row data. λi=β*λi* \\begin{aligned}     \\lambda_i = \\beta * \\lambda^{*}_{} \\end{aligned} analysis, use veteran lung cancer trial data survival package. treat events status equal 2, scale survival time per 100 days, assume every row expected event rate 0.5, roughly double average rate data. practice, constant population average row-specific rate taken mapping table external events onto data. analysis proceeds identically standard Poisson regression. interested linear relationship expected event rate true event rate, set initial parameter estimate 1. case, found SMR 0.474, analysis confidence interval (Likelihood-based) performed check results statistically significant. Suppose wanted take analysis step investigate effect difference covariates. SMR equation can adjusted either additive multiplicative effect, similar Poisson regression model. Let us assume interested effects biological sex. can add another element model rerun regression. case, found SMR sex=0 0.37 SMR sex=1 0.56. investigate confidence intervals determine estimates statistically significant. demonstrates one can use Poisson regressions external event rates estimate differences event rates external populations studied populations.","code":"data(cancer, package = \"survival\") cancer %>% setDT() df <- copy(cancer)  cancer$status <- as.integer(cancer$status == 2) cancer$time <- cancer$time / 100  cancer$erate <- 0.5 a_n <- c(1) control <- list(   \"ncores\" = 1, \"maxiter\" = 20, \"halfmax\" = 5, \"epsilon\" = 1e-9,   \"deriv_epsilon\" = 1e-9, \"verbose\" = 2 ) e <- PoisRun(Poisson(time, status) ~ linear(erate), cancer,   a_n = a_n, control = control ) print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Central Estimate Standard Error 2-tail p-value #>       <char>  <char>            <num>          <num>          <num> #> 1:     erate     lin            0.474         0.0369       9.15e-38 #>  #> Poisson Model Used #> -2*Log-Likelihood: 576.22,  Deviation: 246.22,  AIC: 248.22,  BIC: 581.649 #> Iterations run: 13 #> maximum step size: 1.741e-10, maximum first derivative: 1.235e-06 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.02 seconds #> |-------------------------------------------------------------------| a_n <- c(1, 1)  e <- PoisRun(Poisson(time, status) ~ linear(erate, 0) + linear(sex, 1),   cancer,   a_n = a_n, control = control ) print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Term Number Central Estimate Standard Error 2-tail p-value #>       <char>  <char>       <int>            <num>          <num>          <num> #> 1:     erate     lin           0             0.37          0.111       0.000882 #> 2:       sex     lin           1             0.19          0.257       0.458904 #>  #> Poisson Model Used #> -2*Log-Likelihood: 582.865,  Deviation: 252.865,  AIC: 256.865,  BIC: 593.724 #> Iterations run: 7 #> maximum step size: 9.313e-10, maximum first derivative: 1.416e+01 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.011 seconds #> |-------------------------------------------------------------------|"},{"path":"/articles/Script_Comparison_Epicure.html","id":"introduction-to-colossus","dir":"Articles","previous_headings":"","what":"Introduction to Colossus","title":"Script comparisons with 32-bit Epicure","text":"Colossus developed context radiation epidemiologists wanting use new methods data. time development, 32-bit Epicure popular software running radiation epidemiological analysis. vignette written mind help transitioning users see two similar different, addition providing guidance converting two. script provided discuss Colossus-specific differences well general R capabilities differ Epicure.","code":""},{"path":"/articles/Script_Comparison_Epicure.html","id":"example-epicure-analysis","dir":"Articles","previous_headings":"Introduction to Colossus","what":"Example Epicure Analysis","title":"Script comparisons with 32-bit Epicure","text":"following peanuts script used part validation efforts Colossus. script runs three regressions. linear excess relative risk model, log-linear hazard ratio model dose overall, log-linear hazard ratio model categorical bins dose. Similar regressions performed radiation cohort data assess relationship risk different mortality events cumulative radiation exposure organs. script starts loading dataset. example, assume file called “EX_DOSE.csv” local directory. Next, script sets interval start column interval end column, designates columns multiple levels. Past point, script specifies columns belong subterm term number. case, model product-linear element first term. script additionally sets convergence options. maximum iterations set 100 convergence criteria set 1e-9. regression also set print deviance parameter estimates iteration print final parameter estimates covariance regression concludes. Finally, regression run results printed console. Past point, general process followed two hazard ratio regressions. model definition reset, subterm/term description set, regression run.","code":"RECORDS 4100000 @ WSOPT VARMAX 30 @ USETXT EX_DOSE.csv @ INPUT @ ENTRY age_entry @ EXIT age_exit @ EVENT nonCLL @  levels SES_CAT YOB_CAT sexm dose_cat @ LOGLINEAR 0 SES_CAT YOB_CAT sexm @ PLINEAR 0 cumulative_dose @  FITOPT P V ITER 100 CONV -9 @ FIT @ NOMODEL @  LOGLINEAR 0 SES_CAT YOB_CAT sexm cumulative_dose @  FIT @  NOMODEL @  LOGLINEAR 0 SES_CAT YOB_CAT sexm dose_cat @  FIT @"},{"path":"/articles/Script_Comparison_Epicure.html","id":"colossus-script","dir":"Articles","previous_headings":"Introduction to Colossus","what":"Colossus Script","title":"Script comparisons with 32-bit Epicure","text":"part, steps performed Colossus. script starts reading input file. difference R require memory set aside reading file. Colossus defines model formula. left-hand side formula defines type model, time observed, event columns. right-hand side defines risk factors term subterm. model Cox regression, intervals defined age_entry/age_exit columns, event status stored nonCLL column. denoted ‘Cox(age_entry, age_exit, nonCLL)’. loglinear product-linear subterms added formula specifying subterm type, included columns, term number, .e. ‘subterm(column 1, column 2, …, term number)’. Factored columns added using ‘factor(column)’, default level assumed first level. Next, script defines control information. “control” variable serves similar purpose “FITOPT” option Epicure. control list specifies two cores used perform calculations parallel, 100 iterations used, iterations stop step size 1e-9 first derivatives 1e-9. verbose options specifies errors warnings printed console. Finally, regression run list results returned variable “e”. Regressions Colossus return list results, summary can printed. similar process run two hazard ratio regressions.","code":"df_Dose <- fread(\"EX_DOSE.csv\") model_ERR <- Cox(age_entry, age_exit, nonCLL) ~ plinear(cumulative_dose, 0) +   loglinear(factor(SES_CAT), factor(YOB_CAT), sexm) control <- list(   \"Ncores\" = 1, \"maxiter\" = 100, \"verbose\" = 2,   \"epsilon\" = 1e-9, \"der_epsilon\" = 1e-9 ) e <- CoxRun(model_ERR, df_dose, control = control) print(e) # HR model_HR <- Cox(age_entry, age_exit, nonCLL) ~ loglinear(cumulative_dose, factor(SES_CAT), factor(YOB_CAT), sexm) e <- CoxRun(model_HR, df_dose, control = control) print(e)  # Categorical model_categ <- Cox(age_entry, age_exit, nonCLL) ~ loglinear(factor(dose_cat), factor(SES_CAT), factor(YOB_CAT), sexm) e <- CoxRun(model_categ, df_dose, control = control) print(e)"},{"path":[]},{"path":"/articles/Starting-Description.html","id":"model-structure","dir":"Articles","previous_headings":"","what":"Model Structure","title":"Colossus Description","text":"full potential, Colossus can analyze vast number possible risk/rate models. Specifically, Colossus designed allow combination linear non-linear models estimate Cox proportional hazard ratios, Poisson model rates, Fine-Gray Competing risk ratios. simplest exponential model. simplest model generally used hazard ratios survival analysis exponential linear function covariates. R(β→,x→)=exp(β→⋅x→) \\begin{aligned}     R(\\vec{\\beta},\\vec{x})=\\exp(\\vec{\\beta} \\cdot \\vec{x}) \\end{aligned} Colossus, general model extended abstracting sum product terms subterms. vignette, value calculated quantify risk event denoted risk, R, however exact meaning differs. Cox proportional hazard modeling, risk calculated hazard ratio. Poisson modeling risk calculated estimated number events per person-year. risk (RR) set formula dependent terms (TT). term formula dependent product subterms (SS). subterm function covariates (xx) parameters (α,β\\alpha,\\beta). currently five types risk models available. risk can expressed additive model (RAR_A), product additive model (RPAR_{PA}), Product additive excess model (RPAER_{PAE}), multiplicative relative model (RMR_M), multiplicative excess model (RMER_{}), geometric mixture model relative risks excess risks (RGMIXR_{GMIX}). RA=∑=0nTiRPA=T0×∑=1nTiRPAE=T0×(1+∑=1nTi)RM=T0×∏=1n(Ti)RME=T0×∏=1n(1+Ti)RGMIX=T0×(∏=1n(Ti*))θ×(1+∑=1n(Ti*−1))1−θTi*={TiRelative RiskTi+1Excess Risk \\begin{aligned}     R_{} &= \\sum_{=0}^n T_i\\\\     R_{PA} &= T_0 \\times \\sum_{=1}^n T_i\\\\     R_{PAE} &= T_0 \\times (1 + \\sum_{=1}^n T_i)\\\\     R_{M} &= T_0 \\times \\prod_{=1}^n(T_i)\\\\     R_{} &= T_0 \\times \\prod_{=1}^n( 1 + T_i)\\\\     R_{GMIX} &= T_0 \\times \\left(\\prod_{=1}^n(T^{*}_i) \\right) ^ \\theta \\times \\left( 1 + \\sum_{=1}^n (T^{*}_i - 1) \\right)^{1-\\theta}\\\\     T^{*}_i &= \\begin{cases} T_i &\\text{Relative Risk} \\\\ T_i+1 &\\text{Excess Risk} \\end{cases}\\\\ \\end{aligned} term composed combination 4 types subterms. Every covariate part log-linear subterm, linear subterm, product-linear subterm, general non-linear term. log-linear subterm (SLLS_{LL}) exponential linear combination covariates. linear subterm (SLS_L) linear combination covariates. product-linear subterm (SPLS_{PL}) one plus linear combination covariates. general non-linear term (SNLS_{NL}) sum exponential terms, quadratic terms, linear-threshold terms (FLTF_{LT}), step function terms (FSTPF_{STP}), linear-quadratic terms (FLQF_{LQ}), linear-exponential terms (FLEXPF_{LEXP}). term product non-empty subterms. SLL=∏(exp(xi⋅βi))SL=∑(xi⋅βi)SPL=1+∑(xi⋅βi)SNL=∑(αi×exp(xi⋅βi))+∑(βi⋅(xi)2)+∑iFLT+∑iFSTP+∑iFLQ+∑iFLEXPFLT={αi⋅(x−βi)(x>βi)0elseFSTP={αi(x>βi)0elseFLQ={βi⋅x(x>αi)λi⋅x2+νielseFLEXP={βi⋅x(x>αi)λi−exp(νi+μ⋅x)elseTj=SLL,j×SL,j×SPL,j×SNL,j \\begin{aligned}     S_{LL}&=\\prod_{} (\\exp{(x_i \\cdot \\beta_i)})\\\\     S_{L}&=\\sum_i (x_i \\cdot \\beta_i)\\\\     S_{PL}&=1+ \\sum (x_i \\cdot \\beta_i)\\\\     S_{NL}&=\\sum_i (\\alpha_i \\times \\exp(x_i \\cdot \\beta_i)) + \\sum_i (\\beta_i \\cdot (x_i)^2)\\\\     & + \\sum_i F_{LT} + \\sum_i F_{STP} + \\sum_i F_{LQ} + \\sum_i F_{LEXP}\\\\     F_{LT} &= \\begin{cases} \\alpha_i \\cdot (x-\\beta_i) & (x>\\beta_i) \\\\ 0 &\\text{else} \\end{cases}\\\\     F_{STP} &= \\begin{cases} \\alpha_i & (x>\\beta_i) \\\\ 0 &\\text{else} \\end{cases}\\\\     F_{LQ} &= \\begin{cases} \\beta_i \\cdot x & (x>\\alpha_i) \\\\ \\lambda_i \\cdot x^2 + \\nu_i &\\text{else} \\end{cases}\\\\     F_{LEXP} &= \\begin{cases} \\beta_i \\cdot x & (x>\\alpha_i) \\\\ \\lambda_i - \\exp{(\\nu_i + \\mu \\cdot x)} &\\text{else} \\end{cases}\\\\     T_j&=S_{LL,j} \\times S_{L,j} \\times S_{PL,j} \\times S_{NL,j} \\end{aligned} short, every element risk model subterm type, term number, covariate, parameter value.","code":""},{"path":"/articles/Starting-Description.html","id":"using-the-standard-model","dir":"Articles","previous_headings":"","what":"Using The Standard Model","title":"Colossus Description","text":"Colossus, every equation defined similar fashion. Elements risk equation can viewed rows table: columns store covariate names, term numbers, subterms types, starting point. complex regression parameters can also set remain constant regression. forces parameter value constant remove element risk calculations. Constant elements used risk calculation used calculating steps standard deviations. multiplicative excess risk model, following table equation equivalent. R=exp(βa⋅xa)×(1+βb⋅xb+βc⋅xc) \\begin{aligned}     R = \\exp{(\\beta_{} \\cdot x_{})} \\times (1+\\beta_{b} \\cdot x_{b} + \\beta_{c} \\cdot x_{c}) \\end{aligned} user wanted update model include new term product-linear subterm, table need updated new row. R=exp(βa⋅xa)×(1+(βb⋅xb+βc⋅xc))×(2+βd⋅xd) \\begin{aligned}     R = \\exp{(\\beta_{} \\cdot x_{})} \\times (1 + (\\beta_{b} \\cdot x_{b} + \\beta_{c} \\cdot x_{c})) \\times (2 + \\beta_{d} \\cdot x_{d}) \\end{aligned} Note multiplicative excess model taking product terms, product subterms. equation may written subterms distributed different terms multiplicative model without changing final value. exception subterms moved “first” term multiplicative excess model. equation expressed ways different computational complexity. Models Colossus passed form formula. subterm model expressed element formula. model identifiers (, M, PA, PAE, GMIX) included end formula. Every model except additive multiplicative models distinction first remaining terms. Colossus defaults term 0 unique term. final table also equivalent following code. Interior colossus functions convert vectors formula representations. names denotes column names used, term_n denotes term numbers, tform denotes subterm formula, modelform denotes term formula, a_n denotes initial guesses parameter values. assumed order. function called regression reorders inputs order terms, subterm types, etc.","code":"names <- c(\"a\", \"b\", \"c\", \"d\") term_n <- c(0, 1, 1, 2) tform <- c(\"loglin\", \"lin\", \"lin\", \"plin\") modelform <- \"M\"  a_n <- c(0.1, 0.1, 0.1, 0.1)  model <- outcome ~ loglinear(a, 0) + linear(b, c, 1) +   plinear(d, 2) + ME()"},{"path":"/articles/Starting-Description.html","id":"survival-time-and-event-data","dir":"Articles","previous_headings":"","what":"Survival Time and Event Data","title":"Colossus Description","text":"Colossus performs survival analysis via either Cox Proportional Hazards Poisson model regression. cases, user specifies columns contain time duration events interest. Poisson model regression, column contains person-years number events row data. Cox Proportional Hazards regression, user identifies columns provide starting ending times, column gives event status. event status assumed binary covariate 1 intervals containing event. Colossus supports left-censored data, right-censored data, interval-censored data. data interval censored default, left right censoring handled defining interval endpoints outside minimum maximum event times. Poisson model regression user provides columns person-years per row number events. Poisson model regression supports non-negative number events. user side, names columns containing time events need given. Let us assume dataframe organized follows: Cox proportional hazard, need provide three column names: starting age, ending age, event happened interval. case “Starting_Age”, “Ending_Age”, “Cancer_Status”. example, interval data may always case. Colossus designed allow user omit interval columns represent truncation. Colossus assumes means person missing endpoint outside available data range creates dummy column reference interval endpoint. formula, interval endpoints can named “tstart” “tend”. code, variables look like : Suppose instead interested Poisson model regression, difference instead providing interval endpoints give column interval lengths. Suppose now working following table: just provide duration column event column, “Person_Years” “Cancer_Status”. code looks like following: regression types added formula left-hand side. Similar Surv function survival library, left-hand side formula specifies type model time/event columns used.","code":"df <- data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1) ) # For the interval case tstart <- \"Starting_Age\" tend <- \"Ending_Age\" event <- \"Cancer_Status\" df$Person_Years <- df$Ending_Age - df$Starting_Age pyr <- \"Person_Years\" event <- \"Cancer_Status\" # For the interval case RHS <- Cox(Starting_Age, Ending_Age, Cancer_Status) ~ risk_factors  # Supposing we had left truncated data the following would change RHS <- Cox(tstart = Starting_Age, event = Cancer_Status) ~ risk_factors  # and with right truncated data the following is used RHS <- Cox(Ending_Age, Cancer_Status) ~ risk_factors"},{"path":"/articles/Starting-Description.html","id":"control-and-verbosity","dir":"Articles","previous_headings":"","what":"Control and Verbosity","title":"Colossus Description","text":"Colossus offers several options control input data used returned. can split two general categories. first category convergence parameters. cover number iterations used, limits parameter changes, stopping criteria. second category parameters used debugging additional information. common convergence parameters follows: previous options contained within list parameters, however, additional standalone parameters control convergence. common example keep_constant can used hold parameters constant. keep_constant can assigned vector 0/1 element denote free (0) constant (1) parameters. Going back example, code may look like following: example, parameters held constant 100 iterations 5 half-steps used. errors unused control parameters used, simply ignored. Every commonly required control parameter default value automatically used declared.","code":"keep_constant <- c(0, 0, 0, 0)  control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiter\" = 100, \"halfmax\" = 5, \"epsilon\" = 1e-3,   \"dbeta_max\" = 0.5, \"deriv_epsilon\" = 1e-3, \"step_max\" = 1.0,   \"verbose\" = 2 )"},{"path":"/articles/Starting-Description.html","id":"running-the-regression-and-output","dir":"Articles","previous_headings":"","what":"Running the Regression and Output","title":"Colossus Description","text":"Finally, user calls regression function need. names used throughout vignette defaults assumed. Cox PH regression Poisson model regression called directly return list results. Colossus contains suite additional checks runs inputs starting calculations, designed output explicit details issues. Printing error details may require verbose option TRUE. code, functions called follows: following output regression output lists: case, poisson regression converge. Given examples arbitrary unexpected. Poisson model regression exited due step limit threshold, means score still changing significantly even low step sizes. find better solution user likely either change model equation provide new starting guess lower step size limit. example interpret results Colossus run. additional variants functions described greater detail vignettes.","code":"# assuming the table of covariates is stored in a data.table \"df\"  model_cox <- Cox(Starting_Age, Ending_Age, Cancer_Status) ~ loglinear(a, 0) +   linear(b, c, 1) + plinear(d, 2) + multiplicative()  e <- CoxRun(model_cox, df, a_n = a_n, control = control) print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Term Number Central Estimate Standard Error 2-tail p-value #>       <char>  <char>       <int>            <num>          <num>          <num> #> 1:         a  loglin           0             31.1        1079824          1.000 #> 2:         b     lin           1             14.4            NaN            NaN #> 3:         c     lin           1             14.4            NaN            NaN #> 4:         d    plin           2             31.1            477          0.948 #>  #> Cox Model Used #> -2*Log-Likelihood: 1.374,  AIC: 9.374 #> Iterations run: 30 #> maximum step size: 1.000e+00, maximum first derivative: 9.764e-04 #> Analysis converged #> Run finished in 0.025 seconds #> |-------------------------------------------------------------------|  # or a Poisson model regression model_pois <- Poisson(Person_Years, Cancer_Status)  ~ loglinear(a, 0) + linear(b, c, 1) + plinear(d, 2) + multiplicative() e <- PoisRun(model_pois, df, a_n = a_n, control = control) print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Term Number Central Estimate Standard Error 2-tail p-value #>       <char>  <char>       <int>            <num>          <num>          <num> #> 1:         a  loglin           0         -0.29681        1.10226       7.88e-01 #> 2:         b     lin           1         -0.01166        0.04784       8.07e-01 #> 3:         c     lin           1          0.00725        0.00993       4.65e-01 #> 4:         d    plin           2         -0.84726        0.19126       9.42e-06 #>  #> Poisson Model Used #> -2*Log-Likelihood: 11.992,  Deviation: 7.992,  AIC: 15.992,  BIC: 19.776 #> Iterations run: 5 #> maximum step size: 9.766e-04, maximum first derivative: 4.346e+02 #> Analysis did not converge, check convergence criteria or run further #> Run finished in 0.012 seconds #> |-------------------------------------------------------------------|"},{"path":"/articles/Time_Dep_Cov.html","id":"general-usage","dir":"Articles","previous_headings":"","what":"General Usage","title":"Time Dependent Covariate Use","text":"Cox Proportional Hazards regression, model generally assumed independent event time. However, complex models, Colossus can perform regressions using covariates change time. can split two general types covariates, step functions changing time multiplicative interactions time. Colossus generates new dataset splitting row original dataset smaller intervals. assumes interval values every covariate approximately constant. Cox Proportional Hazards, rows contain event time used regression, Colossus option use small intervals around event time. option, time-dependent covariate evaluated event times. data-sets small number discrete event times, can save time memory.","code":""},{"path":"/articles/Time_Dep_Cov.html","id":"multiplicative-interaction","dir":"Articles","previous_headings":"","what":"Multiplicative Interaction","title":"Time Dependent Covariate Use","text":"simplest type time-dependent covariate interaction term time another covariate. Suppose row dataset factor covariate “group” arbitrary endpoints time interval. Colossus starts using user-provided function calculate value time-dependent covariate endpoints. assume value “group” constant interval time changing linearly. Colossus calculates value time-dependent covariate intervals linearly interpolating values endpoints. process assumes interaction linear interval small enough interaction approximately linear. Linear Interpolated Function Y(x)=x2+1 \\begin{aligned}     Y(x)=x^2 + 1 \\end{aligned} helpful situation user continuous data series intervals believes values can interpolated within interval.","code":"dft <- data.table(\"x\" = c(1, 2, 3), \"y\" = c(2, 5, 10)) g <- ggplot2::ggplot(dft, ggplot2::aes(x = .data$x, y = .data$y)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::geom_line(color = \"black\", alpha = 1) +   ggplot2::labs(x = \"age (days)\", y = \"Covariate Value\") x <- seq(1, 3, by = 0.1) y <- 1 + x^2 dft <- data.table(\"x\" = x, \"y\" = y) g <- g + ggplot2::geom_line(   data = dft, ggplot2::aes(x = .data$x, y = .data$y),   color = \"black\", linetype = \"dashed\" ) g"},{"path":"/articles/Time_Dep_Cov.html","id":"step-function-interaction","dir":"Articles","previous_headings":"","what":"Step Function Interaction","title":"Time Dependent Covariate Use","text":"second type time-dependent covariate changes based conditional statements. One example covariate split data bins time. Colossus uses string identify change value. user inputs string form “#l?” time value “#”, condition “l”, question mark delimiter. Colossus allows four conditions: l: less equal g: greater equal : strictly b: strictly following equivalent “0g?6g?12g?0g?6g?12g?” Monotonic Step Function Applied Y(x)={0(x<0)1(6>x≥0)2(12>x≥6)3(x≥12) \\begin{aligned}     Y(x)=\\begin{cases} 0 &(x < 0) \\\\ 1 & ( 6 > x \\ge 0) \\\\ 2 &(12 > x \\ge 6) \\\\ 3 &(x \\ge 12) \\end{cases}\\\\ \\end{aligned} Meanwhile following equivalent “0g?6g?12l?0g?6g?12l?” Step Function Applied Y(x)={1(x<0)2(6>x≥0)3(12>x≥6)2(x≥12) \\begin{aligned}     Y(x)=\\begin{cases} 1 &(x < 0) \\\\ 2 & (6 > x \\ge 0) \\\\ 3 &(12 > x \\ge 6) \\\\ 2 &(x \\ge 12) \\end{cases}\\\\ \\end{aligned} helpful situations user reason believe effect covariate events uniform time despite covariate constant interval. allows user generate list factors interact covariate interest.","code":"dft <- data.table(\"x\" = c(-1, 1, 5, 8, 13), \"y\" = c(0, 1, 1, 2, 3)) g <- ggplot2::ggplot(dft, ggplot2::aes(x = .data$x, y = .data$y)) +   ggplot2::geom_point(color = \"black\") dft <- data.table(\"x\" = c(-1, -0.01, 0, 1, 5.99, 6, 11.99, 12, 13), \"y\" = c(0, 0, 1, 1, 1, 2, 2, 3, 3)) g <- g + ggplot2::geom_line(data = dft, ggplot2::aes(x = .data$x, y = .data$y), color = \"black\") +   ggplot2::labs(x = \"age (days)\", y = \"Covariate Value\") g dft <- data.table(\"x\" = c(-1, 1, 5, 8, 13), \"y\" = c(1, 2, 2, 3, 2)) g <- ggplot2::ggplot(dft, ggplot2::aes(x = .data$x, y = .data$y)) +   ggplot2::geom_point(color = \"black\") dft <- data.table(\"x\" = c(-1, -0.01, 0, 1, 5.99, 6, 11.99, 12, 13), \"y\" = c(1, 1, 2, 2, 2, 3, 3, 2, 2)) g <- g + ggplot2::geom_line(data = dft, ggplot2::aes(x = .data$x, y = .data$y), color = \"black\") +   ggplot2::labs(x = \"age (days)\", y = \"Covariate Value\") g"},{"path":"/articles/Time_Dep_Cov.html","id":"examples-of-use","dir":"Articles","previous_headings":"","what":"Examples of Use","title":"Time Dependent Covariate Use","text":"following provide basic example method listed . start setting data, example cancer data R survival package. first example linearly interpolate product time biological sex. Linear Interpolation Example second example use step functions increases 200, 500, 700 days. Monotonic Step Function Example third example use step functions increases 200, 400, 700 days decreases 600 800 days. Step Function Example","code":"# Setting up the data for use data(cancer, package = \"survival\") cancer %>% setDT() df <- copy(cancer)  df$UserID <- seq_len(nrow(df))  df$status <- df$status - 1 df$sex <- df$sex - 1  t0 <- \"%trunc%\" t1 <- \"time\" event <- \"status\"  df <- df[, c(\"time\", \"status\", \"sex\", \"UserID\")] grt_f <- function(df, time_col) {   return((df[, \"sex\"] * df[, get(time_col)] / 400)[[1]]) } func_form <- c(\"lin\") iscox <- TRUE dt <- 0.01 df_new <- gen_time_dep(   df, t0, t1, event, iscox, dt, c(\"sex_time\"), c(),   c(grt_f), \"test_new.csv\", func_form,   nthreads = 1 )  g <- ggplot2::ggplot(df_new, ggplot2::aes(x = .data$time, y = .data$sex_time, colour = factor(.data$sex))) +   ggplot2::geom_point() +   ggplot2::geom_line() +   ggplot2::labs(x = \"Time\", y = \"Covariate Value\") g func_form <- c(\"step?0g?200g?500g?700g?\") df_new <- gen_time_dep(   df, t0, t1, event, iscox, dt, c(\"time_step\"), c(),   c(grt_f), \"test_new.csv\", func_form,   nthreads = 1 ) g <- ggplot2::ggplot(df_new, ggplot2::aes(x = .data$time, y = .data$time_step)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::geom_line() +   ggplot2::labs(x = \"Time\", y = \"Covariate Value\") g func_form <- c(\"step?0g?200g?400g?600l?700g?800b?\") df_new <- gen_time_dep(   df, t0, t1, event, iscox, dt, c(\"time_step\"), c(),   c(grt_f), \"test_new.csv\", func_form,   nthreads = 1 ) g <- ggplot2::ggplot(df_new, ggplot2::aes(x = .data$time, y = .data$time_step)) +   ggplot2::geom_point(color = \"black\") +   ggplot2::geom_line() +   ggplot2::labs(x = \"Time\", y = \"Covariate Value\") g"},{"path":"/articles/Wald_and_Log_Bound.html","id":"available-methods","dir":"Articles","previous_headings":"","what":"Available Methods","title":"Confidence Interval Selection","text":"Colossus supports two methods calculating confidence interval model parameters Cox proportional hazards models. Wald method likelihood-based boundary method. vignette focused differences issues may arise.","code":""},{"path":"/articles/Wald_and_Log_Bound.html","id":"wald-method","dir":"Articles","previous_headings":"Available Methods","what":"Wald Method","title":"Confidence Interval Selection","text":"Colossus finishes Cox regression, returns parameter estimates standard errors. simplest form confidence interval assuming normal distribution parameter mean deviation. standard errors calculated covariance matrix, calculated line equation expected information matrix presented 32-bit Epicure manual. covariance matrix calculated using inverse expected information matrix (II). derivation outlined end vignette clarity. every event time (ii) number events (did_i) list subjects risk (l∈Ril \\R_i). Every valid combination subject event time hazard ratio (rlir_{li}) partial derivative hazard ratio respect parameter (β\\beta). equation used compute covariance matrix standard errors returned Colossus default. (βμ,βν)=∑=1N(di*[∑l∈RicliμcliνrliEi−FiμFiνEi2])cliμ=bliμrli,bliμ=∂rli∂βμ,Ei=∑l∈Rirli,Fiμ=∑l∈Ribliμ \\begin{aligned}     (\\beta_\\mu, \\beta_\\nu) = \\sum_{=1}^{N} \\left ( d_i * \\left[ \\sum_{l \\R_i} \\frac{c_{li}^{\\mu} c_{li}^{\\nu} r_{li}}{E_i} - \\frac{F_i^{\\mu} F_i^{\\nu}}{E_i^2} \\right] \\right )\\\\     c_{li}^{\\mu} = \\frac{b_{li}^{\\mu}}{r_{li}}, \\quad b_{li}^{\\mu} = \\frac{\\partial r_{li}}{\\partial \\beta_{\\mu}}, \\quad E_{} = \\sum_{l \\R_i} r_{li}, \\quad F_i^{\\mu} = \\sum_{l \\R_i} b_{li}^{\\mu} \\end{aligned} gives symmetric parameter confidence interval often accurate single-term log-linear models. However, approximation often inaccurate models linear effects, particularly confidence interval includes negative values. Wald method approximates likelihood confidence interval, guarantee model defined interval.","code":""},{"path":"/articles/Wald_and_Log_Bound.html","id":"likelihood-based-bound","dir":"Articles","previous_headings":"Available Methods","what":"Likelihood-Based Bound","title":"Confidence Interval Selection","text":"exact solution directly solve boundary. basic premise model can optimized single parameter (β\\beta) fixed. value β\\beta corresponding maximum log-likelihood. confidence interval range values β\\beta maximum log-likelihood threshold, taken asymptotic χ2\\chi^2 distribution generalized likelihood ratio test. Colossus uses Venzon-Moolgavkar algorithm iteratively solve interval endpoints. one main issue can arise method: uses Newton-Raphson algorithm, may solve local solutions instead global solution. Similar general Colossus regressions, limitations can placed step size limit effects. However, analog selecting multiple starting locations. basis alternatives provided can directly solve true optimum. Methods implemented optimize multiple points apply bisection method instead derivative-based method. method directly solves confidence interval, linear cases may non-symmetric even upper lower bounds. Linear models may defined parameter threshold. optimum value parameter threshold χ2\\chi^2 threshold value, interval lower bound.","code":""},{"path":"/articles/Wald_and_Log_Bound.html","id":"example-and-comparison","dir":"Articles","previous_headings":"Available Methods","what":"Example and Comparison","title":"Confidence Interval Selection","text":"sake comparison, consider analysis capacitor data available survival package. Consider two regressions, one fully exponential one linear effect. regressions converge similar scores. Next, suppose interested confidence intervals. Suppose want 95% confidence intervals Wald likelihood-based boundaries parameters model. Let us start fully exponential model. Wald boundary estimated using central estimates standard deviations. Likelihood boundary solved using LikelihoodBound function applied result. parameter number needs provided (indexed starting one) alpha level needs provided. Overall, Wald likelihood-based boundaries . boundaries temperature (-0.017, 1.537) (-0.01, 1.560), boundaries voltage (0.800, 3.177) (0.841, 3.242). two boundaries less 0.1. Next, analyze model linear effect. expect predictions . boundaries temperature (0.105, 1.796) (0.129, 1.840), boundaries voltage (-3.32, 20.95) (1.97, 34.472). estimates temperature voltage boundaries much .","code":"data(reliability, package = \"survival\") capacitor %>% setDT() df <- copy(capacitor)  df$voltage <- (df$voltage - 200) / 150 df$temperature <- (df$temperature - 170) / 10 df$time <- (df$time - 216) / (1105 - 216)  control <- list(\"Ncores\" = 1, \"maxiter\" = 100, \"verbose\" = 2)  a_n <- c(0.01, 0.01)  e1 <- CoxRun(Cox(time, status) ~ loglinear(temperature, voltage, 0), df,   a_n = a_n, control = control ) print(e1, 5) #> |-------------------------------------------------------------------| #> Final Results #>      Covariate Subterm Central Estimate Standard Error 2-tail p-value #>         <char>  <char>            <num>          <num>          <num> #> 1: temperature  loglin          0.75995        0.39644      0.0552490 #> 2:     voltage  loglin          1.98839        0.60631      0.0010399 #>  #> Cox Model Used #> -2*Log-Likelihood: 210.77792,  AIC: 214.77792 #> Iterations run: 8 #> maximum step size: 5.90475e-05, maximum first derivative: 5.22560e-05 #> Analysis converged #> Run finished in 0.02624 seconds #> |-------------------------------------------------------------------|  e2 <- CoxRun(Cox(time, status) ~ loglinear(temperature, 0) + plinear(voltage, 0),   df,   a_n = a_n, control = control ) print(e2, 5) #> |-------------------------------------------------------------------| #> Final Results #>      Covariate Subterm Central Estimate Standard Error 2-tail p-value #>         <char>  <char>            <num>          <num>          <num> #> 1: temperature  loglin          0.95035         0.4313       0.027563 #> 2:     voltage    plin          8.81720         6.1906       0.154362 #>  #> Cox Model Used #> -2*Log-Likelihood: 208.49028,  AIC: 212.49028 #> Iterations run: 13 #> maximum step size: 2.57874e-03, maximum first derivative: 3.62470e-05 #> Analysis converged #> Run finished in 0.02513 seconds #> |-------------------------------------------------------------------| names <- c(\"temperature\", \"voltage\") tform <- c(\"loglin\", \"loglin\") ci_1 <- c(   e1$beta_0[1] - 1.96 * e1$Standard_Deviation[1],   e1$beta_0[1] + 1.96 * e1$Standard_Deviation[1] ) ci_2 <- c(   e1$beta_0[2] - 1.96 * e1$Standard_Deviation[2],   e1$beta_0[2] + 1.96 * e1$Standard_Deviation[2] )   curve_control <- list(   \"maxstep\" = 100,   \"alpha\" = 0.05,   \"para_number\" = 1, \"manual\" = TRUE ) e <- LikelihoodBound(e1, df, curve_control, control = control) print(\"|------------------- Wald Estimate -------------------|\") #> [1] \"|------------------- Wald Estimate -------------------|\" print(ci_1) #> [1] -0.01708172  1.53697802 print(e, 5) #> |-------------------------------------------------------------------| #> Likelihood Boundary Results #> Solving for the boundary of element: 1 #> Applied to column: 'temperature' #> Subterm: loglin #> Term number: 0 #> Lower limit converged to at -0.0098967 at a score of -107.30968 with of goal of -107.30969 #> Central estimate was 0.75995 #> Upper limit converged to at 1.5599 at a score of -107.30968 with of goal of -107.30969 #> Run finished in 0.00845 seconds #> |-------------------------------------------------------------------|  curve_control <- list(   \"maxstep\" = 100,   \"alpha\" = 0.05,   \"para_number\" = 2, \"manual\" = TRUE ) e <- LikelihoodBound(e1, df, curve_control, control = control) print(\"|------------------- Likelihood Bound Estimate -------------------|\") #> [1] \"|------------------- Likelihood Bound Estimate -------------------|\" print(ci_2) #> [1] 0.8000252 3.1767554 print(e, 5) #> |-------------------------------------------------------------------| #> Likelihood Boundary Results #> Solving for the boundary of element: 2 #> Applied to column: 'voltage' #> Subterm: loglin #> Term number: 0 #> Lower limit converged to at 0.84124 at a score of -107.30968 with of goal of -107.30969 #> Central estimate was 1.9884 #> Upper limit converged to at 3.242 at a score of -107.30968 with of goal of -107.30969 #> Run finished in 0.00772 seconds #> |-------------------------------------------------------------------| ci_1 <- c(   e2$beta_0[1] - 1.96 * e2$Standard_Deviation[1],   e2$beta_0[1] + 1.96 * e2$Standard_Deviation[1] ) ci_2 <- c(   e2$beta_0[2] - 1.96 * e2$Standard_Deviation[2],   e2$beta_0[2] + 1.96 * e2$Standard_Deviation[2] )  curve_control <- list(   \"maxstep\" = 100,   \"alpha\" = 0.05,   \"para_number\" = 1, \"manual\" = TRUE ) e <- LikelihoodBound(e2, df, curve_control, control = control) print(\"|------------------- Wald Estimate -------------------|\") #> [1] \"|------------------- Wald Estimate -------------------|\" print(ci_1) #> [1] 0.1049977 1.7956959 print(e, 5) #> |-------------------------------------------------------------------| #> Likelihood Boundary Results #> Solving for the boundary of element: 1 #> Applied to column: 'temperature' #> Subterm: loglin #> Term number: 0 #> Lower limit converged to at 0.12897 at a score of -106.16586 with of goal of -106.16587 #> Central estimate was 0.95035 #> Upper limit converged to at 1.8401 at a score of -106.16587 with of goal of -106.16587 #> Run finished in 0.00846 seconds #> |-------------------------------------------------------------------|  a_n <- c(1.138152, 1.988403) curve_control <- list(   \"maxstep\" = 100,   \"alpha\" = 0.05,   \"para_number\" = 2, \"manual\" = TRUE ) e <- LikelihoodBound(e2, df, curve_control, control = control) print(\"|------------------- Wald Estimate -------------------|\") #> [1] \"|------------------- Wald Estimate -------------------|\" print(ci_2) #> [1] -3.316339 20.950734 print(e, 5) #> |-------------------------------------------------------------------| #> Likelihood Boundary Results #> Solving for the boundary of element: 2 #> Applied to column: 'voltage' #> Subterm: plin #> Term number: 0 #> Lower limit converged to at 1.9709 at a score of -106.16585 with of goal of -106.16587 #> Central estimate was 8.8172 #> Upper limit converged to at 34.472 at a score of -106.16587 with of goal of -106.16587 #> Run finished in 0.00878 seconds #> |-------------------------------------------------------------------|"},{"path":"/articles/Wald_and_Log_Bound.html","id":"illustration-of-issues-with-likelihood-boundary-algorithm","dir":"Articles","previous_headings":"Available Methods","what":"Illustration of Issues with Likelihood-Boundary Algorithm","title":"Confidence Interval Selection","text":"One important thing keep mind likelihood-based boundary algorithm perfect, times may important manually solve likelihood curve. following example outlines done details curve can cause issues boundary algorithm. following uses dataset used Colossus unit testing. linear parameter selected analysis. point grid, linear parameter fixed model optimized. important note two local optimums within small range (-0.6 global solution 1.4). algorithms used solving likelihood boundary, similar standard regression optimizing algorithm, can trapped local optimums. means algorithm point cross local optimum, can get stuck. two optimums scores close enough 95% confidence interval lower boundary -0.5, 50% confidence interval lower bound -0.5 1.4. meant algorithm converged 50% confidence interval boundary, failed converge lower boundary 95% confidence interval boundary. Development ongoing automate process solving complete likelihood curve.","code":"fname <- \"base_example.csv\" df <- fread(fname)  keep_constant <- c(0, 0, 1) a_n <- c(-1.493177, 5.020007, 1.438377) model <- Cox(entry, exit, event) ~ loglinear(dose0, dose1, 0) + linear(dose0, 1) # control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(100, 100), \"halfmax\" = 5,   \"epsilon\" = 1e-6, \"deriv_epsilon\" = 1e-6, \"step_max\" = 1.0,   \"thres_step_max\" = 100.0, \"verbose\" = 2,   \"ties\" = \"breslow\" )  v0 <- sort(c((0:50 / 50 - 1.0) * 0.8, 1:50 / 50 * 3, 1.438377, -0.5909)) for (v in v0) {   a_n <- c(-1.493177, 5.020007, v)   e <- CoxRun(model, df, a_n = a_n, control = control)   ll <- e$LogLik   beta <- e$beta_0   print(c(ll, beta[3])) } x <- c(-0.8, -0.784, -0.768, -0.752, -0.736, -0.72, -0.704, -0.688, -0.672, -0.656, -0.64, -0.624, -0.608, -0.592, -0.5909, -0.576, -0.56, -0.544, -0.528, -0.512, -0.496, -0.48, -0.464, -0.448, -0.432, -0.416, -0.4, -0.384, -0.368, -0.352, -0.336, -0.32, -0.304, -0.288, -0.272, -0.256, -0.24, -0.224, -0.208, -0.192, -0.176, -0.16, -0.144, -0.128, -0.112, -0.096, -0.08, -0.064, -0.048, -0.032, -0.016, 0.0, 0.06, 0.12, 0.18, 0.24, 0.3, 0.36, 0.42, 0.48, 0.54, 0.6, 0.66, 0.72, 0.78, 0.84, 0.9, 0.96, 1.02, 1.08, 1.14, 1.2, 1.26, 1.32, 1.38, 1.438377, 1.44, 1.5, 1.56, 1.62, 1.68, 1.74, 1.8, 1.86, 1.92, 1.98, 2.04, 2.1, 2.16, 2.22, 2.28, 2.34, 2.4, 2.46, 2.52, 2.58, 2.64, 2.7, 2.76, 2.82, 2.88, 2.94, 3.0) y <- c(-18500.53, -18499.829, -18499.273, -18498.831, -18498.482, -18498.21, -18497.995, -18497.832, -18497.71, -18497.621, -18497.56, -18497.519, -18497.498, -18497.49, -18497.4904, -18497.495, -18497.51, -18497.53, -18497.558, -18497.589, -18497.624, -18497.66, -18497.7, -18497.739, -18497.779, -18497.818, -18497.86, -18497.896, -18497.933, -18497.969, -18498.003, -18498.04, -18498.067, -18498.096, -18498.124, -18498.15, -18498.17, -18498.196, -18498.216, -18498.235, -18498.252, -18498.27, -18498.281, -18498.292, -18498.303, -18498.311, -18498.32, -18498.324, -18498.329, -18498.332, -18498.334, -18498.33, -18498.33, -18498.31, -18498.27, -18498.23, -18498.18, -18498.13, -18498.07, -18498.01, -18497.96, -18497.9, -18497.84, -18497.78, -18497.73, -18497.68, -18497.63, -18497.59, -18497.56, -18497.52, -18497.49, -18497.47, -18497.45, -18497.44, -18497.43, -18497.429487, -18497.43, -18497.43, -18497.44, -18497.45, -18497.47, -18497.5, -18497.52, -18497.56, -18497.6, -18497.64, -18497.69, -18497.74, -18497.8, -18497.86, -18497.93, -18498.0, -18498.07, -18498.15, -18498.23, -18498.32, -18498.41, -18498.5, -18498.6, -18498.7, -18498.81, -18498.92, -18499.03)  df <- data.table(\"x\" = x, \"y\" = y)  g <- ggplot2::ggplot(df, ggplot2::aes(x = .data$x, y = .data$y)) +   ggplot2::geom_line(color = \"black\", alpha = 1, \"linewidth\" = 1.5) +   ggplot2::labs(x = \"Linear Parameter Value\", y = \"Log-Likelihood\") +   ggplot2::ggtitle(\"Multi-Peak Curve\") g"},{"path":"/articles/Wald_and_Log_Bound.html","id":"likelihood-boundary-algorithm-alternative","dir":"Articles","previous_headings":"Available Methods","what":"Likelihood Boundary Algorithm Alternative","title":"Confidence Interval Selection","text":"three functions available calculating likelihood-based boundaries. first method standard Venzon-Moolgavkar algorithm. method attempts optimize model guide desired parameter boundary value. method fastest, susceptible local extrema. Using algorithm depends initial step close local extrema, initial step can scaled . second method modification Venzon-Moolgavkar algorithm. second method, initial step split multiple guesses, guess optimized independently. Venzon-Moolgavkar algorithm continued closest guess exceed target likelihood. theory, method makes likely algorithm start appropriate point, slower slightly less susceptible local extrema. However final portion algorithm still based derivatives, still susceptible local extrema. third method iterative bisection method. algorithm, desired parameter fixed, model optimized endpoints interval interval located contains goal likelihood. interval split half interval width within user-set limit. method takes advantage fact likelihood curve continuous know optimum point must goal. algorithm split two steps: optimizing model fixed points determining interval contains goal. second step depend likelihood derivatives, prone getting stuck local extrema. However, interval width must small enough step solution. Given small enough interval width, every optimization likely converge solution unlikely skipped. method requires model optimized repeatedly, expected take longest. However, bisection method least likely issues converging.","code":"fname <- \"base_example.csv\" df <- fread(fname)  model <- Cox(entry, exit, event) ~ loglinear(dose0, dose1, 0) + linear(dose0, 1) keep_constant <- c(0, 0, 0) a_n <- c(-1.493177, 5.020007, 1.438377) # control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiter\" = 100, \"halfmax\" = 5,   \"verbose\" = 2 ) coxres <- CoxRun(model, df, a_n = a_n, control = control)  curve_control <- list(\"maxstep\" = 20, \"alpha\" = 0.005, \"para_number\" = 3, \"step_size\" = 0.5, \"bisect\" = TRUE) e <- LikelihoodBound(coxres, df, curve_control, control = control)"},{"path":"/articles/Wald_and_Log_Bound.html","id":"expected-information-matrix-derivation","dir":"Articles","previous_headings":"","what":"Expected Information Matrix Derivation","title":"Confidence Interval Selection","text":"expected information matrix calculated using two equations, second derivative log-likelihood probability subject event given rows risk number events. begin, second derivative log-likelihood expressed follows: ∂2LL∂β→μ∂β→ν=∑=1N[δi([Ai,μ,ν−Bi,μ*Bi,ν]−[Ci,μ,ν−Di,μ*Di,ν])]Ai,μ,ν=∂2ri∂β→μ∂β→νri,Bi,μ=∂ri∂β→μriCi,μ,ν=∑l∈Ri∂2rl∂β→μ∂β→νEi,Di,μ=∑l∈Ri∂rl∂β→μEi,Ei=∑l∈Rirl \\begin{aligned}     \\frac{\\partial^2 LL}{\\partial \\vec{\\beta}_{\\mu} \\partial \\vec{\\beta}_{\\nu}} = \\sum_{=1}^N \\left[ \\delta_i \\left( [A_{,\\mu,\\nu} - B_{,\\mu}*B_{,\\nu} ] - [C_{,\\mu,\\nu} - D_{,\\mu}*D_{,\\nu} ]  \\right)\\right]\\\\     A_{,\\mu,\\nu} = \\frac{\\frac{\\partial^2 r_i}{\\partial \\vec{\\beta}_\\mu \\partial \\vec{\\beta}_\\nu}}{r_i}, \\quad B_{,\\mu} = \\frac{\\frac{\\partial r_i}{\\partial \\vec{\\beta}_\\mu}}{r_i} \\\\     C_{,\\mu,\\nu} = \\frac{\\sum_{l \\R_i} \\frac{\\partial^2 r_l}{\\partial \\vec{\\beta}_\\mu \\partial \\vec{\\beta}_\\nu}}{E_i},\\quad D_{,\\mu} = \\frac{\\sum_{l \\R_i} \\frac{\\partial r_l}{\\partial \\vec{\\beta}_\\mu}}{E_i}, \\quad E_{} = \\sum_{l \\R_i} r_l \\\\ \\end{aligned} Next, assume independent failure censoring, dd events risk group RR. Assuming row risk approximately equal background rate, probability given subject event follows: pr(δi=1|d,R,β)=ri/∑l∈Rrl \\begin{aligned}     pr(\\delta_i = 1 | d,R, \\beta) = r_i / \\sum_{l \\R} r_l \\end{aligned} Finally, want evaluate expected information matrix given following: (μ,ν)=E[−∂2LL∂β→μ∂β→ν] \\begin{aligned}     (\\mu, \\nu) = E \\left[-\\frac{\\partial^2 LL}{\\partial \\vec{\\beta}_{\\mu} \\partial \\vec{\\beta}_{\\nu}} \\right] \\end{aligned} can start splitting equation expected contribution event time (ii) simplifying expected value constant terms. Note switch event indicator row (δi\\delta_i) number events risk group (did_i): (μ,ν)=−E[∑k∈Ri(δk([Ai,μ,ν−Bi,μ*Bi,ν]−[Ci,μ,ν−Di,μ*Di,ν]))](μ,ν)=di*[Ci,μ,ν−Di,μ*Di,ν]−E[∑k∈Ri(δk([Ai,μ,ν−Bi,μ*Bi,ν]))]E[∑k∈RiδkAi,μ,ν]=∑l∈RiAl,μ,ν*pr(δl=1)=di*∑l∈Ri∂2rl∂β→μ∂β→νrl*rl∑l∈Rirl=di*Ci,μ,νE[Bi,μ*Bi,ν]=∑l∈RiBi,μ*Bi,ν*pr(δl=1)=di*∑l∈Riclμclνrl∑l∈Rirl \\begin{aligned}     (\\mu, \\nu)_i = - E \\left[ \\sum_{k \\R_i} \\left ( \\delta_k \\left( [A_{,\\mu,\\nu} - B_{,\\mu}*B_{,\\nu} ] - [C_{,\\mu,\\nu} - D_{,\\mu}*D_{,\\nu} ]  \\right) \\right )\\right] \\\\     (\\mu, \\nu)_i = d_i*[C_{,\\mu,\\nu} - D_{,\\mu}*D_{,\\nu} ] - E \\left [ \\sum_{k \\R_i} \\left ( \\delta_k \\left( [A_{,\\mu,\\nu} - B_{,\\mu}*B_{,\\nu} ] \\right ) \\right ) \\right] \\\\     E \\left [ \\sum_{k \\R_i} \\delta_k A_{,\\mu,\\nu} \\right] = \\sum_{l \\R_i} A_{l,\\mu,\\nu} * pr(\\delta_l = 1) = d_i * \\frac{\\sum_{l \\R_i} \\frac{\\frac{\\partial^2 r_l}{\\partial \\vec{\\beta}_\\mu \\partial \\vec{\\beta}_\\nu}}{r_l} * r_l}{ \\sum_{l \\R_i} r_l} = d_i * C_{,\\mu,\\nu}\\\\     E \\left [ B_{,\\mu}*B_{,\\nu} \\right] = \\sum_{l \\R_i} B_{,\\mu}*B_{,\\nu}*pr(\\delta_l = 1) = d_i * \\frac{\\sum_{l \\R_i} c_{l}^{\\mu}c_{l}^{\\nu}r_l}{\\sum_{l \\R_i} r_l} \\end{aligned} Finally, substitute, cancel, use function definitions expected information matrix derived observed information matrix formula. (μ,ν)=di*[∑l∈RicliμcliνrliEi−FiμFiνEi2] \\begin{aligned}     (\\mu, \\nu)_i = d_i * \\left[ \\sum_{l \\R_i} \\frac{c_{li}^{\\mu} c_{li}^{\\nu} r_{li}}{E_i} - \\frac{F_i^{\\mu} F_i^{\\nu}}{E_i^2} \\right] \\end{aligned}","code":""},{"path":"/articles/count_time_tables.html","id":"general-purpose","dir":"Articles","previous_headings":"","what":"General Purpose","title":"Generating Person-Count and Person-Time Tables","text":"performing regression rate hazard ratio, often important look summary data. can informative break columns categories summarize number events average column values category. Colossus offers two functions designed create summary tables, Event_Count_Gen Event_Time_Gen create person-count tables person-time tables respectively. following sections cover generally use function different needs met.","code":""},{"path":"/articles/count_time_tables.html","id":"person-count-tables","dir":"Articles","previous_headings":"General Purpose","what":"Person-Count Tables","title":"Generating Person-Count and Person-Time Tables","text":"person count table simplest way summarize table. assumes columns want break categories columns want summarize. Let us start basic example. Suppose dataset tracking number apples oranges people bought, number hands used carry bag, whether bag ripped . Suppose want split dataset number fruit, count number ripped bags category, figure average number hands used. start defining want split categories. two general ways define intervals, single string list upper lower bounds. Let us start string representation. string expected alternate number delimiter, either “/” “]”, split upper lower bounds interval. Every interval format includes lower bound. interval includes upper bound “]” used, otherwise. interval [2,5) equivalent “2/5” interval [5,8] equivalent “5]8”. method uses triplet sequentially, categories cover every value falls first last number listed. list notation similar. 2 values required list 1 optional value. list vectors titled lower upper, lower upper bounds interval. method can include gaps. Similarly string version, lower bound always included upper bound included upper bound entry includes “]”. list option allows categories labeled instead automatically numbered. third list titled name can provided label category. Suppose want break apple column intervals: [0, 3), [3, 5), [5,7] break oranges column intervals: [-1,3), [3,6), [6,10) labels: , good, excessive. look like following code. splits category 3 levels total 9 combinations. Now define summary variables want. , define list. Every item list named column applied contains string specifying summary method use. two options supported currently: count mean, provide sum mean column category. One can also provide new name summary column listing method “option name”. Otherwise, grouped table use original column name summary column name. Suppose wanted take sum ripped bags name “dropped” take mean hands column. final step run function. function returns two items, grouped data summary category intervals. category intervals checked verify intervals match expected.","code":"apples <- c(0, 1, 2, 3, 4, 5, 6, 2, 2, 3, 4, 2, 1, 5, 6, 4, 2) oranges <- c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1, 3, 2, 2, 1) rip <- c(0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1) hands <- c(1, 1, 2, 3, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2) table <- data.table::data.table(   \"apples\" = apples,   \"oranges\" = oranges,   \"rip\" = rip,   \"hands\" = hands ) apple_category <- \"0/3/5]7\" orange_category <- list(   lower = c(-1, 3, 6),   upper = c(3, 6, 10),   name = c(\"few\", \"good\", \"excessive\") ) categ <- list(   \"apples\" = apple_category,   \"oranges\" = orange_category ) event <- list(\"rip\" = \"count AS dropped\", \"hands\" = \"mean\") Event_Count_Gen(table, categ, event) #> $df #>    apples_category oranges_category COUNT dropped hands #>             <char>           <char> <int>   <num> <num> #> 1:               1                1     8       3  1.50 #> 2:               2                2     5       3  2.00 #> 3:               3                3     4       3  1.25 #>  #> $bounds #> $bounds$apples_category #> [1] \" [0, 3) [3, 5) [5, 7]\" #>  #> $bounds$oranges_category #> [1] \" [-1, 3) [3, 6) [6, 10)\""},{"path":"/articles/count_time_tables.html","id":"person-time-tables","dir":"Articles","previous_headings":"General Purpose","what":"Person-Time Tables","title":"Generating Person-Count and Person-Time Tables","text":"previous method treats every row weighted . many cases, every row measure time may want use. fundamental difference person count tables person time tables, inclusion time. code used generate person time table similar person count table, several important differences. first data time columns. Similar Cox model options Colossus, data entry column, exit column, . denote scenario every interval ends point, starts point, different start stop times. method currently supports day/month/year information combined complete dates. Event_Time_Gen function uses list input time columns. list entry exit items needed, list column name year, month, day columns needed. dates default 1/1/1900 provided. person-year list can also contain unit, defaulted years. second major difference possible use time categories. Time categories set vectors day, month, year interval splitting point. intervals changing every 2 days expressed “day=c(1,3,5,…)”. Time categories unique row can correspond multiple time categories, duration row time category kept distinguish rows partially time interval. time category provided, full duration row used person-year calculations. final difference person-time tables make distinction events summaries. summary list nearly identical event list person-count function. difference weighted_mean option added. mean group weighted person-years. event list person-time table function used determine time categories event columns assigned . Based relative row intervals category intervals, row can part multiple time categories. However, event assigned time category containing endpoint row interval. Finally, function run. Similar person-count table function, function returns grouped table list category boundaries.","code":"a <- c(0, 1, 2, 3, 4, 5, 6, 2, 2, 3, 4, 2, 1, 5, 6, 4, 2) b <- c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1, 3, 2, 2, 1) c <- c(0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1)  d <- c(1, 1, 2, 2, 1, 1, 2, 2, 3, 3, 3, 4, 4, 2, 1, 1, 2) e <- c(1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1) f <- c(   1900, 1900, 1900, 1900, 1900, 1900, 1900, 1900, 1900,   1900, 1900, 1900, 1900, 1900, 1900, 1900, 1900 ) g <- c(4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 5, 5, 5, 4, 4, 4, 4) h <- c(6, 4, 4, 6, 6, 6, 4, 4, 4, 6, 6, 6, 6, 4, 4, 4, 4) i <- c(   1901, 1902, 1903, 1904, 1905, 1906, 1907, 1903, 1904,   1903, 1904, 1910, 1903, 1904, 1903, 1904, 1910 ) table <- data.table::data.table(   \"a\" = a, \"b\" = b, \"c\" = c,   \"d\" = d, \"e\" = e, \"f\" = f,   \"g\" = g, \"h\" = h, \"i\" = i )  pyr <- list(   entry = list(year = \"f\", month = \"e\", day = \"d\"),   exit = list(year = \"i\", month = \"h\", day = \"g\"),   unit = \"years\" ) categ <- list(   \"a\" = \"-1/3/5]7\",   \"b\" = list(     lower = c(-1, 3, 6), upper = c(3, 6, 10),     name = c(\"low\", \"medium\", \"high\")   ),   \"time AS time_bin\" = list(     \"day\" = c(1, 1, 1),     \"month\" = c(1, 1, 1),     \"year\" = c(1899, 1903, 1910)   ) ) summary <- list(\"c\" = \"count AS cases\", \"b\" = \"weighted_mean AS b_weighted\") events <- list(\"c\") pyr <- list(   entry = list(year = \"f\", month = \"e\", day = \"d\"),   exit = list(year = \"i\", month = \"h\", day = \"g\"),   unit = \"years\" ) print(Event_Time_Gen(table, pyr, categ, summary, events, T)) #> $df #>     a_category b_category time_bin AT_RISK        PYR cases b_weighted #>         <char>     <char>   <char>   <int>      <num> <num>      <num> #>  1:          1       high        1       1  2.9952088     0   6.000000 #>  2:          1       high        2       1  0.2600958     0   6.000000 #>  3:          1        low        1       5 12.4791239     1   1.413339 #>  4:          1        low        2       3 14.4257358     0   1.485291 #>  5:          1     medium        1       2  5.9876797     0   3.999543 #>  6:          1     medium        2       2  1.5167693     1   4.664260 #>  7:          2        low        1       1  2.9979466     0   2.000000 #>  8:          2        low        2       1  1.2566735     0   2.000000 #>  9:          2     medium        1       4 11.8083504     0   3.993276 #> 10:          2     medium        2       4  5.7056810     3   4.175144 #> 11:          3       high        1       2  5.8234086     0   6.499765 #> 12:          3       high        2       2  7.6824093     2   6.554170 #> 13:          3        low        1       1  2.9130732     0   2.000000 #> 14:          3        low        2       1  0.2546201     1   2.000000 #> 15:          3     medium        1       1  2.9103354     0   3.000000 #> 16:          3     medium        2       1  1.2566735     0   3.000000 #>  #> $bounds #> $bounds$a_category #> [1] \" [-1, 3) [3, 5) [5, 7]\" #>  #> $bounds$b_category #> [1] \" [-1, 3) [3, 6) [6, 10)\" #>  #> $bounds$time_bin #> [1] \" [1899-01-01 to 1903-01-01] [1903-01-01 to 1910-01-01]\" pyr <- list(   entry = list(year = \"f\", month = \"e\", day = \"d\"),   exit = list(year = \"i\", month = \"h\", day = \"g\"),   unit = \"months\" ) print(Event_Time_Gen(table, pyr, categ, summary, events, T)) #> $df #>     a_category b_category time_bin AT_RISK        PYR cases b_weighted #>         <char>     <char>   <char>   <int>      <num> <num>      <num> #>  1:          1       high        1       1  35.942505     0   6.000000 #>  2:          1       high        2       1   3.121150     0   6.000000 #>  3:          1        low        1       5 149.749487     1   1.413339 #>  4:          1        low        2       3 173.108830     0   1.485291 #>  5:          1     medium        1       2  71.852156     0   3.999543 #>  6:          1     medium        2       2  18.201232     1   4.664260 #>  7:          2        low        1       1  35.975359     0   2.000000 #>  8:          2        low        2       1  15.080082     0   2.000000 #>  9:          2     medium        1       4 141.700205     0   3.993276 #> 10:          2     medium        2       4  68.468172     3   4.175144 #> 11:          3       high        1       2  69.880903     0   6.499765 #> 12:          3       high        2       2  92.188912     2   6.554170 #> 13:          3        low        1       1  34.956879     0   2.000000 #> 14:          3        low        2       1   3.055441     1   2.000000 #> 15:          3     medium        1       1  34.924025     0   3.000000 #> 16:          3     medium        2       1  15.080082     0   3.000000 #>  #> $bounds #> $bounds$a_category #> [1] \" [-1, 3) [3, 5) [5, 7]\" #>  #> $bounds$b_category #> [1] \" [-1, 3) [3, 6) [6, 10)\" #>  #> $bounds$time_bin #> [1] \" [1899-01-01 to 1903-01-01] [1903-01-01 to 1910-01-01]\" pyr <- list(   entry = list(year = \"f\", month = \"e\", day = \"d\"),   exit = list(year = \"i\", month = \"h\", day = \"g\"),   unit = \"days\" ) print(Event_Time_Gen(table, pyr, categ, summary, events, T)) #> $df #>     a_category b_category time_bin AT_RISK   PYR cases b_weighted #>         <char>     <char>   <char>   <int> <num> <num>      <num> #>  1:          1       high        1       1  1094     0   6.000000 #>  2:          1       high        2       1    95     0   6.000000 #>  3:          1        low        1       5  4558     1   1.413339 #>  4:          1        low        2       3  5269     0   1.485291 #>  5:          1     medium        1       2  2187     0   3.999543 #>  6:          1     medium        2       2   554     1   4.664260 #>  7:          2        low        1       1  1095     0   2.000000 #>  8:          2        low        2       1   459     0   2.000000 #>  9:          2     medium        1       4  4313     0   3.993276 #> 10:          2     medium        2       4  2084     3   4.175144 #> 11:          3       high        1       2  2127     0   6.499765 #> 12:          3       high        2       2  2806     2   6.554170 #> 13:          3        low        1       1  1064     0   2.000000 #> 14:          3        low        2       1    93     1   2.000000 #> 15:          3     medium        1       1  1063     0   3.000000 #> 16:          3     medium        2       1   459     0   3.000000 #>  #> $bounds #> $bounds$a_category #> [1] \" [-1, 3) [3, 5) [5, 7]\" #>  #> $bounds$b_category #> [1] \" [-1, 3) [3, 6) [6, 10)\" #>  #> $bounds$time_bin #> [1] \" [1899-01-01 to 1903-01-01] [1903-01-01 to 1910-01-01]\""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Eric Giunta. Author, maintainer. Amir Bahadori. Contributor. Dan Andresen. Contributor. Linda Walsh. Contributor. Benjamin French. Contributor. Lawrence Dauer. Contributor. John Boice Jr. Contributor. Kansas State University. Copyright holder. NASA. Funder. NCRP. Funder. NRC. Funder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Giunta E, Bahadori , Andresen D, Walsh L, French B, Dauer L, Boice Jr J (2025). Colossus: Risk Model Regression Analysis Complex Non-Linear Models. https://github.com/ericgiunta/Colossus. Giunta E, Stutzman D, Cohen S, French B, Walsh L, Dauer L, Boice Jr J, Blattnig S, Andresen D, Bahadori (2025). “Colossus: Software radiation epidemiologic studies big data.” Journal Radiological Protection, 45(2). doi:10.1088/1361-6498/adcd80, https://iopscience.iop.org/article/10.1088/1361-6498/adcd80.","code":"@Manual{,   title = {Colossus: Risk Model Regression and Analysis with Complex Non-Linear Models},   author = {Eric Giunta and Amir Bahadori and Dan Andresen and Linda Walsh and Benjamin French and Lawrence Dauer and John {Boice Jr}},   year = {2025},   url = {https://github.com/ericgiunta/Colossus}, } @Article{,   title = {Colossus: Software for radiation epidemiologic studies with big data},   author = {Eric Giunta and Dawson Stutzman and Sarah Cohen and Benjamin French and Linda Walsh and Lawrence Dauer and John {Boice Jr} and Steve Blattnig and Dan Andresen and Amir Bahadori},   year = {2025},   url = {https://iopscience.iop.org/article/10.1088/1361-6498/adcd80},   publisher = {IOP Publishing},   doi = {10.1088/1361-6498/adcd80},   volume = {45},   number = {2},   journal = {Journal of Radiological Protection}, }"},{"path":"/index.html","id":"colossus","dir":"","previous_headings":"","what":"","title":"","text":"goal Colossus provide open-source means performing survival analysis big data complex risk formulas. Colossus designed perform Cox Proportional Hazard regressions Poisson regressions datasets loaded data.tables data.frames. risk models allowed sums products linear, log-linear, several radiation dose response formulas highlighted vignettes. Additional plotting capabilities available. default, fully portable version code compiled, support OpenMP every system. Note Colossus requires OpenMP support perform parallel calculations. environment variable “R_COLOSSUS_NOT_CRAN” checked determine OpenMP disabled linux compiling clang. number cores set 1 environment variable empty, operating system detected linux, default compiler R compiler clang. Colossus testing checks “NOT_CRAN” variable determine additional tests run. Setting “NOT_CRAN” “false” disable longer tests. Currently, OpenMP support configured linux compiling clang. Note: versions 1.3.1 1.4.1 expected inputs changed. Regressions now run CoxRun PoisRun formula inputs. Please see “Unified Equation Representation” vignette details.","code":""},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"","text":"basic example shows solve common problem:","code":"library(data.table) library(parallel) library(Colossus) ## basic example code reproduced from the starting-description vignette  df <- data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1) )  model <- Cox(Starting_Age, Ending_Age, Cancer_Status) ~ loglinear(a, 0) + linear(b, c, 1) + plinear(d, 2) + multiplicative()  a_n <- c(0.1, 0.1, 0.1, 0.1)  keep_constant <- c(0, 0, 0, 0)  control <- list(   \"lr\" = 0.75, \"maxiter\" = 100, \"halfmax\" = 5, \"epsilon\" = 1e-9,   \"deriv_epsilon\" = 1e-9, \"step_max\" = 1.0,   \"verbose\" = 2, \"ties\" = \"breslow\" )  e <- CoxRun(model, df, a_n = a_n, control = control) print(e) #> |-------------------------------------------------------------------| #> Final Results #>    Covariate Subterm Term Number Central Estimate Standard Error 2-tail p-value #>       <char>  <char>       <int>            <num>          <num>          <num> #> 1:         a  loglin           0         21.67085            NaN            NaN #> 2:         b     lin           1          0.10000            NaN            NaN #> 3:         c     lin           1          0.10000            NaN            NaN #> 4:         d    plin           2          0.10000            Inf              1 #>  #> Cox Model Used #> -2*Log-Likelihood: 2.64,  AIC: 10.64 #> Iterations run: 27 #> maximum step size: 7.50e-01, maximum first derivative: 5.49e-10 #> Analysis converged #> Run finished in 0.04 seconds #> |-------------------------------------------------------------------|"},{"path":"/reference/CaseControlRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully runs a case-control regression model, returning the model and results — CaseControlRun","title":"Fully runs a case-control regression model, returning the model and results — CaseControlRun","text":"CaseControlRun uses formula, data.table, list controls prepare run Colossus matched case-control regression function","code":""},{"path":"/reference/CaseControlRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully runs a case-control regression model, returning the model and results — CaseControlRun","text":"","code":"CaseControlRun(   model,   df,   a_n = list(c(0)),   keep_constant = c(0),   control = list(),   conditional_threshold = 50,   gradient_control = list(),   single = FALSE,   observed_info = FALSE,   cons_mat = as.matrix(c(0)),   cons_vec = c(0),   norm = \"null\",   ... )"},{"path":"/reference/CaseControlRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully runs a case-control regression model, returning the model and results — CaseControlRun","text":"model either formula written get_form function, model result get_form function. df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. keep_constant binary values denote parameters change control list parameters controlling convergence, see Control_Options vignette details conditional_threshold threshold unconditional logistic regression used calculate likelihoods matched group gradient_control list control options gradient descent algorithm. value given, gradient descent algorithm used instead Newton-Raphson. See Control_Options vignette details single boolean denote log-likelihood calculated returned, derivatives iterations observed_info boolean denote observed information matrix used calculate standard error parameters, expected information matrix cons_mat Matrix containing coefficients system linear constraints, formatted matrix cons_vec Vector containing constants system linear constraints, formatted vector norm methods used normalize covariates. Default 'null' normalization. options include 'max' normalize absolute maximum 'mean' normalize mean ... can include named entries control list parameter","code":""},{"path":"/reference/CaseControlRun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully runs a case-control regression model, returning the model and results — CaseControlRun","text":"returns class fully describing model regression results","code":""},{"path":"/reference/CaseControlRun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully runs a case-control regression model, returning the model and results — CaseControlRun","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1),   \"e\" = c(0, 0, 1, 0, 0, 0, 1) ) control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(1, 1),   \"halfmax\" = 1 ) formula <- CaseCon_Strata(Cancer_Status, e) ~   loglinear(a, b, c, 0) + plinear(d, 0) + multiplicative() res <- CaseControlRun(formula, df,   a_n = list(c(1.1, -0.1, 0.2, 0.5), c(1.6, -0.12, 0.3, 0.4)),   control = control )"},{"path":"/reference/ColossusCoxSurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Interprets basic cox survival formula RHS — ColossusCoxSurv","title":"Interprets basic cox survival formula RHS — ColossusCoxSurv","text":"ColossusCoxSurv assigns interprets interval columns cox model. functions called using arguments Cox right-hand side formula. Uses interval start time, end time, event status. expected order named: tstart, tend, event. Fine-Gray Stratified versions use strata weight named options last two entries.","code":""},{"path":"/reference/ColossusCoxSurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interprets basic cox survival formula RHS — ColossusCoxSurv","text":"","code":"ColossusCoxSurv(...)"},{"path":"/reference/ColossusCoxSurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interprets basic cox survival formula RHS — ColossusCoxSurv","text":"... entries cox survival object, tstart, tend, event. Either order named. unnamed two entries, tend event assumed.","code":""},{"path":"/reference/ColossusCoxSurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interprets basic cox survival formula RHS — ColossusCoxSurv","text":"returns list interval endpoints event","code":""},{"path":[]},{"path":"/reference/ColossusLogitSurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Interprets basic logistic survival formula RHS with no grouping — ColossusLogitSurv","title":"Interprets basic logistic survival formula RHS with no grouping — ColossusLogitSurv","text":"ColossusLogitSurv assigns interprets columns trials events logistic model grouping.","code":""},{"path":"/reference/ColossusLogitSurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interprets basic logistic survival formula RHS with no grouping — ColossusLogitSurv","text":"","code":"ColossusLogitSurv(...)"},{"path":"/reference/ColossusLogitSurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interprets basic logistic survival formula RHS with no grouping — ColossusLogitSurv","text":"... entries Logistic object, trials events. trials provided assumes one trial per row.","code":""},{"path":"/reference/ColossusLogitSurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interprets basic logistic survival formula RHS with no grouping — ColossusLogitSurv","text":"returns list event","code":""},{"path":[]},{"path":"/reference/ColossusPoisSurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Interprets basic poisson survival formula RHS — ColossusPoisSurv","title":"Interprets basic poisson survival formula RHS — ColossusPoisSurv","text":"ColossusPoisSurv assigns interprets interval columns poisson model. functions called using arguments Poisson Poisson_Strata right-hand side formula. Uses person-year column, number events, strata columns. first two expected order named: pyr event. Anything beyond event name assumed strata Poisson_Strata used.","code":""},{"path":"/reference/ColossusPoisSurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interprets basic poisson survival formula RHS — ColossusPoisSurv","text":"","code":"ColossusPoisSurv(...)"},{"path":"/reference/ColossusPoisSurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interprets basic poisson survival formula RHS — ColossusPoisSurv","text":"... entries Poisson object without strata, pyr, event, strata columns. Either order named. first two assumed pyr event, rest assumed strata columns","code":""},{"path":"/reference/ColossusPoisSurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interprets basic poisson survival formula RHS — ColossusPoisSurv","text":"returns list duration, strata used, event","code":""},{"path":[]},{"path":"/reference/CoxRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully runs a cox or fine-gray regression model, returning the model and results — CoxRun","title":"Fully runs a cox or fine-gray regression model, returning the model and results — CoxRun","text":"CoxRun uses formula, data.table, list controls prepare run Colossus cox fine-gray regression function","code":""},{"path":"/reference/CoxRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully runs a cox or fine-gray regression model, returning the model and results — CoxRun","text":"","code":"CoxRun(   model,   df,   a_n = list(c(0)),   keep_constant = c(0),   control = list(),   gradient_control = list(),   single = FALSE,   observed_info = FALSE,   cons_mat = as.matrix(c(0)),   cons_vec = c(0),   norm = \"null\",   ... )"},{"path":"/reference/CoxRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully runs a cox or fine-gray regression model, returning the model and results — CoxRun","text":"model either formula written get_form function, model result get_form function. df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. keep_constant binary values denote parameters change control list parameters controlling convergence, see Control_Options vignette details gradient_control list control options gradient descent algorithm. value given, gradient descent algorithm used instead Newton-Raphson. See Control_Options vignette details single boolean denote log-likelihood calculated returned, derivatives iterations observed_info boolean denote observed information matrix used calculate standard error parameters, expected information matrix cons_mat Matrix containing coefficients system linear constraints, formatted matrix cons_vec Vector containing constants system linear constraints, formatted vector norm methods used normalize covariates. Default 'null' normalization. options include 'max' normalize absolute maximum 'mean' normalize mean ... can include named entries control list parameter","code":""},{"path":"/reference/CoxRun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully runs a cox or fine-gray regression model, returning the model and results — CoxRun","text":"returns class fully describing model regression results","code":""},{"path":[]},{"path":"/reference/CoxRun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully runs a cox or fine-gray regression model, returning the model and results — CoxRun","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1),   \"e\" = c(0, 0, 1, 0, 0, 0, 1) ) control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(1, 1),   \"halfmax\" = 1 ) formula <- Cox(Starting_Age, Ending_Age, Cancer_Status) ~   loglinear(a, b, c, 0) + plinear(d, 0) + multiplicative() res <- CoxRun(formula, df,   a_n = list(c(1.1, -0.1, 0.2, 0.5), c(1.6, -0.12, 0.3, 0.4)),   control = control )"},{"path":"/reference/CoxRunMulti.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully runs a cox or fine-gray regression model with multiple column realizations, returning the model and results — CoxRunMulti","title":"Fully runs a cox or fine-gray regression model with multiple column realizations, returning the model and results — CoxRunMulti","text":"CoxRunMulti uses formula, data.table, list controls prepare run Colossus cox fine-gray regression function","code":""},{"path":"/reference/CoxRunMulti.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully runs a cox or fine-gray regression model with multiple column realizations, returning the model and results — CoxRunMulti","text":"","code":"CoxRunMulti(   model,   df,   a_n = list(c(0)),   keep_constant = c(0),   realization_columns = matrix(c(\"temp00\", \"temp01\", \"temp10\", \"temp11\"), nrow = 2),   realization_index = c(\"temp0\", \"temp1\"),   control = list(),   gradient_control = list(),   single = FALSE,   observed_info = FALSE,   fma = FALSE,   mcml = FALSE,   cons_mat = as.matrix(c(0)),   cons_vec = c(0),   ... )"},{"path":"/reference/CoxRunMulti.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully runs a cox or fine-gray regression model with multiple column realizations, returning the model and results — CoxRunMulti","text":"model either formula written get_form function, model result get_form function. df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. keep_constant binary values denote parameters change realization_columns used multi-realization regressions. Matrix column names rows column realizations, columns realization realization_index used multi-realization regressions. Vector column names, one column realizations. name used \"names\" variable equation definition control list parameters controlling convergence, see Control_Options vignette details gradient_control list control options gradient descent algorithm. value given, gradient descent algorithm used instead Newton-Raphson. See Control_Options vignette details single boolean denote log-likelihood calculated returned, derivatives iterations observed_info boolean denote observed information matrix used calculate standard error parameters, expected information matrix fma boolean denote Frequentist Model Averaging method used mcml boolean denote Monte Carlo Maximum Likelihood method used cons_mat Matrix containing coefficients system linear constraints, formatted matrix cons_vec Vector containing constants system linear constraints, formatted vector ... can include named entries control list parameter","code":""},{"path":"/reference/CoxRunMulti.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully runs a cox or fine-gray regression model with multiple column realizations, returning the model and results — CoxRunMulti","text":"returns class fully describing model regression results","code":""},{"path":[]},{"path":"/reference/CoxRunMulti.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully runs a cox or fine-gray regression model with multiple column realizations, returning the model and results — CoxRunMulti","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"t0\" = c(18, 20, 18, 19, 21, 20, 18),   \"t1\" = c(30, 45, 57, 47, 36, 60, 55),   \"lung\" = c(0, 0, 1, 0, 1, 0, 0),   \"dose\" = c(0, 1, 1, 0, 1, 0, 1) ) set.seed(3742) df$rand <- floor(runif(nrow(df), min = 0, max = 5)) df$rand0 <- floor(runif(nrow(df), min = 0, max = 5)) df$rand1 <- floor(runif(nrow(df), min = 0, max = 5)) df$rand2 <- floor(runif(nrow(df), min = 0, max = 5)) names <- c(\"dose\", \"rand\") realization_columns <- matrix(c(\"rand0\", \"rand1\", \"rand2\"), nrow = 1) realization_index <- c(\"rand\") control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiter\" = 1,   \"halfmax\" = 2, \"epsilon\" = 1e-6,   \"deriv_epsilon\" = 1e-6, \"step_max\" = 1.0,   \"thres_step_max\" = 100.0,   \"verbose\" = 0, \"ties\" = \"breslow\", \"double_step\" = 1 ) formula <- Cox(t0, t1, lung) ~ loglinear(dose, rand, 0) + multiplicative() res <- CoxRun(formula, df, control = control)"},{"path":"/reference/Date_Shift.html","id":null,"dir":"Reference","previous_headings":"","what":"Automates creating a date difference column — Date_Shift","title":"Automates creating a date difference column — Date_Shift","text":"Date_Shift generates new dataframe column containing time difference given unit","code":""},{"path":"/reference/Date_Shift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automates creating a date difference column — Date_Shift","text":"","code":"Date_Shift(df, dcol0, dcol1, col_name, units = \"days\")"},{"path":"/reference/Date_Shift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automates creating a date difference column — Date_Shift","text":"df data.table containing columns interest dcol0 list starting month, day, year dcol1 list ending month, day, year col_name vector new column names units time unit use","code":""},{"path":"/reference/Date_Shift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automates creating a date difference column — Date_Shift","text":"returns updated dataframe","code":""},{"path":[]},{"path":"/reference/Date_Shift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automates creating a date difference column — Date_Shift","text":"","code":"library(data.table) m0 <- c(1, 1, 2, 2) m1 <- c(2, 2, 3, 3) d0 <- c(1, 2, 3, 4) d1 <- c(6, 7, 8, 9) y0 <- c(1990, 1991, 1997, 1998) y1 <- c(2001, 2003, 2005, 2006) df <- data.table::data.table(\"m0\" = m0, \"m1\" = m1, \"d0\" = d0, \"d1\" = d1, \"y0\" = y0, \"y1\" = y1) df <- Date_Shift(df, c(\"m0\", \"d0\", \"y0\"), c(\"m1\", \"d1\", \"y1\"), \"date_since\")"},{"path":"/reference/EventAssignment.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicts how many events are due to baseline vs excess — EventAssignment.default","title":"Predicts how many events are due to baseline vs excess — EventAssignment.default","text":"EventAssignment Generic background/excess event calculation function, default nothing happens","code":""},{"path":"/reference/EventAssignment.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicts how many events are due to baseline vs excess — EventAssignment.default","text":"","code":"# Default S3 method EventAssignment(x, df, ...)"},{"path":"/reference/EventAssignment.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicts how many events are due to baseline vs excess — EventAssignment.default","text":"x result object regression, class poisres df data.table containing columns interest ... extended necessary parameters","code":""},{"path":"/reference/EventAssignment.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic background/excess event calculation function — EventAssignment","title":"Generic background/excess event calculation function — EventAssignment","text":"EventAssignment Generic background/excess event calculation function","code":""},{"path":"/reference/EventAssignment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic background/excess event calculation function — EventAssignment","text":"","code":"EventAssignment(x, df, ...)"},{"path":"/reference/EventAssignment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic background/excess event calculation function — EventAssignment","text":"x result object regression, class poisres df data.table containing columns interest ... extended necessary parameters","code":""},{"path":"/reference/EventAssignment.poisres.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicts how many events are due to baseline vs excess for a completed poisson model — EventAssignment.poisres","title":"Predicts how many events are due to baseline vs excess for a completed poisson model — EventAssignment.poisres","text":"EventAssignment.poisres uses user provided data, person-year/event columns, vectors specifying model, options calculate background excess events solved Poisson regression","code":""},{"path":"/reference/EventAssignment.poisres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicts how many events are due to baseline vs excess for a completed poisson model — EventAssignment.poisres","text":"","code":"# S3 method for class 'poisres' EventAssignment(   x,   df,   assign_control = list(),   control = list(),   a_n = c(),   ... )"},{"path":"/reference/EventAssignment.poisres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicts how many events are due to baseline vs excess for a completed poisson model — EventAssignment.poisres","text":"x result object regression, class poisres df data.table containing columns interest assign_control control list bounds calculated control list parameters controlling convergence, see Control_Options vignette details a_n list initial parameter values, used determine number parameters. May either list vectors single vector. ... can include named entries assign_control list parameter","code":""},{"path":"/reference/EventAssignment.poisres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicts how many events are due to baseline vs excess for a completed poisson model — EventAssignment.poisres","text":"returns list final results","code":""},{"path":[]},{"path":"/reference/EventAssignment.poisresbound.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicts how many events are due to baseline vs excess for a completed poisson likelihood boundary regression — EventAssignment.poisresbound","title":"Predicts how many events are due to baseline vs excess for a completed poisson likelihood boundary regression — EventAssignment.poisresbound","text":"EventAssignment.poisresbound uses user provided data, person-year/event columns, vectors specifying model, options calculate background excess events solved Poisson regression","code":""},{"path":"/reference/EventAssignment.poisresbound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicts how many events are due to baseline vs excess for a completed poisson likelihood boundary regression — EventAssignment.poisresbound","text":"","code":"# S3 method for class 'poisresbound' EventAssignment(   x,   df,   assign_control = list(),   control = list(),   a_n = c(),   ... )"},{"path":"/reference/EventAssignment.poisresbound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicts how many events are due to baseline vs excess for a completed poisson likelihood boundary regression — EventAssignment.poisresbound","text":"x result object regression, class poisres df data.table containing columns interest assign_control control list bounds calculated control list parameters controlling convergence, see Control_Options vignette details a_n list initial parameter values, used determine number parameters. May either list vectors single vector. ... can include named entries assign_control list parameter","code":""},{"path":"/reference/EventAssignment.poisresbound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicts how many events are due to baseline vs excess for a completed poisson likelihood boundary regression — EventAssignment.poisresbound","text":"returns list final results","code":""},{"path":[]},{"path":"/reference/Event_Count_Gen.html","id":null,"dir":"Reference","previous_headings":"","what":"uses a table, list of categories, and list of event summaries to generate person-count tables — Event_Count_Gen","title":"uses a table, list of categories, and list of event summaries to generate person-count tables — Event_Count_Gen","text":"Event_Count_Gen generates event-count tables","code":""},{"path":"/reference/Event_Count_Gen.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"uses a table, list of categories, and list of event summaries to generate person-count tables — Event_Count_Gen","text":"","code":"Event_Count_Gen(table, categ, events, verbose = FALSE)"},{"path":"/reference/Event_Count_Gen.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"uses a table, list of categories, and list of event summaries to generate person-count tables — Event_Count_Gen","text":"table dataframe every category/event column needed categ list category columns methods, methods can either strings lists boundaries events list columns summarize, supports counts means renaming summary column verbose integer valued 0-4 controlling information printed terminal. level includes lower levels. 0: silent, 1: errors printed, 2: warnings printed, 3: notes printed, 4: debug information printed. Errors situations stop regression, warnings situations assume default values user might intended, notes provide information regression progress, debug prints C++ progress intermediate results. default level 2 True/False converted 3/0.","code":""},{"path":"/reference/Event_Count_Gen.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"uses a table, list of categories, and list of event summaries to generate person-count tables — Event_Count_Gen","text":"returns grouped table list category boundaries used","code":""},{"path":[]},{"path":"/reference/Event_Count_Gen.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"uses a table, list of categories, and list of event summaries to generate person-count tables — Event_Count_Gen","text":"","code":"library(data.table) a <- c(0, 1, 2, 3, 4, 5, 6) b <- c(1, 2, 3, 4, 5, 6, 7) c <- c(0, 1, 0, 0, 0, 1, 0) table <- data.table::data.table(   \"a\" = a,   \"b\" = b,   \"c\" = c ) categ <- list(   \"a\" = \"0/3/5]7\",   \"b\" = list(     lower = c(-1, 3, 6),     upper = c(3, 6, 10),     name = c(\"low\", \"medium\", \"high\")   ) ) event <- list(   \"c\" = \"count AS cases\",   \"a\" = \"mean\", \"b\" = \"mean\" ) e <- Event_Count_Gen(table, categ, event, T)"},{"path":"/reference/Event_Time_Gen.html","id":null,"dir":"Reference","previous_headings":"","what":"uses a table, list of categories, list of summaries, list of events, and person-year information to generate person-time tables — Event_Time_Gen","title":"uses a table, list of categories, list of summaries, list of events, and person-year information to generate person-time tables — Event_Time_Gen","text":"Event_Time_Gen generates event-time tables","code":""},{"path":"/reference/Event_Time_Gen.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"uses a table, list of categories, list of summaries, list of events, and person-year information to generate person-time tables — Event_Time_Gen","text":"","code":"Event_Time_Gen(table, pyr, categ, summaries, events, verbose = FALSE)"},{"path":"/reference/Event_Time_Gen.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"uses a table, list of categories, list of summaries, list of events, and person-year information to generate person-time tables — Event_Time_Gen","text":"table dataframe every category/event column needed pyr list entry exit lists, containing day/month/year columns table categ list category columns methods, methods can either strings lists boundaries, includes time category entry/exit required pyr list summaries list columns summarize, supports counts, means, weighted means person-year renaming summary column events list events interests, checks events within time interval verbose integer valued 0-4 controlling information printed terminal. level includes lower levels. 0: silent, 1: errors printed, 2: warnings printed, 3: notes printed, 4: debug information printed. Errors situations stop regression, warnings situations assume default values user might intended, notes provide information regression progress, debug prints C++ progress intermediate results. default level 2 True/False converted 3/0.","code":""},{"path":"/reference/Event_Time_Gen.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"uses a table, list of categories, list of summaries, list of events, and person-year information to generate person-time tables — Event_Time_Gen","text":"returns grouped table list category boundaries used","code":""},{"path":[]},{"path":"/reference/Event_Time_Gen.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"uses a table, list of categories, list of summaries, list of events, and person-year information to generate person-time tables — Event_Time_Gen","text":"","code":"library(data.table) a <- c(0, 1, 2, 3, 4, 5, 6) b <- c(1, 2, 3, 4, 5, 6, 7) c <- c(0, 1, 0, 0, 0, 1, 0) d <- c(1, 2, 3, 4, 5, 6, 7) e <- c(2, 3, 4, 5, 6, 7, 8) f <- c(   1900, 1900, 1900, 1900,   1900, 1900, 1900 ) g <- c(1, 2, 3, 4, 5, 6, 7) h <- c(2, 3, 4, 5, 6, 7, 8) i <- c(   1901, 1902, 1903, 1904,   1905, 1906, 1907 ) table <- data.table::data.table(   \"a\" = a, \"b\" = b, \"c\" = c,   \"d\" = d, \"e\" = e, \"f\" = f,   \"g\" = g, \"h\" = h, \"i\" = i ) categ <- list(   \"a\" = \"-1/3/5]7\" ) summary <- list(   \"c\" = \"count AS cases\" ) events <- list(\"c\") pyr <- list(   entry = list(year = \"f\"),   exit = list(year = \"i\"),   unit = \"years\" ) e <- Event_Time_Gen(table, pyr, categ, summary, events)"},{"path":"/reference/Joint_Multiple_Events.html","id":null,"dir":"Reference","previous_headings":"","what":"Automates creating data for a joint competing risks analysis — Joint_Multiple_Events","title":"Automates creating data for a joint competing risks analysis — Joint_Multiple_Events","text":"Joint_Multiple_Events generates input regression multiple non-independent events models","code":""},{"path":"/reference/Joint_Multiple_Events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automates creating data for a joint competing risks analysis — Joint_Multiple_Events","text":"","code":"Joint_Multiple_Events(   df,   events,   name_list,   term_n_list = list(),   tform_list = list(),   keep_constant_list = list(),   a_n_list = list() )"},{"path":"/reference/Joint_Multiple_Events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automates creating data for a joint competing risks analysis — Joint_Multiple_Events","text":"df data.table containing columns interest events vector event column names name_list list vectors columns event specific shared model elements, required term_n_list list vectors term numbers event specific shared model elements, defaults term 0 tform_list list vectors subterm types event specific shared model elements, defaults loglinear keep_constant_list list vectors constant elements event specific shared model elements, defaults free (0) a_n_list list vectors parameter values event specific shared model elements, defaults term 0","code":""},{"path":"/reference/Joint_Multiple_Events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automates creating data for a joint competing risks analysis — Joint_Multiple_Events","text":"returns updated dataframe model inputs","code":""},{"path":[]},{"path":"/reference/Joint_Multiple_Events.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automates creating data for a joint competing risks analysis — Joint_Multiple_Events","text":"","code":"library(data.table) a <- c(0, 0, 0, 1, 1, 1) b <- c(1, 1, 1, 2, 2, 2) c <- c(0, 1, 2, 2, 1, 0) d <- c(1, 1, 0, 0, 1, 1) e <- c(0, 1, 1, 1, 0, 0) df <- data.table(\"t0\" = a, \"t1\" = b, \"e0\" = c, \"e1\" = d, \"fac\" = e) time1 <- \"t0\" time2 <- \"t1\" df$pyr <- df$t1 - df$t0 pyr <- \"pyr\" events <- c(\"e0\", \"e1\") names_e0 <- c(\"fac\") names_e1 <- c(\"fac\") names_shared <- c(\"t0\", \"t0\") term_n_e0 <- c(0) term_n_e1 <- c(0) term_n_shared <- c(0, 0) tform_e0 <- c(\"loglin\") tform_e1 <- c(\"loglin\") tform_shared <- c(\"quad_slope\", \"loglin_top\") keep_constant_e0 <- c(0) keep_constant_e1 <- c(0) keep_constant_shared <- c(0, 0) a_n_e0 <- c(-0.1) a_n_e1 <- c(0.1) a_n_shared <- c(0.001, -0.02) name_list <- list(\"shared\" = names_shared, \"e0\" = names_e0, \"e1\" = names_e1) term_n_list <- list(\"shared\" = term_n_shared, \"e0\" = term_n_e0, \"e1\" = term_n_e1) tform_list <- list(\"shared\" = tform_shared, \"e0\" = tform_e0, \"e1\" = tform_e1) keep_constant_list <- list(   \"shared\" = keep_constant_shared,   \"e0\" = keep_constant_e0, \"e1\" = keep_constant_e1 ) a_n_list <- list(\"shared\" = a_n_shared, \"e0\" = a_n_e0, \"e1\" = a_n_e1) val <- Joint_Multiple_Events(   df, events, name_list, term_n_list,   tform_list, keep_constant_list, a_n_list )"},{"path":"/reference/LikelihoodBound.coxres.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the likelihood boundary for a completed cox model — LikelihoodBound.coxres","title":"Calculates the likelihood boundary for a completed cox model — LikelihoodBound.coxres","text":"LikelihoodBound.coxres solves confidence interval cox model, starting optimum point iteratively optimizing end-points intervals.","code":""},{"path":"/reference/LikelihoodBound.coxres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the likelihood boundary for a completed cox model — LikelihoodBound.coxres","text":"","code":"# S3 method for class 'coxres' LikelihoodBound(x, df, curve_control = list(), control = list(), ...)"},{"path":"/reference/LikelihoodBound.coxres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the likelihood boundary for a completed cox model — LikelihoodBound.coxres","text":"x result object regression, class coxres df data.table containing columns interest curve_control list control options likelihood boundary regression. See Control_Options vignette details. control list parameters controlling convergence, see Control_Options vignette details ... can include named entries curve_control list parameter","code":""},{"path":"/reference/LikelihoodBound.coxres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the likelihood boundary for a completed cox model — LikelihoodBound.coxres","text":"returns list final results","code":""},{"path":[]},{"path":"/reference/LikelihoodBound.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic likelihood boundary calculation function, default option — LikelihoodBound.default","title":"Generic likelihood boundary calculation function, default option — LikelihoodBound.default","text":"LikelihoodBound Generic likelihood boundary calculation function, default nothing happens","code":""},{"path":"/reference/LikelihoodBound.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic likelihood boundary calculation function, default option — LikelihoodBound.default","text":"","code":"# Default S3 method LikelihoodBound(x, df, curve_control = list(), control = list(), ...)"},{"path":"/reference/LikelihoodBound.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic likelihood boundary calculation function, default option — LikelihoodBound.default","text":"x result object regression, class coxres poisres df data.table containing columns interest curve_control list control options likelihood boundary regression. See Control_Options vignette details. control list parameters controlling convergence, see Control_Options vignette details ... extended necessary parameters","code":""},{"path":"/reference/LikelihoodBound.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic likelihood boundary calculation function — LikelihoodBound","title":"Generic likelihood boundary calculation function — LikelihoodBound","text":"LikelihoodBound Generic likelihood boundary calculation function","code":""},{"path":"/reference/LikelihoodBound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic likelihood boundary calculation function — LikelihoodBound","text":"","code":"LikelihoodBound(x, df, curve_control = list(), control = list(), ...)"},{"path":"/reference/LikelihoodBound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic likelihood boundary calculation function — LikelihoodBound","text":"x result object regression, class coxres poisres df data.table containing columns interest curve_control list control options likelihood boundary regression. See Control_Options vignette details. control list parameters controlling convergence, see Control_Options vignette details ... extended necessary parameters","code":""},{"path":"/reference/LikelihoodBound.poisres.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the likelihood boundary for a completed Poisson model — LikelihoodBound.poisres","title":"Calculates the likelihood boundary for a completed Poisson model — LikelihoodBound.poisres","text":"LikelihoodBound.poisres solves confidence interval Poisson model, starting optimum point iteratively optimizing end-points intervals.","code":""},{"path":"/reference/LikelihoodBound.poisres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the likelihood boundary for a completed Poisson model — LikelihoodBound.poisres","text":"","code":"# S3 method for class 'poisres' LikelihoodBound(x, df, curve_control = list(), control = list(), ...)"},{"path":"/reference/LikelihoodBound.poisres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the likelihood boundary for a completed Poisson model — LikelihoodBound.poisres","text":"x result object regression, class poisres df data.table containing columns interest curve_control list control options likelihood boundary regression. See Control_Options vignette details. control list parameters controlling convergence, see Control_Options vignette details ... can include named entries curve_control list parameter","code":""},{"path":"/reference/LikelihoodBound.poisres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the likelihood boundary for a completed Poisson model — LikelihoodBound.poisres","text":"returns list final results","code":""},{"path":[]},{"path":"/reference/Likelihood_Ratio_Test.html","id":null,"dir":"Reference","previous_headings":"","what":"Defines the likelihood ratio test — Likelihood_Ratio_Test","title":"Defines the likelihood ratio test — Likelihood_Ratio_Test","text":"Likelihood_Ratio_Test uses two models calculates ratio","code":""},{"path":"/reference/Likelihood_Ratio_Test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Defines the likelihood ratio test — Likelihood_Ratio_Test","text":"","code":"Likelihood_Ratio_Test(alternative_model, null_model)"},{"path":"/reference/Likelihood_Ratio_Test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Defines the likelihood ratio test — Likelihood_Ratio_Test","text":"alternative_model new model interest list form, output Poisson regression null_model model compare , list form","code":""},{"path":"/reference/Likelihood_Ratio_Test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Defines the likelihood ratio test — Likelihood_Ratio_Test","text":"returns score statistic","code":""},{"path":"/reference/Likelihood_Ratio_Test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Defines the likelihood ratio test — Likelihood_Ratio_Test","text":"","code":"library(data.table) # In an actual example, one would run two seperate RunCoxRegression regressions, #    assigning the results to e0 and e1 e0 <- list(\"name\" = \"First Model\", \"LogLik\" = -120) e1 <- list(\"name\" = \"New Model\", \"LogLik\" = -100) score <- Likelihood_Ratio_Test(e1, e0)"},{"path":"/reference/Linked_Dose_Formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates Full Parameter list for Special Dose Formula — Linked_Dose_Formula","title":"Calculates Full Parameter list for Special Dose Formula — Linked_Dose_Formula","text":"Linked_Dose_Formula Calculates parameters linear-quadratic linear-exponential linked formulas","code":""},{"path":"/reference/Linked_Dose_Formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates Full Parameter list for Special Dose Formula — Linked_Dose_Formula","text":"","code":"Linked_Dose_Formula(tforms, paras, verbose = 0)"},{"path":"/reference/Linked_Dose_Formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates Full Parameter list for Special Dose Formula — Linked_Dose_Formula","text":"tforms list formula types paras list formula parameters verbose integer valued 0-4 controlling information printed terminal. level includes lower levels. 0: silent, 1: errors printed, 2: warnings printed, 3: notes printed, 4: debug information printed. Errors situations stop regression, warnings situations assume default values user might intended, notes provide information regression progress, debug prints C++ progress intermediate results. default level 2 True/False converted 3/0.","code":""},{"path":"/reference/Linked_Dose_Formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates Full Parameter list for Special Dose Formula — Linked_Dose_Formula","text":"returns list full parameters","code":""},{"path":"/reference/Linked_Dose_Formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates Full Parameter list for Special Dose Formula — Linked_Dose_Formula","text":"","code":"library(data.table) tforms <- list(\"cov_0\" = \"quad\", \"cov_1\" = \"exp\") paras <- list(\"cov_0\" = c(1, 3.45), \"cov_1\" = c(1.2, 4.5, 0.1)) full_paras <- Linked_Dose_Formula(tforms, paras)"},{"path":"/reference/Linked_Lin_Exp_Para.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates The Additional Parameter For a linear-exponential formula with known maximum — Linked_Lin_Exp_Para","title":"Calculates The Additional Parameter For a linear-exponential formula with known maximum — Linked_Lin_Exp_Para","text":"Linked_Lin_Exp_Para Calculates additional parameter desired maximum","code":""},{"path":"/reference/Linked_Lin_Exp_Para.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates The Additional Parameter For a linear-exponential formula with known maximum — Linked_Lin_Exp_Para","text":"","code":"Linked_Lin_Exp_Para(y, a0, a1_goal, verbose = 0)"},{"path":"/reference/Linked_Lin_Exp_Para.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates The Additional Parameter For a linear-exponential formula with known maximum — Linked_Lin_Exp_Para","text":"y point formula switch a0 linear slope a1_goal exponential maximum desired verbose integer valued 0-4 controlling information printed terminal. level includes lower levels. 0: silent, 1: errors printed, 2: warnings printed, 3: notes printed, 4: debug information printed. Errors situations stop regression, warnings situations assume default values user might intended, notes provide information regression progress, debug prints C++ progress intermediate results. default level 2 True/False converted 3/0.","code":""},{"path":"/reference/Linked_Lin_Exp_Para.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates The Additional Parameter For a linear-exponential formula with known maximum — Linked_Lin_Exp_Para","text":"returns parameter used Colossus","code":""},{"path":"/reference/Linked_Lin_Exp_Para.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates The Additional Parameter For a linear-exponential formula with known maximum — Linked_Lin_Exp_Para","text":"","code":"library(data.table) y <- 7.6 a0 <- 1.2 a1_goal <- 15 full_paras <- Linked_Lin_Exp_Para(y, a0, a1_goal)"},{"path":"/reference/LogisticRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully runs a logistic regression model, returning the model and results — LogisticRun","title":"Fully runs a logistic regression model, returning the model and results — LogisticRun","text":"LogisticRun uses formula, data.table, list controls prepare run Colossus logistic regression function","code":""},{"path":"/reference/LogisticRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully runs a logistic regression model, returning the model and results — LogisticRun","text":"","code":"LogisticRun(   model,   df,   a_n = list(c(0)),   keep_constant = c(0),   control = list(),   gradient_control = list(),   link = \"odds\",   single = FALSE,   observed_info = FALSE,   cons_mat = as.matrix(c(0)),   cons_vec = c(0),   norm = \"null\",   ... )"},{"path":"/reference/LogisticRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully runs a logistic regression model, returning the model and results — LogisticRun","text":"model either formula written get_form function, model result get_form function. df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. keep_constant binary values denote parameters change control list parameters controlling convergence, see Control_Options vignette details gradient_control list control options gradient descent algorithm. value given, gradient descent algorithm used instead Newton-Raphson. See Control_Options vignette details link Used logistic regression, linking function relating input model event probability. Current options \"odds\", \"ident\", \"loglink\" odds ratio, identity, complimentary loglink options. single boolean denote log-likelihood calculated returned, derivatives iterations observed_info boolean denote observed information matrix used calculate standard error parameters, expected information matrix cons_mat Matrix containing coefficients system linear constraints, formatted matrix cons_vec Vector containing constants system linear constraints, formatted vector norm methods used normalize covariates. Default 'null' normalization. options include 'max' normalize absolute maximum 'mean' normalize mean ... can include named entries control list parameter","code":""},{"path":"/reference/LogisticRun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully runs a logistic regression model, returning the model and results — LogisticRun","text":"returns class fully describing model regression results","code":""},{"path":"/reference/LogisticRun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully runs a logistic regression model, returning the model and results — LogisticRun","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1),   \"e\" = c(0, 0, 1, 0, 0, 0, 1) ) control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(1, 1),   \"halfmax\" = 1 ) formula <- logit(Cancer_Status) ~   loglinear(a, b, c, 0) + plinear(d, 0) + multiplicative() res <- LogisticRun(formula, df, a_n = c(1.1, -0.1, 0.2, 0.5), control = control)"},{"path":"/reference/OMP_Check.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks the OMP flag — OMP_Check","title":"Checks the OMP flag — OMP_Check","text":"OMP_Check Called directly R, checks omp flag returns true omp enabled","code":""},{"path":"/reference/OMP_Check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks the OMP flag — OMP_Check","text":"","code":"OMP_Check()"},{"path":"/reference/OMP_Check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks the OMP flag — OMP_Check","text":"boolean: True OMP allowed","code":""},{"path":"/reference/PoisRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully runs a poisson regression model, returning the model and results — PoisRun","title":"Fully runs a poisson regression model, returning the model and results — PoisRun","text":"PoisRun uses formula, data.table, list controls prepare run Colossus poisson regression function","code":""},{"path":"/reference/PoisRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully runs a poisson regression model, returning the model and results — PoisRun","text":"","code":"PoisRun(   model,   df,   a_n = list(c(0)),   keep_constant = c(0),   control = list(),   gradient_control = list(),   single = FALSE,   observed_info = FALSE,   cons_mat = as.matrix(c(0)),   cons_vec = c(0),   norm = \"null\",   ... )"},{"path":"/reference/PoisRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully runs a poisson regression model, returning the model and results — PoisRun","text":"model either formula written get_form function, model result get_form function. df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. keep_constant binary values denote parameters change control list parameters controlling convergence, see Control_Options vignette details gradient_control list control options gradient descent algorithm. value given, gradient descent algorithm used instead Newton-Raphson. See Control_Options vignette details single boolean denote log-likelihood calculated returned, derivatives iterations observed_info boolean denote observed information matrix used calculate standard error parameters, expected information matrix cons_mat Matrix containing coefficients system linear constraints, formatted matrix cons_vec Vector containing constants system linear constraints, formatted vector norm methods used normalize covariates. Default 'null' normalization. options include 'max' normalize absolute maximum 'mean' normalize mean ... can include named entries control list parameter","code":""},{"path":"/reference/PoisRun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully runs a poisson regression model, returning the model and results — PoisRun","text":"returns class fully describing model regression results","code":""},{"path":[]},{"path":"/reference/PoisRun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully runs a poisson regression model, returning the model and results — PoisRun","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1),   \"e\" = c(0, 0, 1, 0, 0, 0, 1) ) control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(1, 1),   \"halfmax\" = 1 ) formula <- Pois(Ending_Age, Cancer_Status) ~   loglinear(a, b, c, 0) + plinear(d, 0) + multiplicative() res <- PoisRun(formula, df, a_n = c(1.1, -0.1, 0.2, 0.5), control = control)"},{"path":"/reference/PoisRunJoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully runs a joint poisson regression model, returning the model and results — PoisRunJoint","title":"Fully runs a joint poisson regression model, returning the model and results — PoisRunJoint","text":"PoisRunJoint uses list formula, data.table, list controls prepare run Colossus poisson regression function joint dataset","code":""},{"path":"/reference/PoisRunJoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully runs a joint poisson regression model, returning the model and results — PoisRunJoint","text":"","code":"PoisRunJoint(   model,   df,   a_n = list(c(0)),   keep_constant = c(0),   control = list(),   gradient_control = list(),   single = FALSE,   observed_info = FALSE,   cons_mat = as.matrix(c(0)),   cons_vec = c(0),   norm = \"null\",   ... )"},{"path":"/reference/PoisRunJoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully runs a joint poisson regression model, returning the model and results — PoisRunJoint","text":"model either formula written get_form function, model result get_form function. df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. keep_constant binary values denote parameters change control list parameters controlling convergence, see Control_Options vignette details gradient_control list control options gradient descent algorithm. value given, gradient descent algorithm used instead Newton-Raphson. See Control_Options vignette details single boolean denote log-likelihood calculated returned, derivatives iterations observed_info boolean denote observed information matrix used calculate standard error parameters, expected information matrix cons_mat Matrix containing coefficients system linear constraints, formatted matrix cons_vec Vector containing constants system linear constraints, formatted vector norm methods used normalize covariates. Default 'null' normalization. options include 'max' normalize absolute maximum 'mean' normalize mean ... can include named entries control list parameter","code":""},{"path":"/reference/PoisRunJoint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully runs a joint poisson regression model, returning the model and results — PoisRunJoint","text":"returns class fully describing model regression results","code":""},{"path":[]},{"path":"/reference/PoisRunJoint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully runs a joint poisson regression model, returning the model and results — PoisRunJoint","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"Flu_Status\" = c(0, 1, 0, 0, 1, 0, 1),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1),   \"e\" = c(0, 0, 1, 0, 0, 0, 1) ) control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(1, 1),   \"halfmax\" = 1 ) formula_list <- list(Pois(Ending_Age, Cancer_Status) ~ plinear(d, 0),   Pois(Ending_Age, Flu_Status) ~ loglinear(d, 0),   \"shared\" = Pois(Ending_Age) ~ loglinear(a, b, c, 0) ) res <- PoisRunJoint(formula_list, df, control = control)"},{"path":"/reference/PoisRunMulti.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully runs a poisson regression model with multiple column realizations, returning the model and results — PoisRunMulti","title":"Fully runs a poisson regression model with multiple column realizations, returning the model and results — PoisRunMulti","text":"PoisRunMulti uses formula, data.table, list controls prepare run Colossus poisson regression function","code":""},{"path":"/reference/PoisRunMulti.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully runs a poisson regression model with multiple column realizations, returning the model and results — PoisRunMulti","text":"","code":"PoisRunMulti(   model,   df,   a_n = list(c(0)),   keep_constant = c(0),   realization_columns = matrix(c(\"temp00\", \"temp01\", \"temp10\", \"temp11\"), nrow = 2),   realization_index = c(\"temp0\", \"temp1\"),   control = list(),   gradient_control = list(),   single = FALSE,   observed_info = FALSE,   fma = FALSE,   mcml = FALSE,   cons_mat = as.matrix(c(0)),   cons_vec = c(0),   ... )"},{"path":"/reference/PoisRunMulti.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully runs a poisson regression model with multiple column realizations, returning the model and results — PoisRunMulti","text":"model either formula written get_form function, model result get_form function. df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. keep_constant binary values denote parameters change realization_columns used multi-realization regressions. Matrix column names rows column realizations, columns realization realization_index used multi-realization regressions. Vector column names, one column realizations. name used \"names\" variable equation definition control list parameters controlling convergence, see Control_Options vignette details gradient_control list control options gradient descent algorithm. value given, gradient descent algorithm used instead Newton-Raphson. See Control_Options vignette details single boolean denote log-likelihood calculated returned, derivatives iterations observed_info boolean denote observed information matrix used calculate standard error parameters, expected information matrix fma boolean denote Frequentist Model Averaging method used mcml boolean denote Monte Carlo Maximum Likelihood method used cons_mat Matrix containing coefficients system linear constraints, formatted matrix cons_vec Vector containing constants system linear constraints, formatted vector ... can include named entries control list parameter","code":""},{"path":"/reference/PoisRunMulti.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully runs a poisson regression model with multiple column realizations, returning the model and results — PoisRunMulti","text":"returns class fully describing model regression results","code":""},{"path":[]},{"path":"/reference/PoisRunMulti.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully runs a poisson regression model with multiple column realizations, returning the model and results — PoisRunMulti","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"t0\" = c(18, 20, 18, 19, 21, 20, 18),   \"t1\" = c(30, 45, 57, 47, 36, 60, 55),   \"lung\" = c(0, 0, 1, 0, 1, 0, 0),   \"dose\" = c(0, 1, 1, 0, 1, 0, 1) ) set.seed(3742) df$rand <- floor(runif(nrow(df), min = 0, max = 5)) df$rand0 <- floor(runif(nrow(df), min = 0, max = 5)) df$rand1 <- floor(runif(nrow(df), min = 0, max = 5)) df$rand2 <- floor(runif(nrow(df), min = 0, max = 5)) names <- c(\"dose\", \"rand\") realization_columns <- matrix(c(\"rand0\", \"rand1\", \"rand2\"), nrow = 1) realization_index <- c(\"rand\") control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiter\" = 1,   \"halfmax\" = 2, \"epsilon\" = 1e-6,   \"deriv_epsilon\" = 1e-6, \"step_max\" = 1.0,   \"thres_step_max\" = 100.0,   \"verbose\" = 0, \"ties\" = \"breslow\", \"double_step\" = 1 ) formula <- Pois(t1, lung) ~ loglinear(CONST, dose, rand, 0) + multiplicative() res <- PoisRun(formula, df, control = control)"},{"path":"/reference/RelativeRisk.coxres.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates hazard ratios for a reference vector — RelativeRisk.coxres","title":"Calculates hazard ratios for a reference vector — RelativeRisk.coxres","text":"coxres.RelativeRisk uses cox result object data, evaluate relative risk data using risk model result","code":""},{"path":"/reference/RelativeRisk.coxres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates hazard ratios for a reference vector — RelativeRisk.coxres","text":"","code":"# S3 method for class 'coxres' RelativeRisk(x, df, a_n = c(), ...)"},{"path":"/reference/RelativeRisk.coxres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates hazard ratios for a reference vector — RelativeRisk.coxres","text":"x result object regression, class coxres df data.table containing columns interest a_n list initial parameter values, used determine number parameters. May either list vectors single vector. ... extended match future parameters needed","code":""},{"path":"/reference/RelativeRisk.coxres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates hazard ratios for a reference vector — RelativeRisk.coxres","text":"returns class fully describing model regression results","code":""},{"path":"/reference/RelativeRisk.coxres.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates hazard ratios for a reference vector — RelativeRisk.coxres","text":"","code":"library(data.table) df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1),   \"e\" = c(0, 0, 1, 0, 0, 0, 1) ) control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(1, 1),   \"halfmax\" = 1 ) formula <- Cox(Starting_Age, Ending_Age, Cancer_Status) ~   loglinear(a, b, c, 0) + plinear(d, 0) + multiplicative() res <- CoxRun(formula, df,   a_n = list(c(1.1, -0.1, 0.2, 0.5), c(1.6, -0.12, 0.3, 0.4)),   control = control ) res_risk <- RelativeRisk(res, df)"},{"path":"/reference/RelativeRisk.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic relative risk calculation function, default option — RelativeRisk.default","title":"Generic relative risk calculation function, default option — RelativeRisk.default","text":"RelativeRisk.default Generic relative risk calculation function, default nothing happens","code":""},{"path":"/reference/RelativeRisk.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic relative risk calculation function, default option — RelativeRisk.default","text":"","code":"# Default S3 method RelativeRisk(x, df, ...)"},{"path":"/reference/RelativeRisk.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic relative risk calculation function, default option — RelativeRisk.default","text":"x result object regression, class coxres df data.table containing columns interest ... extended necessary parameters","code":""},{"path":"/reference/RelativeRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic relative risk calculation function — RelativeRisk","title":"Generic relative risk calculation function — RelativeRisk","text":"RelativeRisk Generic relative risk calculation function","code":""},{"path":"/reference/RelativeRisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic relative risk calculation function — RelativeRisk","text":"","code":"RelativeRisk(x, df, ...)"},{"path":"/reference/RelativeRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic relative risk calculation function — RelativeRisk","text":"x result object regression, class coxres df data.table containing columns interest ... extended necessary parameters","code":""},{"path":"/reference/Replace_Missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically assigns missing values in listed columns — Replace_Missing","title":"Automatically assigns missing values in listed columns — Replace_Missing","text":"Replace_Missing checks column fills NA values","code":""},{"path":"/reference/Replace_Missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically assigns missing values in listed columns — Replace_Missing","text":"","code":"Replace_Missing(df, name_list, msv, verbose = FALSE)"},{"path":"/reference/Replace_Missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically assigns missing values in listed columns — Replace_Missing","text":"df data.table containing columns interest name_list vector string column names check msv value replace na , used every column used verbose integer valued 0-4 controlling information printed terminal. level includes lower levels. 0: silent, 1: errors printed, 2: warnings printed, 3: notes printed, 4: debug information printed. Errors situations stop regression, warnings situations assume default values user might intended, notes provide information regression progress, debug prints C++ progress intermediate results. default level 2 True/False converted 3/0.","code":""},{"path":"/reference/Replace_Missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatically assigns missing values in listed columns — Replace_Missing","text":"returns filled datatable","code":""},{"path":[]},{"path":"/reference/Replace_Missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatically assigns missing values in listed columns — Replace_Missing","text":"","code":"library(data.table) ## basic example code reproduced from the starting-description vignette df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, NA, 47, 36, NA, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0) ) df <- Replace_Missing(df, c(\"Starting_Age\", \"Ending_Age\"), 70)"},{"path":"/reference/Residual.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic Residual calculation function, default option — Residual.default","title":"Generic Residual calculation function, default option — Residual.default","text":"Residual.default Generic Residual calculation function, default nothing happens","code":""},{"path":"/reference/Residual.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic Residual calculation function, default option — Residual.default","text":"","code":"# Default S3 method Residual(x, df, ...)"},{"path":"/reference/Residual.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic Residual calculation function, default option — Residual.default","text":"x result object regression, class coxres poisres df data.table containing columns interest ... extended necessary parameters","code":""},{"path":"/reference/Residual.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic Residual calculation function — Residual","title":"Generic Residual calculation function — Residual","text":"Residual Generic Residual calculation function","code":""},{"path":"/reference/Residual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic Residual calculation function — Residual","text":"","code":"Residual(x, df, ...)"},{"path":"/reference/Residual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic Residual calculation function — Residual","text":"x result object regression, class coxres poisres df data.table containing columns interest ... extended necessary parameters","code":""},{"path":"/reference/Residual.poisres.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the Residuals for a completed poisson model — Residual.poisres","title":"Calculates the Residuals for a completed poisson model — Residual.poisres","text":"Residual.poisres uses user provided data, person-year/event columns, vectors specifying model, options calculate residuals solved Poisson regression","code":""},{"path":"/reference/Residual.poisres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the Residuals for a completed poisson model — Residual.poisres","text":"","code":"# S3 method for class 'poisres' Residual(   x,   df,   control = list(),   a_n = c(),   pearson = FALSE,   deviance = FALSE,   ... )"},{"path":"/reference/Residual.poisres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the Residuals for a completed poisson model — Residual.poisres","text":"x result object regression, class poisres df data.table containing columns interest control list parameters controlling convergence, see Control_Options vignette details a_n list initial parameter values, used determine number parameters. May either list vectors single vector. pearson boolean calculate pearson residuals deviance boolean calculate deviance residuals ... can include named entries assign_control list parameter","code":""},{"path":"/reference/Residual.poisres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the Residuals for a completed poisson model — Residual.poisres","text":"returns list final results","code":""},{"path":[]},{"path":"/reference/System_Version.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks OS, compilers, and OMP — System_Version","title":"Checks OS, compilers, and OMP — System_Version","text":"System_Version checks OS, default R c++ compiler, OMP enabled","code":""},{"path":"/reference/System_Version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks OS, compilers, and OMP — System_Version","text":"","code":"System_Version()"},{"path":"/reference/System_Version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks OS, compilers, and OMP — System_Version","text":"returns list results","code":""},{"path":[]},{"path":"/reference/Time_Since.html","id":null,"dir":"Reference","previous_headings":"","what":"Automates creating a date since a reference column — Time_Since","title":"Automates creating a date since a reference column — Time_Since","text":"Time_Since generates new dataframe column containing time since reference given unit","code":""},{"path":"/reference/Time_Since.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automates creating a date since a reference column — Time_Since","text":"","code":"Time_Since(df, dcol0, tref, col_name, units = \"days\")"},{"path":"/reference/Time_Since.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automates creating a date since a reference column — Time_Since","text":"df data.table containing columns interest dcol0 list ending month, day, year tref reference time date format col_name vector new column names units time unit use","code":""},{"path":"/reference/Time_Since.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automates creating a date since a reference column — Time_Since","text":"returns updated dataframe","code":""},{"path":[]},{"path":"/reference/Time_Since.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automates creating a date since a reference column — Time_Since","text":"","code":"library(data.table) m0 <- c(1, 1, 2, 2) m1 <- c(2, 2, 3, 3) d0 <- c(1, 2, 3, 4) d1 <- c(6, 7, 8, 9) y0 <- c(1990, 1991, 1997, 1998) y1 <- c(2001, 2003, 2005, 2006) df <- data.table::data.table(   \"m0\" = m0, \"m1\" = m1,   \"d0\" = d0, \"d1\" = d1,   \"y0\" = y0, \"y1\" = y1 ) tref <- strptime(\"3-22-1997\", format = \"%m-%d-%Y\", tz = \"UTC\") df <- Time_Since(df, c(\"m1\", \"d1\", \"y1\"), tref, \"date_since\")"},{"path":"/reference/factorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Splits a parameter into factors — factorize","title":"Splits a parameter into factors — factorize","text":"factorize uses user provided list columns define new parameter unique value update data.table. interaction terms","code":""},{"path":"/reference/factorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splits a parameter into factors — factorize","text":"","code":"factorize(df, col_list, verbose = 0)"},{"path":"/reference/factorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splits a parameter into factors — factorize","text":"df data.table containing columns interest col_list array column names factor terms defined verbose integer valued 0-4 controlling information printed terminal. level includes lower levels. 0: silent, 1: errors printed, 2: warnings printed, 3: notes printed, 4: debug information printed. Errors situations stop regression, warnings situations assume default values user might intended, notes provide information regression progress, debug prints C++ progress intermediate results. default level 2 True/False converted 3/0.","code":""},{"path":"/reference/factorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splits a parameter into factors — factorize","text":"returns list two named fields. df updated dataframe, cols new column names","code":""},{"path":[]},{"path":"/reference/factorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splits a parameter into factors — factorize","text":"","code":"library(data.table) a <- c(0, 1, 2, 3, 4, 5, 6) b <- c(1, 2, 3, 4, 5, 6, 7) c <- c(0, 1, 2, 1, 0, 1, 0) df <- data.table::data.table(\"a\" = a, \"b\" = b, \"c\" = c) col_list <- c(\"c\") val <- factorize(df, col_list) df <- val$df new_col <- val$cols"},{"path":"/reference/gen_time_dep.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies time dependence to parameters — gen_time_dep","title":"Applies time dependence to parameters — gen_time_dep","text":"gen_time_dep generates new dataframe time dependent covariates applying grid time","code":""},{"path":"/reference/gen_time_dep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies time dependence to parameters — gen_time_dep","text":"","code":"gen_time_dep(   df,   time1,   time2,   event0,   iscox,   dt,   new_names,   dep_cols,   func_form,   fname,   tform,   nthreads = as.numeric(detectCores()) )"},{"path":"/reference/gen_time_dep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies time dependence to parameters — gen_time_dep","text":"df data.table containing columns interest time1 column used time period starts time2 column used time period end event0 column used event status iscox boolean rows event times kept, rows removed true. Cox proportional hazards model use rows intervals containing event times dt spacing time new rows new_names list new names use instead default, default used entry ”\" dep_cols columns needed new dataframe func_form vector functions apply time-dependent covariate. form func(df, time) returning vector new column value fname filename used new dataframe tform list string function identifiers, used linear/step nthreads number threads use, use threads available machine","code":""},{"path":"/reference/gen_time_dep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies time dependence to parameters — gen_time_dep","text":"returns updated dataframe","code":""},{"path":[]},{"path":"/reference/gen_time_dep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies time dependence to parameters — gen_time_dep","text":"","code":"library(data.table) # Adapted from the tests a <- c(20, 20, 5, 10, 15) b <- c(1, 2, 1, 1, 2) c <- c(0, 0, 1, 1, 1) df <- data.table::data.table(\"a\" = a, \"b\" = b, \"c\" = c) time1 <- \"%trunc%\" time2 <- \"a\" event <- \"c\" control <- list(   \"lr\" = 0.75, \"maxiter\" = -1, \"halfmax\" = 5, \"epsilon\" = 1e-9,   \"deriv_epsilon\" = 1e-9, \"step_max\" = 1.0,   \"thres_step_max\" = 100.0,   \"verbose\" = FALSE, \"ties\" = \"breslow\", \"double_step\" = 1 ) grt_f <- function(df, time_col) {   return((df[, \"b\"] * df[, get(time_col)])[[1]]) } func_form <- c(\"lin\") df_new <- gen_time_dep(   df, time1, time2, event, TRUE, 0.01, c(\"grt\"), c(),   c(grt_f), paste(\"test\", \"_new.csv\", sep = \"\"), func_form, 1 ) file.remove(\"test_new.csv\") #> [1] TRUE"},{"path":"/reference/get_form.html","id":null,"dir":"Reference","previous_headings":"","what":"Interprets a Colossus formula and makes necessary changes to data — get_form","title":"Interprets a Colossus formula and makes necessary changes to data — get_form","text":"get_form uses formula data.table, fully describe model Colossus regression function.","code":""},{"path":"/reference/get_form.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interprets a Colossus formula and makes necessary changes to data — get_form","text":"","code":"get_form(formula, df, nthreads = as.numeric(detectCores())/2)"},{"path":"/reference/get_form.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interprets a Colossus formula and makes necessary changes to data — get_form","text":"formula formula object, written Colossus notation. See Unified Equation Representation vignette details. df data.table containing columns interest nthreads number threads use, use threads available machine","code":""},{"path":"/reference/get_form.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interprets a Colossus formula and makes necessary changes to data — get_form","text":"returns class fully describing model updated data","code":""},{"path":[]},{"path":"/reference/get_form.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interprets a Colossus formula and makes necessary changes to data — get_form","text":"","code":"library(data.table) ## basic example code reproduced from the starting-description vignette df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1),   \"e\" = c(0, 0, 1, 0, 0, 0, 1) ) formula <- Cox(Starting_Age, Ending_Age, Cancer_Status) ~   loglinear(a, b, c, 0) + plinear(d, 0) + multiplicative() model <- get_form(formula, df, 1)"},{"path":"/reference/get_form_joint.html","id":null,"dir":"Reference","previous_headings":"","what":"Interprets a Poisson joint formula and makes necessary changes to data — get_form_joint","title":"Interprets a Poisson joint formula and makes necessary changes to data — get_form_joint","text":"get_form_joint uses two event formula, shared formula, data.table, fully describe model joint Poisson model.","code":""},{"path":"/reference/get_form_joint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interprets a Poisson joint formula and makes necessary changes to data — get_form_joint","text":"","code":"get_form_joint(formula_list, df, nthreads = as.numeric(detectCores())/2)"},{"path":"/reference/get_form_joint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interprets a Poisson joint formula and makes necessary changes to data — get_form_joint","text":"formula_list list formula objects, written Colossus notation. See Unified Equation Representation vignette details. formula include elements specific specified event column. list can include entry named \"shared\" denote shared terms. person-year strata columns . df data.table containing columns interest nthreads number threads use, use threads available machine","code":""},{"path":"/reference/get_form_joint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interprets a Poisson joint formula and makes necessary changes to data — get_form_joint","text":"returns class fully describing model updated data","code":""},{"path":[]},{"path":"/reference/plot.coxres.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs Cox Proportional Hazard model plots — plot.coxres","title":"Performs Cox Proportional Hazard model plots — plot.coxres","text":"plot.coxres uses user provided data, time/event columns, vectors specifying model, options choose save plots","code":""},{"path":"/reference/plot.coxres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs Cox Proportional Hazard model plots — plot.coxres","text":"","code":"# S3 method for class 'coxres' plot(x, df, plot_options, a_n = c(), ...)"},{"path":"/reference/plot.coxres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs Cox Proportional Hazard model plots — plot.coxres","text":"x result object regression, class coxres df data.table containing columns interest plot_options list parameters controlling plot options, see RunCoxPlots() different options a_n list initial parameter values, used determine number parameters. May either list vectors single vector. ... can include named entries plot_options parameter","code":""},{"path":"/reference/plot.coxres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs Cox Proportional Hazard model plots — plot.coxres","text":"saves plots current directory returns data used plots","code":""},{"path":"/reference/plot.coxres.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs Cox Proportional Hazard model plots — plot.coxres","text":"","code":"library(data.table) ## basic example code reproduced from the starting-description vignette df <- data.table::data.table(   \"UserID\" = c(112, 114, 213, 214, 115, 116, 117),   \"Starting_Age\" = c(18, 20, 18, 19, 21, 20, 18),   \"Ending_Age\" = c(30, 45, 57, 47, 36, 60, 55),   \"Cancer_Status\" = c(0, 0, 1, 0, 1, 0, 0),   \"a\" = c(0, 1, 1, 0, 1, 0, 1),   \"b\" = c(1, 1.1, 2.1, 2, 0.1, 1, 0.2),   \"c\" = c(10, 11, 10, 11, 12, 9, 11),   \"d\" = c(0, 0, 0, 1, 1, 1, 1) ) control <- list(   \"ncores\" = 1, \"lr\" = 0.75, \"maxiters\" = c(1, 1),   \"halfmax\" = 1 ) formula <- Cox(Starting_Age, Ending_Age, Cancer_Status) ~   loglinear(a, b, c, 0) + plinear(d, 0) + multiplicative() res <- CoxRun(formula, df,   control = control,   a_n = list(c(1.1, -0.1, 0.2, 0.5), c(1.6, -0.12, 0.3, 0.4)) ) plot_options <- list(   \"type\" = c(\"surv\", paste(tempfile(),     \"run\",     sep = \"\"   )), \"studyid\" = \"UserID\",   \"verbose\" = FALSE ) res_plot <- plot(res, df, plot_options)"},{"path":"/reference/print.caseconres.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a case-control regression output clearly — print.caseconres","title":"Prints a case-control regression output clearly — print.caseconres","text":"print.caseconres uses list output regression, prints table results summarizes score convergence.","code":""},{"path":"/reference/print.caseconres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a case-control regression output clearly — print.caseconres","text":"","code":"# S3 method for class 'caseconres' print(x, ...)"},{"path":"/reference/print.caseconres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a case-control regression output clearly — print.caseconres","text":"x result object regression, class caseconres ... can include number digits, named digit, unnamed integer entry assumed digits","code":""},{"path":"/reference/print.caseconres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints a case-control regression output clearly — print.caseconres","text":"return nothing, prints results console","code":""},{"path":[]},{"path":"/reference/print.coxres.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a cox regression output clearly — print.coxres","title":"Prints a cox regression output clearly — print.coxres","text":"print.coxres uses list output regression, prints table results summarizes score convergence.","code":""},{"path":"/reference/print.coxres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a cox regression output clearly — print.coxres","text":"","code":"# S3 method for class 'coxres' print(x, ...)"},{"path":"/reference/print.coxres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a cox regression output clearly — print.coxres","text":"x result object regression, class coxres ... can include number digits, named digit, unnamed integer entry assumed digits","code":""},{"path":"/reference/print.coxres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints a cox regression output clearly — print.coxres","text":"return nothing, prints results console","code":""},{"path":[]},{"path":"/reference/print.coxresbound.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a cox likelihood boundary regression output clearly — print.coxresbound","title":"Prints a cox likelihood boundary regression output clearly — print.coxresbound","text":"print.coxresbound uses list output regression, prints table results summarizes score convergence.","code":""},{"path":"/reference/print.coxresbound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a cox likelihood boundary regression output clearly — print.coxresbound","text":"","code":"# S3 method for class 'coxresbound' print(x, ...)"},{"path":"/reference/print.coxresbound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a cox likelihood boundary regression output clearly — print.coxresbound","text":"x result object regression, class coxresbound ... can include number digits, named digit, unnamed integer entry assumed digits","code":""},{"path":"/reference/print.coxresbound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints a cox likelihood boundary regression output clearly — print.coxresbound","text":"return nothing, prints results console","code":""},{"path":[]},{"path":"/reference/print.logitres.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a logistic regression output clearly — print.logitres","title":"Prints a logistic regression output clearly — print.logitres","text":"print.logitres uses list output regression, prints table results summarizes score convergence.","code":""},{"path":"/reference/print.logitres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a logistic regression output clearly — print.logitres","text":"","code":"# S3 method for class 'logitres' print(x, ...)"},{"path":"/reference/print.logitres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a logistic regression output clearly — print.logitres","text":"x result object regression, class logitres ... can include number digits, named digit, unnamed integer entry assumed digits","code":""},{"path":"/reference/print.logitres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints a logistic regression output clearly — print.logitres","text":"return nothing, prints results console","code":""},{"path":[]},{"path":"/reference/print.poisres.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a poisson regression output clearly — print.poisres","title":"Prints a poisson regression output clearly — print.poisres","text":"print.poisres uses list output regression, prints table results summarizes score convergence.","code":""},{"path":"/reference/print.poisres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a poisson regression output clearly — print.poisres","text":"","code":"# S3 method for class 'poisres' print(x, ...)"},{"path":"/reference/print.poisres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a poisson regression output clearly — print.poisres","text":"x result object regression, class poisres ... can include number digits, named digit, unnamed integer entry assumed digits","code":""},{"path":"/reference/print.poisres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints a poisson regression output clearly — print.poisres","text":"return nothing, prints results console","code":""},{"path":[]},{"path":"/reference/print.poisresbound.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a poisson likelihood boundary regression output clearly — print.poisresbound","title":"Prints a poisson likelihood boundary regression output clearly — print.poisresbound","text":"print.poisresbound uses list output regression, prints table results summarizes score convergence.","code":""},{"path":"/reference/print.poisresbound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a poisson likelihood boundary regression output clearly — print.poisresbound","text":"","code":"# S3 method for class 'poisresbound' print(x, ...)"},{"path":"/reference/print.poisresbound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a poisson likelihood boundary regression output clearly — print.poisresbound","text":"x result object regression, class poisresbound ... can include number digits, named digit, unnamed integer entry assumed digits","code":""},{"path":"/reference/print.poisresbound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints a poisson likelihood boundary regression output clearly — print.poisresbound","text":"return nothing, prints results console","code":""},{"path":[]},{"path":"/news/index.html","id":"colossus-09","dir":"Changelog","previous_headings":"","what":"Colossus 0.9","title":"Colossus 0.9","text":"Added NEWS.md file track changes package.","code":""},{"path":"/news/index.html","id":"colossus-100","dir":"Changelog","previous_headings":"","what":"Colossus 1.0.0","title":"Colossus 1.0.0","text":"CRAN release: 2024-02-20 Initial submission C++ code modified apply OpenMP code OpenMP isn’t detected, resolve MacOS installation failures","code":""},{"path":"/news/index.html","id":"colossus-101","dir":"Changelog","previous_headings":"","what":"Colossus 1.0.1","title":"Colossus 1.0.1","text":"CRAN release: 2024-02-26 Configuration improved detect compiler information Linux configuration depends system wide c++ default compiler used compile R OpenMP support used c++ default R compiler clang","code":""},{"path":"/news/index.html","id":"colossus-102","dir":"Changelog","previous_headings":"","what":"Colossus 1.0.2","title":"Colossus 1.0.2","text":"utility checks updated check keep_constant 0/1 values code fail keep_constant integer valued 0/1, explanation ","code":""},{"path":"/news/index.html","id":"colossus-103","dir":"Changelog","previous_headings":"","what":"Colossus 1.0.3","title":"Colossus 1.0.3","text":"configuration script libraries moved Suggested: Imports: configuration script functions moved non-exported functions Colossus, circumvents note imported libraries used may later used provide user function informs OpenMP /isn’t supported","code":""},{"path":"/news/index.html","id":"colossus-104","dir":"Changelog","previous_headings":"","what":"Colossus 1.0.4","title":"Colossus 1.0.4","text":"utility checks updated check term numbers subterm types R side code fail term numbers integers, term numbers missing, subterm types ","code":""},{"path":"/news/index.html","id":"colossus-105","dir":"Changelog","previous_headings":"","what":"Colossus 1.0.5","title":"Colossus 1.0.5","text":"compilation flags changed macros","code":""},{"path":"/news/index.html","id":"colossus-110","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.0","title":"Colossus 1.1.0","text":"CRAN release: 2024-04-03 Default Makevars now fully portable default windows uses OpenMP now GitHub version include instructions activating configuration use OpenMP gcc Linux","code":""},{"path":"/news/index.html","id":"colossus-111","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.1","title":"Colossus 1.1.1","text":"CRAN release: 2024-04-30 ggplot2 longer required, now optional additional testing added coverage default Makevars added via bash script","code":""},{"path":"/news/index.html","id":"colossus-112","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.2","title":"Colossus 1.1.2","text":"Log-likelihood bound functionality added subject usual convergence issues, manual search option","code":""},{"path":"/news/index.html","id":"colossus-113","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.3","title":"Colossus 1.1.3","text":"CRAN release: 2024-09-06 Cox regression now removes rows end first event start last event Cox regression now sets constant rows constant, helps aliasing Tests now use sink() avoid printing much excessive output console. Tests now consolidated .","code":""},{"path":"/news/index.html","id":"colossus-1141","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.4.1","title":"Colossus 1.1.4.1","text":"CRAN release: 2024-09-20 Cox plotting functions now return tables used plots (last plot table returned) Plotting vignette updated include details plots survival package listed suggested plotting vignette","code":""},{"path":"/news/index.html","id":"colossus-1142","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.4.2","title":"Colossus 1.1.4.2","text":"CRAN release: 2024-10-21 R errors warnings sent stop() warning(). C++ errors warnings still controlled verbosity argument ggsave defaults width/height = 7 Updates started fix possible OpenMP issues fedora 36 running clang 18 Unable debug printing option cover c++ files testing, still test output readable. debug output removed.","code":""},{"path":"/news/index.html","id":"colossus-115","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.5","title":"Colossus 1.1.5","text":"Started adding simplifications allow faster iterations Added simplification linear ERR model Started gradient descent code Started external rate comparison options Added person-count person-time table generation code vignette","code":""},{"path":"/news/index.html","id":"colossus-1155","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.5.5","title":"Colossus 1.1.5.5","text":"Added CoxCurveSolver function solve likelihood boundaries via bisection method","code":""},{"path":"/news/index.html","id":"colossus-116","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.6","title":"Colossus 1.1.6","text":"MacOS testing OpenMP finished. MacOS use OpenMP officially checked. default systems forced use single thread linux using clang. can turned setting “R_COLOSSUS_NOT_CRAN” environment variable.","code":""},{"path":"/news/index.html","id":"colossus-117","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.7","title":"Colossus 1.1.7","text":"Gradient descent algorithms tested presented vignette Multiple realization function tested ","code":""},{"path":"/news/index.html","id":"colossus-118","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.8","title":"Colossus 1.1.8","text":"CurveSolve functions converted c++ functions Testing scaled back take less time","code":""},{"path":"/news/index.html","id":"colossus-119","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.9","title":"Colossus 1.1.9","text":"Cox based functions switched covariance matrix calculation negative inverse log-likelihood second derivative, expected information matrix.","code":""},{"path":"/news/index.html","id":"colossus-1110","dir":"Changelog","previous_headings":"","what":"Colossus 1.1.10","title":"Colossus 1.1.10","text":"Cox based functions updated improve speed Additional CurveSolve output provided give final window width final step","code":""},{"path":"/news/index.html","id":"colossus-12","dir":"Changelog","previous_headings":"","what":"Colossus 1.2","title":"Colossus 1.2","text":"CRAN release: 2025-02-13 Cox Poisson functions now return expected information matrix derived covariance","code":""},{"path":"/news/index.html","id":"colossus-121","dir":"Changelog","previous_headings":"","what":"Colossus 1.2.1","title":"Colossus 1.2.1","text":"Matched Case-Control base code equation vignette added","code":""},{"path":"/news/index.html","id":"colossus-122","dir":"Changelog","previous_headings":"","what":"Colossus 1.2.2","title":"Colossus 1.2.2","text":"Additional code cleanup minor utility function speed improvements","code":""},{"path":"/news/index.html","id":"colossus-130","dir":"Changelog","previous_headings":"","what":"Colossus 1.3.0","title":"Colossus 1.3.0","text":"CRAN release: 2025-06-05 Multiple realization code updated improve speed lingering debugging variables removed: fir der_iden","code":""},{"path":"/news/index.html","id":"colossus-131","dir":"Changelog","previous_headings":"","what":"Colossus 1.3.1","title":"Colossus 1.3.1","text":"Convergence check performed often Checks actual maximum step taken compare threshold Previous versions may run iterations necessary meet derivative step size thresholds","code":""},{"path":"/news/index.html","id":"colossus-140","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.0","title":"Colossus 1.4.0","text":"Switch formula inputs model classes Removed unused functions, simplify documentation","code":""},{"path":"/news/index.html","id":"colossus-141","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.1","title":"Colossus 1.4.1","text":"Formula input now allows general applications factor, ns(), bs(), (var^n), interaction, etc.","code":""},{"path":"/news/index.html","id":"colossus-142","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.2","title":"Colossus 1.4.2","text":"Option added normalize covariates, either scaled mean maximum values. Gradient descent option now calculates standard error covariance second derivative regression.","code":""},{"path":"/news/index.html","id":"colossus-143","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.3","title":"Colossus 1.4.3","text":"CRAN release: 2025-10-30 Logistic regression added Newton step calculation now checks predicted change score, moves opposite direction expected score worse","code":""},{"path":"/news/index.html","id":"colossus-144","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.4","title":"Colossus 1.4.4","text":"Corrected factorization applied factored columns Fixed event assignment reordering data Multiplicative Multiplicative-excess models now distinct. default left multiplicative-excess.","code":""},{"path":"/news/index.html","id":"colossus-145","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.5","title":"Colossus 1.4.5","text":"CRAN release: 2025-12-07 Updated geometric-mixture code apply defaults 0.5 theta excess terms Corrected normalization intercept parameters","code":""},{"path":"/news/index.html","id":"colossus-146","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.6","title":"Colossus 1.4.6","text":"CRAN release: 2025-12-16 Fixed bug second derivative risk calculations, wrong correction multi-term risk values. Improved results printing. Basic regression results print term number column multiple terms used. Likelihood boundary results now print limit score negative limit hit. ncores option used Colossus calculations now also applied data.table operations. Previous number reset calculations, may need manually reset regression hits error.","code":""},{"path":"/news/index.html","id":"colossus-147","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.7","title":"Colossus 1.4.7","text":"Updated behavior negative risk hit. Partial steps now smaller, overall maximum step size checked loop. Regressions end hitting negative limit now print warning result table.","code":""},{"path":"/news/index.html","id":"colossus-148","dir":"Changelog","previous_headings":"","what":"Colossus 1.4.8","title":"Colossus 1.4.8","text":"Updated stratified poisson modeling correctly update background strata risk levels Updated formula reading throw errors long formulas","code":""}]
